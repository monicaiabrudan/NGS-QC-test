[
  {
    "objectID": "course_modules/Module1/module1.html",
    "href": "course_modules/Module1/module1.html",
    "title": "Overview",
    "section": "",
    "text": "Content by Eric Dawson (Bioinformatics Scientist (Genomics / AI) - Nvidia) and Carla Daniela Robles Espinoza (Laboratorio Internacional de Investigación sobre el Genoma Humano, Universidad Nacional Autónoma de México)\n\nDuration\n3 hours\n\n\nKey topics\nIn this module, learners will look at data formats in detail. At the end of the theory, there is a mandatory to test their knowledge.\nFASTQ\n• Unaligned read sequences with base qualities\nSAM/BAM\n• Unaligned or aligned reads\n• Text and binary formats\nCRAM\n• Better compression than BAM\nVCF/BCF\n• Flexible variant call format\n• Arbitrary types of sequence variation\n• SNPs, indels, structural variations\n\n\nActivities\n\nLecture: 1 hour\nPractical exercises: 1.5 hours\nAssessment quiz: 0.5 hours\n\n\n\nManual\nModule manual\n\n\nPresentation slides\n(PPT/PDF, to be generated from the module manual. Instructions on how to that will be added here.)\n\n\nLecture recording, notes and scripts\nPre-recorded lecture, temporally stored on the LMS\n\n\nPractical exercises\n\nGoogle Colab\nYou can practice working with the file formats presented in this modules using a Google Colab developed specifically for this purpose.\nFor detailed information on what is Google Colab, check: What is google colab?\nTo get started with Google Colab use a shared link from Google Drive:\na. Open the Shared Link: Click on the shared link provided to you. It will usually look like this: https://drive.google.com/file/d/....\nThe shared link is IntroductionToLinux.ipynb\nb. Make a Copy: If the link opens a view-only version of the notebook, you can create your own editable copy by selecting File &gt; Save a copy in Drive. This will save the notebook to your Google Drive.\nc. Open Your Copy: Once the copy is saved, you can open it from your Google Drive. You can also access it anytime through Google Colab by selecting File &gt; Open notebook and navigating to your Drive.\n\n\nVirtual Machine\nCommand line walk through.\n\n\n\nDatasets\nPractice files for this module can be found on Github.\n\n\nAssessment quiz\nQuestions"
  },
  {
    "objectID": "course_modules/Module1/module1_manual.html",
    "href": "course_modules/Module1/module1_manual.html",
    "title": "Manual",
    "section": "",
    "text": "These formats store raw or processed nucleotide and protein sequences. \n\n\nHere’s an example of 4 lines from a human reference genome FASTA file:\n\n\"&gt;chr1\" is the header for chromosome 1. Each chromosome has its own header line in the file. \nHeaders usually contain additional details like source, version, or length, e.g.:\n&gt;chr1 dna:chromosome chromosome:GRCh38:1:1:248956422:1.\nThe following lines are the “sequence lines”.\nThey contain nucleotide bases (A, T, C, G, and sometimes N for unknown bases). In FASTA files, the sequence is often wrapped to fit within 80 characters per line.\n\n\n\nFASTQ is a simple format for raw unaligned sequencing reads. This is an extension to the FASTA file format and it is composed of sequence and an associated per base quality score.\n\n\nThe quality of the sequenced nucleotides is encoded in ASCII characters with decimal codes 33-126.\n\nThe ASCII code of “A” is 65. For a nucleotide that has the quality score encoded by A, this can be translates to quality score of Q=65−33=32.\nThe formula to compute the phred quality score is: P = 10−Q/10\n\nThe figure above shows the interpretation of the quality scores, in terms of probability of error and accuracy.\nBeware:\n\nmultiple quality scores were in use: Sanger, Solexa, Illumina 1.3+.\npaired-end sequencing produces two FASTQ files.\n\n\nThe ASCII table (American Standard Code for Information Interchange) is a character encoding standard that maps 128 characters (0–127) to numeric codes. It includes letters (uppercase and lowercase), digits, punctuation marks, control characters (e.g., newline, tab), and special symbols, enabling computers to represent and process text."
  },
  {
    "objectID": "course_modules/Module1/module1_manual.html#other-important-information",
    "href": "course_modules/Module1/module1_manual.html#other-important-information",
    "title": "Manual",
    "section": "Other important information",
    "text": "Other important information\nA CIGAR string (Compact Idiosyncratic Gapped Alignment Report) is a sequence of operations used in SAM/BAM files to describe how a read is aligned to a reference genome. It specifies matches, mismatches, insertions, deletions, and other events in the alignment.\n\nStructure of a CIGAR String\nA CIGAR string consists of a series of operations, each represented by a length (number) followed by a character (operation type).\n\nCommon Operations:\n\nM: Match (alignment match or mismatch).\nExample: 10M = 10 bases aligned (could include mismatches).\nI: Insertion (relative to the reference).\nExample: 5I = 5 bases inserted in the query sequence.\nD: Deletion (relative to the reference).\nExample: 3D = 3 bases deleted in the reference sequence.\nS: Soft clipping (query sequence bases not aligned but present in the sequence).\nExample: 8S = 8 bases clipped from the start or end.\nH: Hard clipping (query sequence bases not aligned and removed from the sequence).\nExample: 10H = 10 bases clipped and not stored in the sequence.\nN: Skipped region (in the reference).\nExample: 100N = 100 bases skipped in the reference (e.g., introns in RNA-Seq).\nP: Padding (used with insertions or deletions in multiple sequence alignment).\n=: Exact match to the reference.\nX: Mismatch to the reference.\n\nExamples:\nRef: ACGTACGTACGTACGT\nRead: ACGT----ACGTACGA\nCigar: 4M 4D 8M\nRef: ACGT----ACGTACGT\nRead: ACGTACGTACGTACGT\nCigar: 4M 4I 8M\n\nRef: ACTCAGTG--GT\nRead: ACGCA-TGCAGTtagacgt\nCigar: 5M 1D 2M 2I 2M 7S\n\n\n\n** Key Takeaways:**\n\nCIGAR strings describe how the query sequence aligns to the reference genome.\nThey are critical for understanding alignments in SAM/BAM files.\nTools like samtools or IGV can help visualize alignments and interpret CIGAR strings.\n\n\n\nThe MAF file format\nMAF stands for “Mutation-Annotation Format” and is a tab-delimited text file containing aggregated information from VCF files (NCI-GDC). It aggregates lots of information – 120+ fields per mutation! You can review all these at: https://docs.gdc.cancer.gov/Data/File_Formats/MAF_Format/\nYou can convert between VCF and MAF via vcf2maf tools!\nperl vcf2maf.pl –input-vcf [vcf_file] –output-maf\n[maf_file] –vep-path /cm/shared/apps/vep/ensembl-vep-\nrelease-106.1/ –vep-data /mnt/Archives/vep/106/38/ –ref-\nfasta [fasta_file] –tumor-id [tumor] –normal-id [normal]"
  },
  {
    "objectID": "course_modules/Module1/module1_manual.html#ga4gh",
    "href": "course_modules/Module1/module1_manual.html#ga4gh",
    "title": "Manual",
    "section": "GA4GH",
    "text": "GA4GH\nThe Global Alliance for Genomics and Health (GA4GH) is an international coalition dedicated to advancing human health by creating frameworks and standards for sharing genomic and clinical data. Its mission is to enable responsible, ethical, and secure global collaboration in genomics research and healthcare.\nCore Mission:\n\nEstablish a common framework to facilitate the sharing of genomic and clinical data.\n\n\n\nImprove human health through international collaboration and innovation.\n\n\nWorking Groups\nGA4GH is organized into several working groups, each focusing on a specific aspect of genomic data sharing:\n\nClinical: Applies genomics to healthcare and medicine.\nRegulatory and Ethics: Addresses legal, ethical, and policy issues related to genomic data.\nSecurity: Ensures the privacy and protection of sensitive genomic data.\nData: Develops tools, resources, and initiatives to enhance data sharing and analysis.\n\n\n\nKey Projects of the Data Working Group\n\nBeacon Project: Tests global willingness to share genetic data.\nBRCA Challenge: Advances understanding of breast and other cancers by studying BRCA-related genetic variants.\nMatchmaker Exchange: Connects researchers with data on rare phenotypes or genotypes.\nReference Variation: Standardizes how genomes are described to improve interpretation and assembly.\nBenchmarking: Creates toolkits for evaluating variant calling in germline, cancer, and transcriptomic data.\nFile Formats: Develops and maintains standards such as CRAM, SAM/BAM, and VCF/BCF for efficient genomic data storage and processing.\n\n\n\nFile Format Standards\nGA4GH maintains file format standards through resources like the HTS Specifications repository (http://samtools.github.io/hts-specs/), which supports interoperability and efficient data management in genomics.\nAdditional Resources:\n1. File format tutorial - University of Connecticut\n2. UCSC Galaxy - Data file formats\n3. 12 Common Bioinformatics Files Types Explained (Youtube Video)"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html",
    "title": "File conversion",
    "section": "",
    "text": "In this section we are going to look at how to convert from one file format to another. There are many tools available for converting between file formats, and we will use some of the most common ones: samtools, bcftools and Picard."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#sam-to-bam",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#sam-to-bam",
    "title": "File conversion",
    "section": "SAM to BAM",
    "text": "SAM to BAM\nTo convert from SAM to BAM format we are going to use the samtools view command. In this instance, we would like to include the SAM header, so we use the -h option:\n\nsamtools view -h data/NA20538.bam &gt; data/NA20538.sam\n\nNow, have a look at the first ten lines of the SAM file. They should look like they did in the previous section when you viewed the BAM file header.\n\nhead data/NA20538.sam\n\nWell that was easy! And converting SAM to BAM is just as straightforward. This time there is no need for the -h option, however we have to tell samtools that we want the output in BAM format. We do so by adding the -b option:\n\nsamtools view -b data/NA20538.sam &gt; data/NA20538_2.bam\n\nSamtools is very well documented, so for more usage options and functions, have a look at the samtools manual http://www.htslib.org/doc/samtools-1.0.html."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#bam-to-cram",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#bam-to-cram",
    "title": "File conversion",
    "section": "BAM to CRAM",
    "text": "BAM to CRAM\nThe samtools view command can be used to convert a BAM file to CRAM format. In the data directory there is a BAM file called yeast.bam that was created from S. cerevisiae Illumina sequencing data. There is also a reference genome in the directory, called Saccharomyces_cerevisiae.EF4.68.dna.toplevel.fa. For the conversion, an index file (.fai) for the reference must be created. This can be done using samtools faidx. However, as we will see, samtools will generate this file on the fly when we specify a reference file using the -F option.\nTo convert to CRAM, we use the -C option to tell samtools we want the output as CRAM, and the -T option to specify what reference file to use for the conversion. We also use the -o option to specify the name of the output file. Give this a try:\n\nsamtools view -C -T data/Saccharomyces_cerevisiae.EF4.68.dna.toplevel.fa -o data/yeast.cram data/yeast.bam\n\nHave a look at what files were created:\n\nls -l data\n\nAs you can see, this has created an index file for the reference genome called Saccharomyces_cerevisiae.EF4.68.dna.toplevel.fa.fai and the CRAM file yeast.cram.\n\nExercises\nQ1: Since CRAM files use reference-based compression, we expect the CRAM file to be smaller than the BAM file. What is the size of the CRAM file?\nQ2: Is your CRAM file smaller than the original BAM file?\nTo convert CRAM back to BAM, simply change -C to -b and change places for the input and output CRAM/BAM:\nsamtools view -b -T data/Saccharomyces_cerevisiae.EF4.68.dna.toplevel.fa -o data/yeast.bam data/yeast.cram"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#fastq-to-sam",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#fastq-to-sam",
    "title": "File conversion",
    "section": "FASTQ to SAM",
    "text": "FASTQ to SAM\nSAM format is mainly used to store alignment data, however in some cases we may want to store the unaligned data in SAM format and for this we can use the picard tools FastqToSam application. Picard tools is a Java application that comes with a number of useful options for manipulating high-throughput sequencing data. .\nTo convert the FASTQ files of lane 13681_1#18 to unaligned SAM format, run:\n\npicard FastqToSam F1=data/13681_1#18_1.fastq.gz F2=data/13681_1#18_2.fastq.gz O=data/13681_1#18.sam SM=13681_1#18\n\nFrom here you can go on and convert the SAM file to BAM and CRAM, as described previously. There are also multiple options for specifying what metadata to include in the SAM header. To see all available options, run:\n\npicard FastqToSam -h"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#cram-to-fastq",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#cram-to-fastq",
    "title": "File conversion",
    "section": "CRAM to FASTQ",
    "text": "CRAM to FASTQ\nIt is possible to convert CRAM to FASTQ directly using the samtools fastq command. However, for many applications we need the fastq files to be ordered so that the order of the reads in the first file match the order of the reads in the mate file. For this reason, we first use samtools collate to produce a collated BAM file.\n\nsamtools collate data/yeast.cram data/yeast.collated\n\nThe newly produced BAM file will be called yeast.collated.bam. Let’s use this to create two FASTQ files, one for the forward reads and one for the reverse reads:\n\nsamtools fastq -1 data/yeast.collated_1.fastq -2 data/yeast.collated_2.fastq data/yeast.collated.bam\n\nFor further information and usage options, have a look at the samtools manual page (http://www.htslib.org/doc/samtools.html)."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#vcf-to-bcf",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#vcf-to-bcf",
    "title": "File conversion",
    "section": "VCF to BCF",
    "text": "VCF to BCF\nIn a similar way that samtools view can be used to convert between SAM, BAM and CRAM, bcftools view can be used to convert between VCF and BCF. To convert the file called 1kg.bcf to a compressed VCF file called 1kg.vcf.gz, run:\n\nbcftools view -O z -o data/1kg.vcf.gz data/1kg.bcf\n\nThe -O option allows us to specify in what format we want the output, compressed BCF (b), uncompressed BCF (u), compressed VCF (z) or uncompressed VCF (v). With the -o option we can select the name of the output file.\nHave a look at what files were generated (the options -lrt will list the files in reverse chronological order):\n\nls -lrt data\n\nThis also generated an index file, 1kg.bcf.csi.\nTo convert a VCF file to BCF, we can run a similar command. If we want to keep the original BCF, we need to give the new one a different name so that the old one is not overwritten:\n\nbcftools view -O b -o data/1kg_2.bcf data/1kg.vcf.gz\n\nCongratulations you have reached the end of the Data formats and QC tutorial!"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html",
    "title": "NGS Data formats and QC",
    "section": "",
    "text": "There are several file formats for storing Next Generation Sequencing (NGS) data. In this tutorial we will look at some of the most common formats for storing NGS reads and variant data. We will cover the following formats:\nFASTQ - This format stores unaligned read sequences with base qualities\nSAM/BAM - This format stores unaligned or aligned reads (text and binary formats)\nCRAM - This format is similar to BAM but has better compression than BAM\nVCF/BCF - Flexible variant call format for storing SNPs, indels, structural variations (text and binary formats)\nFollowing this, we will work through some examples of converting between the different formats.\nFurther to understanding the different file formats, it is important to remember that all sequencing platforms have technical limitations that can introduce biases in your sequencing data. Because of this it is very important to check the quality of the data before starting any analysis, whether you are planning to use something you have sequenced yourself or publicly available data. In the latter part of this tutorial we will describe how to perform a QC assessment for your NGS data."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#introduction",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#introduction",
    "title": "NGS Data formats and QC",
    "section": "",
    "text": "There are several file formats for storing Next Generation Sequencing (NGS) data. In this tutorial we will look at some of the most common formats for storing NGS reads and variant data. We will cover the following formats:\nFASTQ - This format stores unaligned read sequences with base qualities\nSAM/BAM - This format stores unaligned or aligned reads (text and binary formats)\nCRAM - This format is similar to BAM but has better compression than BAM\nVCF/BCF - Flexible variant call format for storing SNPs, indels, structural variations (text and binary formats)\nFollowing this, we will work through some examples of converting between the different formats.\nFurther to understanding the different file formats, it is important to remember that all sequencing platforms have technical limitations that can introduce biases in your sequencing data. Because of this it is very important to check the quality of the data before starting any analysis, whether you are planning to use something you have sequenced yourself or publicly available data. In the latter part of this tutorial we will describe how to perform a QC assessment for your NGS data."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#learning-outcomes",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#learning-outcomes",
    "title": "NGS Data formats and QC",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nOn completion of the tutorial, you can expect to be able to:\n\nDescribe the different NGS data formats available (FASTQ, SAM/BAM, CRAM, VCF/BCF)\nPerform a QC assessment of high throughput sequence data\nPerform conversions between the different data formats"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#tutorial-sections",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#tutorial-sections",
    "title": "NGS Data formats and QC",
    "section": "Tutorial sections",
    "text": "Tutorial sections\nThis tutorial comprises the following sections:\n1. Data formats\n2. QC assessment\nIf you have time you can also complete:\n\nFile conversion"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#authors",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#authors",
    "title": "NGS Data formats and QC",
    "section": "Authors",
    "text": "Authors\nThis tutorial was written by Jacqui Keane and Sara Sjunnebo based on material from Petr Danecek and Thomas Keane."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#running-the-commands-from-this-tutorial",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#running-the-commands-from-this-tutorial",
    "title": "NGS Data formats and QC",
    "section": "Running the commands from this tutorial",
    "text": "Running the commands from this tutorial\nYou can follow this tutorial by typing all the commands you see into a terminal window. This is similar to the “Command Prompt” window on MS Windows systems, which allows the user to type DOS commands to manage files.\nTo get started, open a new terminal on your computer and type the command below:\n\ncd ~/course_data/data_formats/\n\nNow you can follow the instructions in the tutorial from here."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#lets-get-started",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#lets-get-started",
    "title": "NGS Data formats and QC",
    "section": "Let’s get started!",
    "text": "Let’s get started!\nThis tutorial assumes that you have samtools, bcftools and Picard tools installed on your computer. These are already installed on the VM you are using. To check that these are installed, you can run the following commands:\n\nsamtools --help\n\n\nbcftools --help\n\n\npicard -h\n\nThis should return the help message for samtools, bcftools and picard tools respectively.\nTo get started with the tutorial, go to the first section: Data formats"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html",
    "title": "QC assessment of NGS data",
    "section": "",
    "text": "QC is an important part of any analysis. In this section we are going to look at some of the metrics and graphs that can be used to assess the QC of NGS data."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#base-quality",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#base-quality",
    "title": "QC assessment of NGS data",
    "section": "Base quality",
    "text": "Base quality\nIllumina sequencing technology relies on sequencing by synthesis. One of the most common problems with this is dephasing. For each sequencing cycle, there is a possibility that the replication machinery slips and either incorporates more than one nucleotide or perhaps misses to incorporate one at all. The more cycles that are run (i.e. the longer the read length gets), the greater the accumulation of these types of errors gets. This leads to a heterogeneous population in the cluster, and a decreased signal purity, which in turn reduces the precision of the base calling. The figure below shows an example of this.\n\n\n\nMean Base Quality\n\n\nBecause of dephasing, it is possible to have high-quality data at the beginning of the read but really low-quality data towards the end of the read. In those cases you can decide to trim off the low-quality reads, for example using a tool called Trimmomatic.\nThe figures below shows an example of a good sequencing run (left) and a poor sequencing run (right).\n\n\n\nBase quality"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#other-base-calling-errors",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#other-base-calling-errors",
    "title": "QC assessment of NGS data",
    "section": "Other base calling errors",
    "text": "Other base calling errors\nThere are several different reasons for a base to be called incorrectly, as shown in the figure below. Phasing noise and signal decay is a result of the dephasing issue described above. During library preparation, mixed clusters can occur if multiple templates get co-located. These clusters should be removed from the downstream analysis. Boundary effects occur due to optical effects when the intensity is uneven across each tile, resulting in higher intensity found toward the center. Cross-talk occurs because the emission frequency spectra for each of the four base dyes partly overlap, creating uncertainty. Finally, for previous sequencing cycle methods T fluorophore accumulation was an issue, where incomplete removal of the dye coupled to thymine lead to an ambient accumulation the nucleotides, causing a false high Thymine trend.\n\n\n\nBase Calling Errors\n\n\nBase-calling for next-generation sequencing platforms, doi: 10.1093/bib/bbq077"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#mismatches-per-cycle",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#mismatches-per-cycle",
    "title": "QC assessment of NGS data",
    "section": "Mismatches per cycle",
    "text": "Mismatches per cycle\nAligning reads to a high-quality reference genome can provide insight to the quality of a sequencing run by showing you the mismatches to the reference sequence. This can help you detect cycle-specific errors. Mismatches can occur due to two main causes, sequencing errors and differences between your sample and the reference genome, which is important to bear in mind when interpreting mismatch graphs. The figure below shows an example of a good run (left) and a bad one (right). In the graph on the left, the distribution of the number of mismatches is even between the cycles, which is what we would expect from a good run. However, in the graph on the right, two cycles stand out with a lot of mismatches compared to the other cycles.\n\n\n\nMismatches per cycle"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#gc-content",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#gc-content",
    "title": "QC assessment of NGS data",
    "section": "GC content",
    "text": "GC content\nIt is a good idea to compare the GC content of the reads against the expected distribution in a reference sequence. The GC content varies between species, so a shift in GC content like the one seen below could be an indication of sample contamination. In the left graph below, we can see that the GC content of the sample is about the same as for the reference, at ~38%. However, in the right graph, the GC content of the sample is closer to 55%, indicating that there is an issue with this sample.\n\n\n\nGC Content"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#gc-content-by-cycle",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#gc-content-by-cycle",
    "title": "QC assessment of NGS data",
    "section": "GC content by cycle",
    "text": "GC content by cycle\nLooking at the GC content per cycle can help detect if the adapter sequence was trimmed. For a random library, it is expected to be little to no difference between the different bases of a sequence run, so the lines in this plot should be parallel with each other like in the graph on the left below. In the graph on the right, the initial spikes are likely due to adapter sequences that have not been removed.\n\n\n\nGC content by cycle"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#fragment-size",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#fragment-size",
    "title": "QC assessment of NGS data",
    "section": "Fragment size",
    "text": "Fragment size\nFor paired-end sequencing the size of DNA fragments also matters. In the first of the examples below, the fragment size peaks around 440 bp. In the second however, there is also a peak at around 200 bp. This indicates that there was an issue with the fragment size selection during library prep.\n\n\n\nFragment size distribution\n\n\n\nExercises\nQ1: The figure below is from a 100bp paired-end sequencing. Can you spot any problems?\n\n\n\nQ1 Insert size distribution"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#insertionsdeletions-per-cycle",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#insertionsdeletions-per-cycle",
    "title": "QC assessment of NGS data",
    "section": "Insertions/Deletions per cycle",
    "text": "Insertions/Deletions per cycle\nSometimes, air bubbles occur in the flow cell, which can manifest as false indels. The spike in the right image provides an example of how this can look.\n\n\n\nIndels per cycle"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#generating-qc-stats",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#generating-qc-stats",
    "title": "QC assessment of NGS data",
    "section": "Generating QC stats",
    "text": "Generating QC stats\nNow let’s try this out! We will generate QC stats for two lanes of Illumina paired-end sequencing data from yeast. The reads have already been aligned to the Saccromyces cerevisiae reference genome to produce the BAM file lane1.sorted.bam.\nNow we will use samtools stats to generate the stats for the primary alignments. The option -f can be used to filter reads with specific tags, while -F can be used to filter out reads with specific tags. The following command will include only primary alignments:\n\nsamtools stats -F SECONDARY data/lane1.sorted.bam &gt; data/lane1.sorted.bam.bchk\n\nHave a look at the first 47 lines of the statistics file that was generated:\n\nhead -n 47 data/lane1.sorted.bam.bchk\n\nThis file contains a number of useful stats that we can use to get a better picture of our data, and it can even be plotted with plot-bamstats, as you will see soon. First let’s have a closer look at some of the different stats. Each part of the file starts with a # followed by a description of the section and how to extract it from the file. Let’s have a look at all the sections in the file:\n\ngrep ^'#' data/lane1.sorted.bam.bchk | grep 'Use'\n\n\nSummary Numbers (SN)\nThis initial section contains a summary of the alignment and includes some general statistics. In particular, you can see how many bases mapped, and how much of the genome that was covered.\n\n\nExercises\nNow look at the output and try to answer the questions below.\nQ2: What is the total number of reads?\nQ3: What proportion of the reads were mapped?\nQ4: How many pairs were mapped to a different chromosome?\nQ5: What is the insert size mean and standard deviation?\nQ6: How many reads were paired properly?\n\n\nGenerating QC plots\nFinally, we will create some QC plots from the output of the stats command using the command plot-bamstats which is included in the samtools package:\n\nplot-bamstats -p data/lane1-plots/ data/lane1.sorted.bam.bchk\n\nNow in your web browser open the file lane1-plots/index.html to view the QC information.\nQ7: How many reads have zero mapping quality?\nQ8: Which read (forward/reverse) of the first fragments and second fragments are higher base quality on average?\nNow continue to the next section of the tutorial: File conversion."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html",
    "title": "Data formats for NGS data",
    "section": "",
    "text": "Here we will take a closer look at some of the most common NGS data formats. First, check you are in the correct directory.\npwd\nIt should display something like:\n/home/manager/course_data/data_formats/"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#fasta",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#fasta",
    "title": "Data formats for NGS data",
    "section": "FASTA",
    "text": "FASTA\nThe FASTA format is used to store both nucleotide data and protein sequences. Each sequence in a FASTA file is represented by two parts, a header line and the actual sequence. The header always starts with the symbol “&gt;” and is followed by information about the sequence, such as a unique identifier. The following lines show two sequences represented in FASTA format:\n&gt;Sequence_1\nCTTGACGACTTGAAAAATGACGAAATCACTAAAAAACGTGAAAAATGAGAAATG\nAAAATGACGAAATCACTAAAAAACGTGACGACTTGAAAAATGACCAC\n&gt;Sequence_2\nCTTGAGACGAAATCACTAAAAAACGTGACGACTTGAAGTGAAAAATGAGAAATG\nAAATCATGACGACTTGAAGTGAAAAAGTGAAAAATGAGAAATGAACGTGACGAC\nAAAATGACGAAATCATGACGACTTGAAGTGAAAAATAAATGACC\n\nExercises\nQ1: How many sequences are there in the fasta file data/example.fasta? (Hint: is there a grep option you can use?)"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#fastq",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#fastq",
    "title": "Data formats for NGS data",
    "section": "FASTQ",
    "text": "FASTQ\nFASTQ is a data format for sequencing reads. It is an extension to the FASTA file format, and includes a quality score for each base. Have a look at the example below, containing two reads:\n@ERR007731.739 IL16_2979:6:1:9:1684/1\nCTTGACGACTTGAAAAATGACGAAATCACTAAAAAACGTGAAAAATGAGAAATG\n+\nBBCBCBBBBBBBABBABBBBBBBABBBBBBBBBBBBBBABAAAABBBBB=@&gt;B\n@ERR007731.740 IL16_2979:6:1:9:1419/1\nAAAAAAAAAGATGTCATCAGCACATCAGAAAAGAAGGCAACTTTAAAACTTTTC\n+\nBBABBBABABAABABABBABBBAAA&gt;@B@BBAA@4AAA&gt;.&gt;BAA@779:AAA@A\nWe can see that for each read we get four lines:\n\nThe read metadata, such as the read ID. Starts with @ and, for paired-end Illumina reads, is terminated with /1 or /2 to show that the read is the member of a pair.\nThe read\nStarts with + and optionally contains the ID again\nThe per base Phred quality score\n\nThe quality scores range (in theory) from 1 to 94 and are encoded as ASCII characters. The first 32 ASCII codes are reserved for control characters which are not printable, and the 33rd is reserved for space. Neither of these can be used in the quality string, so we need to subtract 33 from whatever the value of the quality character is. For example, the ASCII code of “A” is 65, so the corresponding quality is:\nQ = 65 - 33 = 32\nThe Phred quality score Q relates to the base-calling error probability P as\n       P = 10-Q/10\nThe Phred quality score is a measure of the quality of base calls. For example, a base assigned with a Phred quality score of 30 tells us that there is a 1 in 1000 chance that this base was called incorrectly.\n\n\n\n\n\n\n\n\nPhred Quality Score\nProbability of incorrect base call\nBase call accuracy\n\n\n\n\n10\n1 in 10\n90%\n\n\n20\n1 in 100\n99%\n\n\n30\n1 in 1000\n99.9%\n\n\n40\n1 in 10,000\n99.99%\n\n\n50\n1 in 100,000\n99.999%\n\n\n60\n1 in 1,000,000\n99.9999%\n\n\n\n\nExercises\nQ2: How many reads are there in the file example.fastq? (Hint: remember that @ is a possible quality score. Is there something else in the header that is unique?)"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#sam",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#sam",
    "title": "Data formats for NGS data",
    "section": "SAM",
    "text": "SAM\nSAM (Sequence Alignment/Map) format is a unified format for storing read alignments to a reference genome. It is a standard format for storing NGS sequencing reads, base qualities, associated meta-data and alignments of the data to a reference genome. If no reference genome is available, the data can also be stored unaligned.\nThe files consist of a header section (optional) and an alignment section. The alignment section contains one record (a single DNA fragment alignment) per line describing the alignment between fragment and reference. Each record has 11 fixed columns and optional key:type:value tuples. Open the SAM/BAM file specification document https://samtools.github.io/hts-specs/SAMv1.pdf either in a web browser or you can find a copy in the QC directory as you may need to refer to it throughout this tutorial.\nNow let us have a closer look at the different parts of the SAM/BAM format.\n\nHeader Section\nThe header section of a SAM file looks like:\n@HD VN:1.0  SO:coordinate\n@SQ SN:test_ref LN:17637\n@RG ID:ERR003612 PL:ILLUMINA LB:g1k-sc-NA20538-TOS-1 PI:2000 DS:SRP000540 SM:NA20538 CN:SC\nEach line in the SAM header begins with an @, followed by a two-letter header record type code as defined in the SAM/BAM format specification document. Each record type can contain meta-data captured as a series of key-value pairs in the format of ‘TAG:VALUE’.\n\nRead groups\nOne useful record type is RG which can be used to describe each lane of sequencing. The RG code can be used to capture extra meta-data for the sequencing lane. Some common RG TAGs are:\n\nID: SRR/ERR number\nPL: Sequencing platform\nPU: Run name\nLB: Library name\nPI: Insert fragment size\nSM: Individual/Sample\nCN: Sequencing centre\n\nWhile most of these are self explanitory, insert fragment size may occasionally be negative. This simply indicates that the reads found are overlapping while its size is less than 2 x read length.\n\n\n\nExercises\nLook at the following line from the header of a SAM file and answering the questions that follow:\n@RG ID:ERR003612 PL:ILLUMINA LB:g1k-sc-NA20538-TOS-1 PI:2000 DS:SRP000540 SM:NA20538 CN:SC\nQ3: What does RG stand for?\nQ4: What is the sequencing platform?\nQ5: What is the sequencing centre?\nQ6: What is the lane identifier?\nQ7: What is the expected fragment insert size?\n\n\nAlignment Section\nThe alignment section of SAM files contains one line per read alignment, an example is\nERR005816.1408831 163 Chr1    19999970    23  40M5D30M2I28M   =   20000147    213 GGTGGGTGGATCACCTGAGATCGGGAGTTTGAGACTAGGTGG...    &lt;=@A@??@=@A@A&gt;@BAA@ABA:&gt;@&lt;&gt;=BBB9@@2B3&lt;=@A@...\nEach of the lines are composed of multiple columns listed below. The first 11 columns are mandatory.\n\nQNAME: Query NAME of the read or the read pair i.e. DNA sequence\nFLAG: Bitwise FLAG (pairing, strand, mate strand, etc.)\nRNAME: Reference sequence NAME\nPOS: 1-Based leftmost POSition of clipped alignment\nMAPQ: MAPping Quality (Phred-scaled)\nCIGAR: Extended CIGAR string (operations: MIDNSHPX=)\nMRNM: Mate Reference NaMe (’=’ if same as RNAME)\nMPOS: 1-Based leftmost Mate POSition\nISIZE: Inferred Insert SIZE\nSEQ: Query SEQuence on the same strand as the reference\nQUAL: Query QUALity (ASCII-33=Phred base quality)\nOTHER: Optional fields\n\nThe image below provides a visual guide to some of the columns of the SAM format.\n\n\n\nSAM format\n\n\n\n\nExercises\nLet’s have a look at example.sam. Notice that we can use the standard UNIX operations like cat on this file.\n\ncat data/example.sam\n\nQ8: What is the mapping quality of ERR003762.5016205? (Hint: can you use grep and awk to find this?)\nQ9: What is the CIGAR string for ERR003814.6979522? (Hint: we will go through the meaning of CIGAR strings in the next section)\nQ10: What is the inferred insert size of ERR003814.1408899?\n\n\nCIGAR string\nColumn 6 of the alignment is the CIGAR string for that alignment. The CIGAR string provides a compact representation of sequence alignment. Have a look at the table below. It contains the meaning of all different symbols of a CIGAR string:\n\n\n\nSymbol\nMeaning\n\n\n\n\nM\nalignment match or mismatch\n\n\n=\nsequence match\n\n\nX\nsequence mismatch\n\n\nI\ninsertion into the read (sample sequenced)\n\n\nD\ndeletion from the read (sample sequenced)\n\n\nS\nsoft clipping (clipped sequences present in SEQ)\n\n\nH\nhard clipping (clipped sequences NOT present in SEQ)\n\n\nN\nskipped region from the reference\n\n\nP\npadding (silent deletion from padded reference)\n\n\n\nBelow are two examples describing the CIGAR string in more detail.\nExample 1:\nRef:     ACGTACGTACGTACGT\nRead:  ACGT- - - - ACGTACGA\nCigar: 4M 4D 8M\nThe first four bases in the read are the same as in the reference, so we can represent these as 4M in the CIGAR string. Next comes 4 deletions, represented by 4D, followed by 7 alignment matches and one alignment mismatch, represented by 8M. Note that the mismatch at position 16 is included in 8M. This is because it still aligns to the reference.\nExample 2:\nRef:     ACTCAGTG- - GT\nRead:  ACGCA- TGCAGTtagacgt\nCigar: 5M 1D 2M 2I 2M 7S\nHere we start off with 5 alignment matches and mismatches, followed by one deletion. Then we have two more alignment matches, two insertions and two more matches. At the end, we have seven soft clippings, 7S. These are clipped sequences that are present in the SEQ (Query SEQuence on the same strand as the reference).\n\n\nExercises\nQ11: What does the CIGAR from Q9 mean?\nQ12: How would you represent the following alignment with a CIGAR string?\nRef:     ACGT- - - - ACGTACGT\nRead:  ACGTACGTACGTACGT\n\n\nFlags\nColumn 2 of the alignment contains a combination of bitwise FLAGs describing the alignment. The following table contains the information you can get from the bitwise FLAGs:\n\n\n\n\n\n\n\n\n\nHex\nDec\nFlag\nDescription\n\n\n\n\n0x1\n1\nPAIRED\npaired-end (or multiple-segment) sequencing technology\n\n\n0x2\n2\nPROPER_PAIR\neach segment properly aligned according to the aligner\n\n\n0x4\n4\nUNMAP\nsegment unmapped\n\n\n0x8\n8\nMUNMAP\nnext segment in the template unmapped\n\n\n0x10\n16\nREVERSE\nSEQ is reverse complemented\n\n\n0x20\n32\nMREVERSE\nSEQ of the next segment in the template is reversed\n\n\n0x40\n64\nREAD1\nthe first segment in the template\n\n\n0x80\n128\nREAD2\nthe last segment in the template\n\n\n0x100\n256\nSECONDARY\nsecondary alignment\n\n\n0x200\n512\nQCFAIL\nnot passing quality controls\n\n\n0x400\n1024\nDUP\nPCR or optical duplicate\n\n\n0x800\n2048\nSUPPLEMENTARY\nsupplementary alignment\n\n\n\nFor example, if you have an alignment with FLAG set to 113, this can only be represented by decimal codes 64 + 32 + 16 + 1, so we know that these four flags apply to the alignment and the alignment is paired-end, reverse complemented, sequence of the next template/mate of the read is reversed and the read aligned is the first segment in the template.\n\nPrimary, secondary and supplementary alignments\nA read that aligns to a single reference sequence (including insertions, deletions, skips and clipping but not direction changes), is a linear alignment. If a read cannot be represented as a linear alignment, but instead is represented as a group of linear alignments without large overlaps, it is called a chimeric alignment. These can for instance be caused by structural variations. Usually, one of the linear alignments in a chimeric alignment is considered to be the representative alignment, and the others are called supplementary.\nSometimes a read maps equally well to more than one spot. In these cases, one of the possible alignments is marked as the primary alignment and the rest are marked as secondary alignments."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#bam",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#bam",
    "title": "Data formats for NGS data",
    "section": "BAM",
    "text": "BAM\nBAM (Binary Alignment/Map) format, is a compressed binary version of SAM. This means that, while SAM is human readable, BAM is only readable for computers. BAM files can be viewed using samtools, and will then have the same format as a SAM file. The key features of BAM are:\n\nCan store alignments from most mappers\nSupports multiple sequencing technologies\nSupports indexing for quick retrieval/viewing\nCompact size (e.g. 112Gbp Illumina = 116GB disk space)\nReads can be grouped into logical groups e.g. lanes, libraries, samples\nWidely supported by variant calling packages and viewers\n\nSince BAM is a binary format, we can’t use the standard UNIX operations directly on this file format. Samtools is a set of programs for interacting with SAM and BAM files. Using the samtools view command, print the header of the BAM file:\n\nsamtools view -H data/NA20538.bam\n\n\nExercises\nQ13: What version of the human assembly was used to perform the alignments? (Hint: Can you spot this somewhere in the @SQ records?)\nQ14: How many lanes are in this BAM file? (Hint: Do you recall what RG represents?)\nQ15: What programs were used to create this BAM file? (Hint: have a look for the program record, @PG)\nQ16: What version of bwa was used to align the reads? (Hint: is there anything in the @PG record that looks like it could be a version tag?)\nThe output from running samtools view on a BAM file without any options is a headerless SAM file. This gets printed to STDOUT in the terminal, so we will want to pipe it to something. Let’s have a look at the first read of the BAM file:\n\nsamtools view data/NA20538.bam | head -n 1\n\nQ17: What is the name of the first read? (Hint: have a look at the alignment section if you can’t recall the different fields)\nQ18: What position does the alignment of the read start at?"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#cram",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#cram",
    "title": "Data formats for NGS data",
    "section": "CRAM",
    "text": "CRAM\nEven though BAM files are compressed, they are still very large. Typically they use 1.5-2 bytes for each base pair of sequencing data that they contain, and while disk capacity is ever improving, increases in disk capacity are being far outstripped by sequencing technologies.\nBAM stores all of the data, this includes every read base, every base quality, and it uses a single conventional compression technique for all types of data. CRAM was designed for better compression of genomic data than SAM/BAM. CRAM uses three important concepts:\n\nReference based compression\nControlled loss of quality information\nDifferent compression methods to suit the type of data, e.g. base qualities vs. metadata vs. extra tags\n\nThe figure below displays how reference-based compression works. Instead of saving all the bases of all the reads, only the nucleotides that differ from the reference, and their positions, are kept.\n\n\nIn lossless (no information is lost) mode a CRAM file is 60% of the size of a BAM file, so archives and sequencing centres have moved from BAM to CRAM.\nSince samtools 1.3, CRAM files can be read in the same way that BAM files can. We will look closer at how you can convert between SAM, BAM and CRAM formats in the next section."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#indexing",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#indexing",
    "title": "Data formats for NGS data",
    "section": "Indexing",
    "text": "Indexing\nTo allow for fast random access of regions in BAM and CRAM files, they can be indexed. The files must first be coordinate-sorted rather that sorted by read name. This can be done using samtools sort. If no options are supplied, it will by default sort by the left-most position of the reference.\n\nsamtools sort -o data/NA20538_sorted.bam data/NA20538.bam\n\nNow we can use samtools index to create an index file (.bai) for our sorted BAM file:\n\nsamtools index data/NA20538_sorted.bam\n\nTo look for reads mapped to a specific region, we can use samtools view and specify the region we are interested in as: RNAME[:STARTPOS[-ENDPOS]]. For example, to look at all the reads mapped to a region called chr4, we could use:\nsamtools view alignment.bam chr4\nTo look at the region on chr4 beginning at position 1,000,000 and ending at the end of the chromosome, we can do:\nsamtools view alignment.bam chr4:1000000\nAnd to explore the 1001bp long region on chr4 beginning at position 1,000 and ending at position 2,000, we can use:\nsamtools view alignment.bam chr4:1000-2000\n\nExercises\nQ19: How many reads are mapped to region 20025000-20030000 on chromosome 1?"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#vcf",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#vcf",
    "title": "Data formats for NGS data",
    "section": "VCF",
    "text": "VCF\nThe VCF file format was introduced to store variation data. VCF consists of tab-delimited text and is parsable by standard UNIX commands which makes it flexible and user-extensible. The figure below provides an overview of the different components of a VCF file:\n\n\n\nVCF format\n\n\n\nVCF header\nThe VCF header consists of meta-information lines (starting with ##) and a header line (starting with #). All meta-information lines are optional and can be put in any order, except for fileformat. This holds the information about which version of VCF is used and must come first.\nThe meta-information lines consist of key=value pairs. Examples of meta-information lines that can be included are ##INFO, ##FORMAT and ##reference. The values can consist of multiple fields enclosed by &lt;&gt;. More information about these fields is available in the VCF specification http://samtools.github.io/hts-specs/VCFv4.3.pdf. This can be accessed using a web browser and there is a copy in the QC directory.\n\nHeader line\nThe header line starts with # and consists of 8 required fields:\n\nCHROM: an identifier from the reference genome\nPOS: the reference position\nID: a list of unique identifiers (where available)\nREF: the reference base(s)\nALT: the alternate base(s)\nQUAL: a phred-scaled quality score\nFILTER: filter status\nINFO: additional information\n\nIf the file contains genotype data, the required fields are also followed by a FORMAT column header, and then a number of sample IDs. The FORMAT field specifies the data types and order. Some examples of these data types are:\n\nGT: Genotype, encoded as allele values separated by either / or |\nDP: Read depth at this position for this sample\nGQ: Conditional genotype quality, encoded as a phred quality\n\n\n\n\nBody\nIn the body of the VCF, each row contains information about a position in the genome along with genotype information on samples for each position, all according to the fields in the header line."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#bcf",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#bcf",
    "title": "Data formats for NGS data",
    "section": "BCF",
    "text": "BCF\nBCF is a compressed binary representation of VCF.\nVCF can be compressed with BGZF (bgzip) and indexed with TBI or CSI (tabix), but even compressed it can still be very big. For example, a compressed VCF with 3781 samples of human data will be 54 GB for chromosome 1, and 680 GB for the whole genome. VCFs can also be slow to parse, as text conversion is slow. The main bottleneck is the “FORMAT” fields. For this reason the BCF format was developed.\nIn BCF files the fields are rearranged for fast access. The following images show the process of converting a VCF file into a BCF file.\n\n\nBcftools comprises a set of programs for interacting with VCF and BCF files. It can be used to convert between VCF and BCF and to view or extract records from a region.\n\nbcftools view\nLet’s have a look at the header of the file 1kg.bcf in the data directory. Note that bcftools uses -h to print only the header, while samtools uses -H for this.\n\nbcftools view -h data/1kg.bcf\n\nSimilarly to BAM, BCF supports random access, that is, fast retrieval from a given region. For this, the file must be indexed:\n\nbcftools index data/1kg.bcf\n\nNow we can extract all records from the region 20:24042765-24043073, using the -r option. The -H option will make sure we don’t include the header in the output:\n\nbcftools view -H -r 20:24042765-24043073 data/1kg.bcf\n\n\n\nbcftools query\nThe versatile bcftools query command can be used to extract any VCF field. Combined with standard UNIX commands, this gives a powerful tool for quick querying of VCFs. Have a look at the usage options:\n\nbcftools query -h\n\nLet’s try out some useful options. As you can see from the usage, -l will print a list of all the samples in the file. Give this a go:\n\nbcftools query -l data/1kg.bcf\n\nAnother very useful option is -s which allows you to extract all the data relating to a particular sample. This is a common option meaning it can be used for many bcftools commands, like bcftools view. Try this for sample HG00131:\n\nbcftools view -s HG00131 data/1kg.bcf | head -n 50\n\nThe format option, -f can be used to select what gets printed from your query command. For example, the following will print the position, reference base and alternate base for sample HG00131, separated by tabs:\n\nbcftools query -f'%POS\\t%REF\\t%ALT\\n' -s HG00131 data/1kg.bcf | head\n\nFinally, let’s look at the -i option. With this option we can select only sites for which a particular expression is true. For instance, if we only want to look at sites that have at least 2 alternate alleles across all samples, we can use the following expression (piped to head to only show a subset of the output):\n\nbcftools query -f'%CHROM\\t%POS\\n' -i 'AC[0]&gt;2' data/1kg.bcf | head\n\nWe use -i with the expression AC[0]&gt;2. AC is an info field that holds the __a__llele __c__ount. Some fields can hold multiple values, so we use AC[0]&gt;2 to indicate that we are looking for the first value (this is zero indexed, and hence starts at 0 instead of 1), and that this value should be &gt; 2. To format our output, we use -f to specify that we want to print the chromosome name and position.\nThere is more information about expressions on the bcftools manual page http://samtools.github.io/bcftools/bcftools.html#expressions\n\n\nExercises\nNow, try and answer the following questions about the file 1kg.bcf in the data directory. For more information about the different usage options you can open the bcftools query manual page http://samtools.github.io/bcftools/bcftools.html#query in a web browser.\nQ20: What version of the human assembly do the coordinates refer to?\nQ21: How many samples are there in the BCF?\nQ22: What is the genotype of the sample HG00107 at the position 20:24019472? (Hint: use the combination of -r, -s, and -f options)\nQ23: How many positions are there with more than 10 alternate alleles? (Hint: use the -i filtering option)\nQ24: In how many positions does HG00107 have a non-reference genotype and a read depth bigger than 10? (Hint: you can use pipes to combine bcftools queries)"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#gvcf",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#gvcf",
    "title": "Data formats for NGS data",
    "section": "gVCF",
    "text": "gVCF\nOften it is not enough to know variant sites only. For instance, we don’t know if a site was dropped because it matches the reference or because the data is missing. We sometimes need evidence for both variant and non-variant positions in the genome. In gVCF format, blocks of reference-only sites can be represented in a single record using the “INFO/END” tag. Symbolic alleles (&lt;*&gt;) are used for incremental calling:\n\n\n\ngVCF\n\n\n\nExercises\nQ25: In the above example, what is the size of the reference-only block starting at position 9923?\nQ26: For the same block, what is the first base?\nQ27: How many reference reads does the block have?\nNow continue to the next section of the tutorial: QC assessment of NGS data."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html",
    "title": "Identifying contamination",
    "section": "",
    "text": "It is always a good idea to check that your data is from the species you expect it to be. A very useful tool for this is Kraken. In this tutorial we will go through how you can use Kraken to check your samples for contamination.\nNote if using the Sanger cluster: Kraken is run as part of the automatic qc pipeline and you can retreive the results using the pf qc script. For more information, run pf man qc."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#setting-up-a-database",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#setting-up-a-database",
    "title": "Identifying contamination",
    "section": "Setting up a database",
    "text": "Setting up a database\nTo run Kraken you need to either build a database or download an existing one. The standard database is very large (33 GB), but thankfully there are some smaller, pre-built databased available. To download the smallest of them, the 4 GB MiniKraken. If you don’t already have a kraken database set up, run:\n\nwget https://ccb.jhu.edu/software/kra\\\n    ken/dl/minikraken_20171019_4GB.tgz\n\nThen all you need to do is un-tar it:\n\ntar -zxvf minikraken_20171019_4GB.tgz\n\nThis version of the database is constructed from complete bacterial, archaeal, and viral genomes in RefSeq, however it contains only around 3 percent of the kmers from the original kraken database (more information here). If the pre-packaged databases are not quite what you are looking for, you can create your own customized database instead. Details about this can be found here.\nNote if using the Sanger cluster: There are several pre-built databases available centrally on the Sanger cluster. For more information, please contact the Pathogen Informatics team."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#running-kraken",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#running-kraken",
    "title": "Identifying contamination",
    "section": "Running Kraken",
    "text": "Running Kraken\nTo run Kraken, you need to provide the path to the database you just created. By default, the input files are assumed to be in FASTA format, so in this case we also need to tell Kraken that our input files are in FASTQ format, gzipped, and that they are paired end reads:\n\nkraken --db ./minikraken_20171013_4GB --output kraken_results \\\n    --fastq-input --gzip-compressed --paired \\\n    data/13681_1#18_1.fastq.gz data/13681_1#18_2.fastq.gz\n\nThe five columns in the file that’s generated are:\n\n“C”/“U”: one letter code indicating that the sequence was either classified or unclassified.\nThe sequence ID, obtained from the FASTA/FASTQ header.\nThe taxonomy ID Kraken used to label the sequence; this is 0 if the sequence is unclassified.\nThe length of the sequence in bp.\nA space-delimited list indicating the LCA mapping of each k-mer in the sequence.\n\nTo get a better overview you can create a kraken report:\n\nkraken-report --db ./minikraken_20171013_4GB \\\n    kraken_results &gt; kraken-report"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#looking-at-the-results",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#looking-at-the-results",
    "title": "Identifying contamination",
    "section": "Looking at the results",
    "text": "Looking at the results\nLet’s have a closer look at the kraken_report for the sample. If for some reason your kraken-run failed there is a prebaked kraken-report at data/kraken-report\n\nhead -n 20 kraken-report\n\nThe six columns in this file are:\n\nPercentage of reads covered by the clade rooted at this taxon\nNumber of reads covered by the clade rooted at this taxon\nNumber of reads assigned directly to this taxon\nA rank code, indicating (U)nclassified, (D)omain, (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, or (S)pecies. All other ranks are simply ‘-’.\nNCBI taxonomy ID\nScientific name"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#exercises",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#exercises",
    "title": "Identifying contamination",
    "section": "Exercises",
    "text": "Exercises\nQ1: What is the most prevalent species in this sample?\nQ2: Are there clear signs of contamination?\nQ3: What percentage of reads could not be classified?"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#heterozygous-snps",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#heterozygous-snps",
    "title": "Identifying contamination",
    "section": "Heterozygous SNPs",
    "text": "Heterozygous SNPs\nFor bacteria, another thing that you can look at to detect contamination is if there are heterozygous SNPs in your samples. Simply put, if you align your reads to a reference, you would expect any snps to be homozygous, i.e. if one read differs from the reference genome, then the rest of the reads that map to that same location will also do so:\nHomozygous SNP\nRef:       CTTGAGACGAAATCACTAAAAAACGTGACGACTTG\nRead1:  CTTGAGtCG\nRead2:  CTTGAGtCGAAA\nRead3:         GAGtCGAAATCACTAAAA\nRead4:               GtCGAAATCA\nBut if there is contamination, this may not be the case. In the example below, half of the mapped reads have the T allele and half have the A.\nHeterozygous SNP\nRef:       CTTGAGACGAAATCACTAAAAAACGTGACGACTTG\nRead1:  CTTGAGtCG\nRead2:  CTTGAGaCGAAA\nRead3:         GAGaCGAAATCACTAAAA\nRead4:               GtCGAAATCA\nNote if using the Sanger cluster: Heterozygous SNPs are calculated as part of the automated QC pipeline. The result for each lane is available in the file heterozygous_snps_report.txt.\nCongratulations! You have reached the end of this tutorial. You can find the answers to all the questions of the tutorial here.\nTo revisit the previous section click here. Alternatively you can head back to the index page"
  },
  {
    "objectID": "course_modules/Module2/module2.html",
    "href": "course_modules/Module2/module2.html",
    "title": "Overview",
    "section": "",
    "text": "Content by\n\nDuration\n4 hours\n\n\nKey topics\nIn this module, learners will look at:\n\nRead alignment theory and tools\nChallenges in alignment and quality assessment\nData processing and scalability\n\n\n\nActivities\n\nLecture: 1h\nPractical exercises: 2.5h\nQuiz: 0.5h\n\n\n\nManual\nModule manual\n\n\nPresentation slides\n(PPT/PDF, to be generated from the module manual)\n\n\nLecture notes or scripts\nPre-recorded lecture\n\n\nPractical exercises\nVirtual machine\n\n\nDatasets"
  },
  {
    "objectID": "course_modules/Module2/module2_manual.html",
    "href": "course_modules/Module2/module2_manual.html",
    "title": "Manual",
    "section": "",
    "text": "Sequence alignment in NGS is the process of determining the most likely source of the observed DNA sequencing read within the reference genome sequence.\n\n\n\n1.2 Why align?\nThere are typical inferences you can make from an alignment of NGS data against a reference genome:\n• Variation from the reference – could have functional consequence.\n• Transcript abundance: Instead of a microarray, you could use alignment to genome to quantify expression: more sensitive\n• Ab-initio transcript discovery: you can see a pileup from RNA seq data showing evidence for an exon which was previously missed or an exon which is being skipped in a transcript.\n\n\n\n 1.2 Learning outcomes\nOn completion of the tutorial, you can expect to be able to:\n• Perform read alignment using standard tools (BWA-MEM)\n• Perform the following task and understand their effect on analysis results\n– Mark Duplicates\n• Visualise read alignments using IGV (Integrated Visualisation Tool)\nIf there is time you will learn how to:\n• Merge the results from multiple alignments and understand when it is appropriate to perform a merge\n\n\n\nThis tutorial comprises the following sections:\n1. Performing read alignment\n2. Alignment visualisation\nThere is also an additional (optional) section: 3. Alignment workflows\n\n\n\nThis tutorial was written by Jacqui Keane based on material from Thomas Keane, Vivek Iyer and Victoria Offord.\n\n\n\nYou can follow this tutorial by typing all the commands you see into a terminal window. This is similar to the “Command Prompt” window on MS Windows systems, which allows the user to type DOS commands to manage files.\nTo get started, open a new terminal on your computer and type the command below:\ncd /home/manager/course_data/read_alignment Now you can follow the instructions in the tutorial from here.\n\n\n\nThis tutorial assumes that you have samtools, bwa, Picard tools and IGV installed on your computer.\nThese are already installed on the VM you are using. To check that these are installed, you can run the following commands:\nsamtools --help\nbwa\npicard -h\nigv\nThis should return the help message for samtools, bwa and Picard tools respectively. The final command should launch the genome viewer IGV. You can close the IGV software, we will use it later in this tutorial to visualise alignments.\nTo get started with the tutorial, head to the first section: Performing read alignment"
  },
  {
    "objectID": "course_modules/Module2/module2_manual.html#read-alignment",
    "href": "course_modules/Module2/module2_manual.html#read-alignment",
    "title": "Manual",
    "section": "",
    "text": "Sequence alignment in NGS is the process of determining the most likely source of the observed DNA sequencing read within the reference genome sequence.\n\n\n\n1.2 Why align?\nThere are typical inferences you can make from an alignment of NGS data against a reference genome:\n• Variation from the reference – could have functional consequence.\n• Transcript abundance: Instead of a microarray, you could use alignment to genome to quantify expression: more sensitive\n• Ab-initio transcript discovery: you can see a pileup from RNA seq data showing evidence for an exon which was previously missed or an exon which is being skipped in a transcript.\n\n\n\n 1.2 Learning outcomes\nOn completion of the tutorial, you can expect to be able to:\n• Perform read alignment using standard tools (BWA-MEM)\n• Perform the following task and understand their effect on analysis results\n– Mark Duplicates\n• Visualise read alignments using IGV (Integrated Visualisation Tool)\nIf there is time you will learn how to:\n• Merge the results from multiple alignments and understand when it is appropriate to perform a merge\n\n\n\nThis tutorial comprises the following sections:\n1. Performing read alignment\n2. Alignment visualisation\nThere is also an additional (optional) section: 3. Alignment workflows\n\n\n\nThis tutorial was written by Jacqui Keane based on material from Thomas Keane, Vivek Iyer and Victoria Offord.\n\n\n\nYou can follow this tutorial by typing all the commands you see into a terminal window. This is similar to the “Command Prompt” window on MS Windows systems, which allows the user to type DOS commands to manage files.\nTo get started, open a new terminal on your computer and type the command below:\ncd /home/manager/course_data/read_alignment Now you can follow the instructions in the tutorial from here.\n\n\n\nThis tutorial assumes that you have samtools, bwa, Picard tools and IGV installed on your computer.\nThese are already installed on the VM you are using. To check that these are installed, you can run the following commands:\nsamtools --help\nbwa\npicard -h\nigv\nThis should return the help message for samtools, bwa and Picard tools respectively. The final command should launch the genome viewer IGV. You can close the IGV software, we will use it later in this tutorial to visualise alignments.\nTo get started with the tutorial, head to the first section: Performing read alignment"
  },
  {
    "objectID": "course_modules/Module2/module2_manual.html#performing-read-alignment",
    "href": "course_modules/Module2/module2_manual.html#performing-read-alignment",
    "title": "Manual",
    "section": "2. Performing Read Alignment",
    "text": "2. Performing Read Alignment\nHere we will use the BWA aligner to align a smll set of Illumina sequencing data to the Mus Musculus reference genome. We will align genomic sequence (from Whole-Genome Sequencing) from a mouse embryo which has been mutagenised while the one-cell stage using CRISPR-Cas9 and a gRNA targeting an exon of the Tyr gene. The successful mutation of the gene will delete one or both alleles. A bi-allelic null Tyr mouse will be albino, but otherwise healthy.\nFirst, check you are in the correct directory.\npwd\nIt should display something like:\n/home/manager/course_data/read_alignment\n\n2.1 Viewing the reference genome\nGo to the ref directory that contains the fasta files of the reference genomes: cd ~/course_data/read_alignment/data/ref\nFasta files (.fa) are used to store raw sequencing information before aligning data. A single chromosome from the mouse genome is contained in the file GRCm38.68.dna.toplevel.chr7.fa.gz\nView the file with zless (we use zless instead of less because the file is compressed):\nzless GRCm38.68.dna.toplevel.chr7.fa.gz\nQ1: What is the length of chromosome 7 of the mouse genome? (Hint: Look at the fasta header for chromosome 7)\n................................................................................................\nSimilar to a BAM file, to allow fast retrieval of data, an index file is often required. You should check for the presence of fasta indexes for the genome in the ‘ref’ directory:\nGRCm38.68.dna.toplevel.chr7.fa.gz.amb … GRCm38.68.dna.toplevel.chr7.fa.gz.sa\nThese are created by BWA: suffixtrees, bwt transform etc.\nIf these index files don’t exist, then you can run the indexing with the command\nbwa index GRCm38.68.dna.toplevel.chr7.fa.gz\nBeware – this indexing process can take 3-5 minutes so please only run it if the index files do not exist!\n\n\n2.2 Align the data with bwa\nGo to the ~/course_data/read_alignment/data/Exercise1/fastq/ directory - you can use this command:\ncd ../Exercise1/fastq\nUse the bwa mem command to align the fastq files to the mouse reference genome. By default bwa outputs SAM format directly to the standard output (in this case your terminal window), therefore you will have to redirect the result into a SAM file.\nbwa mem ../../ref/GRCm38.68.dna.toplevel.chr7.fa.gz md5638a_7_87000000_R1.fastq.gz md5638a_7_87000000_R2.fastq.gz &gt; md5638.sam\nThis may take a few minutes, please be patient.\n\n\n2.3 Convert a SAM file to a BAM file\nNow use samtools to convert the SAM file md5638.sam created in the previous step into a BAM file called md5638.bam.\nsamtools view -O BAM -o md5638.bam md5638.sam\nQ2: How much space is saved by using a BAM file instead of a SAM file?\n................................................................................................\n\n\n2.4 Sort and index the BAM file\nThe BAM files produced by BWA are sorted by read name (same order as the original fastq files). However, most viewing and variant calling software require the BAM files to be sorted by reference coordinate position and indexed for rapid retrieval. Therefore, use ‘samtools sort’ to produce a new BAM file called md5638.sorted.bam that is sorted by position.\nsamtools sort -T temp -O bam -o md5638.sorted.bam md5638.bam\nFinally index the sorted BAM file using ‘samtools index’ command.\nNote: indexing a BAM file is also a good way to check that the BAM file has not been truncated (e.g. your disk becomes full when writing the BAM file). At the end of every BAM file, a special end of file (EOF) marker is written. The Samtools index command will first check for this and produce an error message if it is not found.\nsamtools index md5638.sorted.bam\n\n\n2.5 Unix pipes to combine the commands together\nTo produce the sorted BAM file above we had to carry out several separate commands and produce intermediate files. The Unix pipe command allows you to feed the output of one command into the next command.\nYou can combine all of these commands together using unix pipes, and do all of this data processing together and avoid writing intermediate files. To do this type:\nbwa mem ../../ref/GRCm38.68.dna.toplevel.chr7.fa.gz md5638a_7_87000000_R1.fastq..gz md5638a_7_87000000_R2.fastq.gz | samtools view -O BAM - | samtools sort -T temp -O bam -o md5638_2.sorted.bam -\nNow index the BAM file:\nsamtools index md5638_2.sorted.bam\nNote: When the symbol - is used above, Unix will automatically replace - with the output produced by the preceding command (i.e. the command before the | symbol).\n\n\n\n2.6 Mark PCR Duplicates\nWe will use a program called ‘MarkDuplicates’ that is part of Picard tools (http://picard.source-forge.net) to remove PCR duplicates that may have been introduced during the library construction stage. To find the options for ‘MarkDuplicates’ – type:\npicard MarkDuplicates\nNow run MarkDuplicates using the ‘I=’ option to specify the input BAM file and the ‘O=’ option to specify the output file (e.g. md5638.markdup.bam). You will also need to specify the duplication metrics output file using ‘M=’ (e.g. md5638.markdup.metrics).\npicard MarkDuplicates I=md5638.sorted.bam O=md5638.markdup.bam M=md5638.metrics.txt\nQ3: From looking at the output metrics file - how many reads were marked as duplicates? What was the percent duplication?\n................................................................................................\nDon’t forget to generate an index for the new bam file using samtools.\nsamtools index md5638.markdup.bam\n\n\n\n2.7 Generate QC Stats\nUse samtools to collect some statistics and generate QC plots from the alignment in the BAM file from the previous step. Make sure you save the output of the stats command to a file (e.g. md5638.markdup.stats).\nsamtools stats md5638.markdup.bam &gt; md5638.markdup.stats\nplot-bamstats -p md5638_plot/ md5638.markdup.stats\n\n\n2.8 Exercises\nNow look at the output and answer the following questions:\nQ4: What is the total number of reads?\nQ5: What proportion of the reads were mapped?\nQ6: How many reads were paired correctly/properly?\nQ7: How many read pairs mapped to a different chromosome?\nQ8: What is the insert size mean and standard deviation?\nIn your web browser open the file called md5638_plot.html to view the QC information and answer the following questions:\nQ9: How many reads have zero mapping quality?\nQ10: Which of the first fragments or second fragments are higher base quality on average?\nCongratulations you have succesfully aligned some NGS data to a reference genome! Now continue to the next section of the tutorial: Alignment visualisation."
  },
  {
    "objectID": "course_modules/Module2/module2_manual.html#alignment-visualisation",
    "href": "course_modules/Module2/module2_manual.html#alignment-visualisation",
    "title": "Manual",
    "section": "3. Alignment Visualisation",
    "text": "3. Alignment Visualisation\nYou have now made it to the interesting part!\nIntegrative Genome Viewer (IGV) http://www.broadinstitute.org/igv/ allows you to visualise genomic datasets and is a very useful tool for looking at the alignment of reads onto a reference genome from BAM files.\nStart IGV by typing:\nigv &\n\n3.1 IGV main window\nWhen you start IGV, it will open a main window. At the top of this window you have a toolbar and genome ruler for navigation. The largest area in the main window is the data viewer where your alignments, annotations and other data will be displayed. To do this, IGV uses horizontal rows called tracks. Finally, at the bottom, there is a sequence viewer which contains the base level information for your reference genome.\n\n\n\n3.2 Load the reference genome\nIGV provides several genomes which can be selected with the “Genome drop-down box” on the toolbar.\nGo to ’ Genomes -&gt; Load Genome From Server… ’ and select “Mouse mm10”. This is a synonym for GRCm38, which is the current mouse assembly (reference genome)\n\n\n\n\n3.2.1 IGV toolbar and genome ruler\nOnce the genome has loaded, the chromosomes will be shown on the genome ruler with their names/numbers above. When a region is selected, a red box will appear. This represents the visible region of the genome.\nAbove the genome ruler is the toolbar which has a variety controls for navigating the genome:\n\nGenome drop-down - load a genome\nChromosome drop-down - zoom to a chromosome\nSearch - zoom to a chromosome, locus or gene\n\nThere are several other buttons which can be used to control the visible portion of the genome.\n\nWhole genome - zoom back out to whole genome view\nPrevious/next view - move backward/forward through views (like the back/forward buttons in a web browser)\nRefresh - refresh the display\nZoom - zooms in (+) / out (-) on a chromosome\n\n\n\n\n3.2.2 Sequence viewer\nThe sequence viewer shows the genome at the single nucleotide level. You won’t be able to see the sequence until you are zomed in. Let’s try it, select the zooom in (+) option in the top right of the screeen. As you start to zoom in (+), you will see that each nucleotide is represented by a coloured bar (red=T, yellow=G, blue=C and green=A). This makes it easier to spot repetitive regions in the genome. Carry on zooming in (+) and you will see the individual nucleotides.\n\n\n\n3.3 Navigation in IGV\nThere are several views in IGV\n\nGenome view\nChromosome view\nRegion view\n\nThere are several ways to to zoom in and out to these views to look at specific regions or base level information.\n\n\n3.3.1 Whole genome view\nTo get a view of the entire genome select the zoom to whole genome icon (house icon) found in the toolbar at the top of the IGV window.\n\n\n\n3.3.2 Chromosome view\nTo get a view of a specific chromosome select the chromosome from the chromosome drop down list in the toolbar of the IGV window.\n\n\n3.3.3 Region view\nJump to region If you know the co-ordinates of the region you want to view, you can enter them into the “Search” and click “Go”. The format is chromosome:start-stop. For example, to view from 100,000 to 100,100 on chr7, you would enter chr7:100,000-100,100 in the search box. We will practice this later in an exercise.\nSelect region If you don’t know the specific co-ordinates of the region you want to look at, you can click and drag to select a region on the genome toolbar.\nNote: the visible region of the chromosome is indicated by the red box on the genome ruler.\n\n\n3.3.4 Zooming in and out\nYou can zoom in and out from each view by using the “+” and “-” buttons on the zoom control at the right-hand side of the toolbar. This will also work with the “+” and “-” keys on your keyboard.\n\n\n3.4 Load the alignment\nIGV can be used to visualise many different types of data, including read alignments. Each time you load an alignment file it will be added to the data viewer as a new major track.\nGo to ’ File -&gt; Load from File… ‘. Select the “md5638.markdup.bam” BAM file that you created in the previous section and click’ Open ’.\nNote: BAM files and their corresponding index files must be in the same directory for IGV to load them properly.\nFor each read alignment, a major track will appear containing two minor tracks for that sample:\n\ncoverage information\nread alignments\n\nFor the total number of visible tracks, see the bottom left of main window.\nAt the genome level view, there will be no coverage plot or read alignments visible. At the chromosome level view, there are two messages displayed: Zoom in to see coverage/alignments. Finally, once you have zoomed in (+) you will see a density plot in the coverage track and your read alignments.\n\n\n3.5 Visualising alignments\n\n\n3.5.1 Coverage information\nWhen zoomed in to view a region, you can get alignment information for each position in the genome by hovering over the coverage track. This will open a yellow box which tells you the total number of reads mapped at that position, a breakdown of the mapped nucleotide frequencies and the number of reads mapping in a forward/reverse orientation. In the example shown below, 95 reads mapped, 50 forward and 45 reverse, all of which called A at position 202,768 on chromosome PccAS_05_v3.\nThis is just an example for illustrative purposes, please do not try to look at this position in IGV here.\n\n\n3.5.2 Viewing individual read alignment information\nRead are represented by grey or transparent/white bars which are stacked together where they align to the reference genome. Reads are pointed to indicate the orientation in which they mapped i.e. on the forward or reverse strand. Hovering over an individual read will display information about its alignment.\n(images/igv-read-information.png “IGV - read information”)\nMismatches occur where the nucleotide in the aligned read is not the same as the nucleotide in that position on the reference genome. A mismatch is indicated by a coloured bar at the relevant position on the read. The colour of the bar represents the mismatched base in the read (red=T, yellow=G, blue=C and green=A).\n\n\n3.6 IGV configuration\nFollow the instructions that follow to set up your IGV view:\nSelect the little yellow “speech bubble” icon in the toolbar and set the option to “Show Details on Click” (or you will go mad, I promise!).\nZoom in so you can see sequence reads and go to region chr7:87480000-87485000 using the navigation bar at the top.\nControl-click or right-click in the data view window. Choose sort alignments by insert size, then choose colour alignments by insert size and finally choose “View as pairs”.\nGo to ’ View -&gt; Preferences… ’ select the ’ Alignments ’ tab and ensure the “Show soft-clipped bases” option is ticked. This colour highlighting emphasises soft-clips on the read itself.\nYour IGV session should look similar to:\n\n\n\n3.7 Exercises\nGo to chromosome chr7, positions 87,483,625-87,484,330 using the navigation bar across the top. Take in the glorious view of a genome pileup. Stop and smell the roses! Click on stuff!\nScroll around, zoom in and out a bit!\n2. Go back to chromosome 7:87,483,625-87,484,330. What is the (rough) coverage across this region? (Hint: Look at the coverage track)\nCan you spot the three mutant variants (two small and one larger) in this region? State what the evidence is for them?\nHints\n• Hint1: Look around 87,483,960 for an insertion. How large is it? How many reads does it occur in?\n• Hint2: Look around 87,483,960 for a deletion. How large is it? How many reads does it occur in?\n• Hint3: Zoom out slightly and watch the coverage track between 87,483,700 - 87,484,200.\nOnce you’ve spotted the large change look at reference sequence the edges of the mutation to hazard a guess as to its mechanism.\n4. Can you venture a guess as to what happened here? Why are these mutations present?\nCongratulations you have completed the Read Alignment tutorial. If you have time left then continue to the next (optional) section of the tutorial: Alignment workflows.\nHere is an additional IGV tutorial and refresher: https://github.com/sanger-pathogens/pathogen-informatics-training/blob/master/Notebooks/IGV/IGV.pdf. You can find a copy of this tutorial in your manual. Unfortunately, there is not enough time to complete this tutorial now but you may find it useful to look at it after the course."
  },
  {
    "objectID": "course_modules/Module2/module2_manual.html#ngs-workflows",
    "href": "course_modules/Module2/module2_manual.html#ngs-workflows",
    "title": "Manual",
    "section": "4. NGS Workflows",
    "text": "4. NGS Workflows\nA typical NGS experiment involves more than one sample, potential 10’s or 100’s of samples. During the experiment, a sample may be split across multiple libraries and and a library may be split across multiple sequencing runs (lanes). For example, you may have to increase the number of runs for a specific sample to increase the read-depth (sequencing volume), so you have to prepare multiple libraries.\nTherefore you need a coordinated workflow, driven by standard software to bring it reliably together.\nRead alignment is just the first part of that. Once you have a BAM file for each sequencing run you need to merge them together to produce a BAM file for the library. At this stage it is important to perform de-duplication on the merged data. The main purpose of removing duplicates is to mitigate the effects of PCR amplification bias introduced during library construction. PCR duplicates erroneously inflate the coverage and, if not removed, can give the illusion of high confidence when it is not really there which can have an effect on downstream analysis such as variant calling.\nThe figure below outlines a typical NGS workflow:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "The materials provided in this repository are FREE to use. This work is licensed under a Creative Commons Attribution 4.0 International License. Reuse is encouraged with acknowledgement.\n\nAll materials to be added in markdown (with extension .qmd), except for recorded lectures.\nThere are no slides on this website. Instead, you will find instructions on how to generate slides from the markdown content."
  },
  {
    "objectID": "template_course.html",
    "href": "template_course.html",
    "title": "template_course",
    "section": "",
    "text": "Course Overview\n- Course Title\n- Course Description: Short and extended versions\n- Course format \n- Target Audience: (e.g., clinicians, researchers, students)\n- Prerequisites: Knowledge or skills expected\n \nLearning Outcomes\n- Clearly defined, measurable outcomes using Blooms action verbs \n- Mapped to competencies if relevant\nAssessment\n- Formative assessments (quizzes, exercises, peer review)\n- Summative assessments (final project, test, reflection)\n- Rubrics and grading templates for instructors \n- Submission methods/platform\n- Model answers or guides \n \nTeaching Platform & Tech Tools\n- Platforms guide: e.g., GitHub Classroom, Google classroom, Moodle, Zoom etc \n- Accounts/Access setup instructions\n- Tools used in communication and teaching: e.g., Zoom, Slack, BLAST, RStudio\n- Instructions for setting up any required environments (Docker, Conda, virtual machines)\n \nResources & References\n- Core readings (articles, textbooks)\n- Supplementary materials (websites, tools, videos)\n- Glossary of terms\n- FAQs and Troubleshooting guide (tech and teaching)\n \nInstructor & Facilitator Guide - important to include\n- Adult learning strategies [see T3 resource] \n- Teaching tips for each module\n- Common learner questions/issues \n- Discussion prompts\n- Inclusivity guidance [see T3 resource, UDL] \n \n \nEvaluation & Feedback Templates\n- Evaluation questions [what do we want to know] \n- Data collection: learner feedback forms, instructor reflection log/observation structured notes, ost course survey etc)\n- Plan for data analysis \n- Plan for results dissemination"
  },
  {
    "objectID": "course_modules/Module3/module3.html",
    "href": "course_modules/Module3/module3.html",
    "title": "Overview",
    "section": "",
    "text": "Content by\n\nDuration\n\n\nKey topics\nIn this module, learners will look at …\n\n\nActivities\n\nLecture:\nPractical exercises:\nQuiz:\n\n\n\nManual\nModule manual\n\n\nPresentation slides\n(PPT/PDF, to be generated from the module manual)\n\n\nLecture notes or scripts\nPre-recorded lecture\n\n\nPractical exercises\nGoogle Colab walkthrough\nCommand line walkthrough\n\n\nDatasets"
  },
  {
    "objectID": "course_modules/template_module.html",
    "href": "course_modules/template_module.html",
    "title": "template_module",
    "section": "",
    "text": "Title of session/module\n  - Duration \n  - Key topics\n  - Activities (lectures, hands-on, discussions) - Use GHRU template here \n- Presentation slides (PPT/PDF)\n- Lecture notes or scripts\n- Videos (prerecorded lectures, screencasts, youtube etc, with transcripts)\n- Practical/lab exercises (e.g., Jupyter notebooks, Google Colab walkthrough, command line walkthroughs)\n- Datasets (example files or open data repositories)\n- Case studies or examples"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats-answers.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats-answers.html",
    "title": "Data formats for NGS data - Answers",
    "section": "",
    "text": "1. There are 10 sequences in this file. To count all the header lines, we can use grep -c \"&gt;\" data/example.fasta\n2. There are 8 reads in this file. We can use grep to search for /1 or /2:\ngrep -c \"/1\" data/example.fastq\nAlternatively, we can use wc -l to count the lines in the file and then divide this by 4.\n3. RG = Read Group\n4. Illumina. See the __PL__field.\n5. SC. See the CN field.\n6. ERR003612. See the ID field.\n7. 2kbp. See the PI field.\n8. The quality is 48. We can use grep to find the id, followed by awk to print the fifth column:\ngrep \"ERR003762.5016205\" data/example.sam | awk '{print $5}'\n9. The CIGAR is 37M. We can use grep and awk to find it:\ngrep ERR003814.6979522 data/example.sam | awk '{print $6}'\n10. 213. The ninth column holds the insert size, so we can use awk to get this:\ngrep ERR003814.1408899 data/example.sam | awk '{print $9}'\n11. The CIGAR in Q9 was 37M, meaning all 37 bases in the read are either matches or mismatches to the reference.\n12. CIGAR: 4M 4I 8M. The first four bases in the read are the same as in the reference, so we can represent these as 4M in the CIGAR string. Next comes 4 insertions, represented by 4I, followed by 8 alignment matches, represented by 8M.\n13. NCBI build v37\n14. There are 15 lanes in the file. We can count the @RG lines manually, or use standard UNIX commands such as:\nsamtools view -H data/NA20538.bam | grep ^@RG | wc -l\nor\nsamtools view -H data/NA20538.bam | awk '{if($1==\"@RG\")n++}END{print n}'\n15. Looking at the @PG records ID tags, we see that three programs were used: GATK IndelRealigner, GATK TableRecalibration and bwa.\n16. The @PG records contain a the tag VN. From this we see that bwa version 0.5.5 was used.\n17. The first collumn holds the name of the read: ERR003814.1408899\n18. Chromosome 1, position 19999970. Column three contains the name of the reference sequenceand the fourth column holds the leftmost position of the clipped alignment.\n19. 320 reads are mapped to this region. We have already sorted and indexed the BAM file, so now we can search for the reagion using samtools view. Then we can pipe the output to wc to count the number of reads in this region:\nsamtools view data/NA20538_sorted.bam 1:20025000-20030000 | wc -l\n20. The reference version is 37. In the same way that we can use -h in samtools to include the header in the output, we can also use this with bcftools:\nbcftools view -h data/1kg.bcf | grep \"##reference\"\n21. There are 50 samples in the file. The -l option will list all samples in the file:\nbcftools query -l data/1kg.bcf | wc -l\n22. The genotype is A/T. With -f we specify the format of the output, -r is used to specify the region we are looking for, and with -s we select the sample.\nbcftools query -f'%POS [ %TGT]\\n' -r 20:24019472 -s HG00107 data/1kg.bcf\n23. There are 4778 positions with more than 10 alternate alleles. We can use -i to specify that we are looking for instances where the value of the INFO:AC tag (Allele Count) is greater than 10:\nbcftools query -f'%POS\\n' -i 'AC[0]&gt;10' data/1kg.bcf | wc -l\n24. There are 451 such positions. The first command picks out sample HG00107. We can then pipe the output to the second command to filter by depth and non-reference genotype. Then use wc to count the lines:\nbcftools view -s HG00107 data/1kg.bcf | bcftools query -i'FMT/DP&gt;10 & FMT/GT!=\"0/0\"' -f'%POS[ %GT %DP]\\n' | wc -l\n25. 26. The first base is at position 9923 and the last is at 9948.\n26. G. To reduce file size, only the first base is provided in the REF field.\n27. 10. See the MinDP tag in the INFO field."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment-answers.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment-answers.html",
    "title": "QC assessment of NGS data",
    "section": "",
    "text": "1. The peak is at 140 bp, and the read length is 100 bp. This means that the forward and reverse reads overlap with 60 bp.\n2. There are 400252 reads in total.\nLook inside the file and locate the field “raw total sequences”. To extract the information quickly from multiple files, commands similar to the following can be used:\ngrep ^SN lane*.sorted.bam.bchk | awk -F'\\t' '$2==\"raw total sequences:\"'\n3. 76% of the reads were mapped. Divide “reads mapped” (303036) by “raw total sequences” (400252).\n4. 2235 pairs mapped to a different chromosome. Look for “pairs on different chromosomes”\n5. The mean insert size is 275.9 and the standard deviation is 47.7. Look for “insert size mean” and “insert size standard deviation”.\n6. 282478 reads were properly paired. Look for “reads properly paired”.\n7. 23,803 (7.9%) of the reads have zero mapping quality. Look for “zero MQ” in the “Reads” section.\n8. The forward reads. Look at the “Quality per cycle” graphs."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion-answers.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion-answers.html",
    "title": "File conversion - Answers",
    "section": "",
    "text": "1. The CRAM file is ~18 MB. We can check this using:\nls -lh data/yeast.cram\n2. Yes, the BAM file is ~16 MB bigger than the CRAM file. We can check this using:\nls -lh data/yeast*"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination-answers.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination-answers.html",
    "title": "Identifying contamination - Answers",
    "section": "",
    "text": "1. Streptococcus pneumoniae\n2. No\n3. ~7% of the reads. Look for “unclassified” at the top of the file."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/lecture/src/hts-qc.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/lecture/src/hts-qc.html",
    "title": "only for printing",
    "section": "",
    "text": "% subset-slides\n\\vskip2em\n\\vskip10em\n\nData Formats\nFASTQ\n\nUnaligned read sequences with base qualities\n\nSAM/BAM\n\nUnaligned or aligned reads\nText and binary formats\n\nCRAM\n\nBetter compression than BAM\n\nVCF/BCF\n\nFlexible variant call format\nArbitrary types of sequence variation\nSNPs, indels, structural variations\n\n\\vskip2em\nSpecifications maintained by the Global Alliance for Genomics and Health\n\n\nFASTQ\n\nSimple format for raw unaligned sequencing reads\nExtension to the FASTA file format\nSequence and an associated per base quality score\n\n\nQuality encoded in ASCII characters with decimal codes 33-126\n\nASCII code of “A” is 65, the corresponding quality is Q\\(= 65 - 33 = 32\\)\n\n\\vskip0em\n\nPhred quality score: \\(P = 10^{-Q/10}\\) \n\nBeware: multiple quality scores were in use!\n\nSanger, Solexa, Illumina 1.3+\n\nPaired-end sequencing produces two FASTQ files\n\n{A: Q=30, one error in 1000 bases}\n\n\nSAM / BAM\nSAM (Sequence Alignment/Map) format\n\nUnified format for storing read alignments to a reference genome\nDeveloped by the 1000 Genomes Project group (2009)\n\n\nOne record (a single DNA fragment alignment) per line describing alignment between fragment and reference\n11 fixed columns + optional key:type:value tuples\n\n\\vskip0.5em\n\\vskip0.5em\n\\vskip1em\nNote that BAM can contain\n\nunmapped reads\nmultiple alignments of the same read\nsupplementary (chimeric) reads\n\n\n\nSAM\nSAM fields\n\\vskip1em \nCCCTAACCCTAACCATAGCCCTAACCCTAACCCTAACCCTAACCCT[…]CAAACCCACCCCCAAACCCAAAACCTCACCAC\nFFFFFJJJJJJJJFJJJJFJAJJJJJ-JJAAAJFJJFFJJF&lt;FJJFFJJJJFJJJJFF[…]&lt;—F—–A7-J-&lt;J-A–77AF—J7–\nMD:Z:1G24C2A76 PG:Z:MarkDuplicates RG:Z:1 NM:i:3 MQ:i:0 AS:i:94 XS:i:94 \\end{verbatim}}}\n\n\nCIGAR string\nCompact representation of sequence alignment\n\\vskip1em \nExamples:\n\n\nFlags\n\\vskip0.5em\n\\vskip0.5em\nBit operations made easy\n\npython \nsamtools flags \n\n\\vskip5em\n\n\nOptional tags\nEach lane has a unique RG tag that contains meta-data for the lane\nRG tags\n\nID: SRR/ERR number\nPL: Sequencing platform\nPU: Run name\nLB: Library name\nPI: Insert fragment size\nSM: Individual\nCN: Sequencing center\n\n\\vskip10em\n\n\nBAM\nBAM (Binary Alignment/Map) format\n\nBinary version of SAM\nDeveloped for fast processing and random access\n\nBGZF (Block GZIP) compression for indexing\n\n\nKey features\n\nCan store alignments from most mappers\nSupports multiple sequencing technologies\nSupports indexing for quick retrieval/viewing\nCompact size (e.g. 112Gbp Illumina = 116GB disk space)\nReads can be grouped into logical groups e.g. lanes, libraries, samples\nWidely supported by variant calling packages and viewers\n\n\n\nReference based Compression\nBAM files are too large\n\n~1.5-2 bytes per base pair\n\nIncreases in disk capacity are being far outstripped by sequencing technologies\nBAM stores all of the data\n\nEvery read base\nEvery base quality\nUsing a single conventional compression technique for all types of data\n\n\\vskip14em\n\n\nCRAM\nThree important concepts\n\nReference based compression\nControlled loss of quality information\nDifferent compression methods to suit the type of data, e.g. base qualities vs. metadata vs. extra tags\n\nIn lossless mode: 60% of BAM size\nArchives and sequencing centers moving from BAM to CRAM\n\nSupport for CRAM added to Samtools/HTSlib in 2014\nSoon to be available in Picard/GATK\n\n\\vskip1em\n\n\nVCF: Variant Call Format\nFile format for storing variation data\n\nTab-delimited text, parsable by standard UNIX commands\nFlexible and user-extensible\nCompressed with BGZF (bgzip), indexed with TBI or CSI (tabix)\n\n\\vskip1em\n\\vskip3em\n\n\nVCF / BCF\nVCFs can be very big\n\ncompressed VCF with 3781 samples, human data:\n\n54 GB for chromosome 1\n680 GB whole genome\n\n\nVCFs can be slow to parse\n\ntext conversion is slow\nmain bottleneck: FORMAT fields\n\n\\vskip0.5em\n\\vskip1em\nBCF\n\nbinary representation of VCF\nfields rearranged for fast access\n\n\\vskip0.5em\n\n\ngVCF\nOften it is not enough not know variant sites only\n\nwas a site dropped because of a reference call or because of missing data?\nwe need evidence for both variant and non-variant positions in the genome\n\n\\vskip0.5em\ngVCF\n\nblocks of reference-only sites can be represented in a single record using the INFO/END tag\nsymbolic alleles &lt;*&gt; for incremental calling\n\nraw, “callable” gVCF\ncalculate genotype likelihoods only once (an expensive step)\nthen call incrementally as more samples come in\n\n\n\\vskip0.5em\n\n\nOptimizing variant calls for speed\n\\vskip2em\n\\vskip3em\nNew TWK format by Marcus Klarqvist (under development)\n\nBCF still too slow for querying hundreds of thousands and millions of samples\nbigger but 100x faster for certain operations on GTs\n\n\n\nCustom formats for custom tasks\n\\centerline{ \\hskip1em } \\vskip1em \\centerline{ \\hskip2em }\n\n\nGlobal Alliance for Genomics and Health\nInternational coalition dedicated to improving human health\nMission\n\nestablish a common framework to enable sharing of genomic and clinical data\n\nWorking groups\n\nclinical\nregulatory and ethics\nsecurity\ndata\n\nData working group\n\nbeacon project .. test the willingness of international sites to share genetic data \nBRCA challenge .. advance understanding of the genetic basis of breast and other cancers \nmatchmaker exchange .. locate data on rare phenotypes or genotypes \nreference variation .. describe how genomes differ so researchers can assemble and interpret them \nbenchmarking .. develop variant calling benchmark toolkits for germline, cancer, and transcripts \nfile formats .. CRAM, SAM/BAM, VCF/BCF \n\nFile formats\n\nhttp://samtools.github.io/hts-specs/\n\n% # Coffee break and questions %\n% \\vskip7em %\n\n\nQuality Control\nBiases in sequencing\n\nBase calling accuracy\nRead cycle vs. base content\nGC vs. depth\nIndel ratio\n\n\\vskip0.5em\nBiases in mapping\n\\vskip1em\nGenotype checking\n\nSample swaps\nContaminations\n\n\n\nBase quality\nSequencing by synthesis: dephasing\n\ngrowing sequences in a cluster gradually desynchronize\nerror rate increases with read length\n\n\\vskip1em\nCalculate the average quality at each position across all reads\n\\vskip0.5em\n\\vskip0.5em\n\n\nBase calling errors\n\n\n\nBase quality\n\\centerline{ \\hskip5em } \n\n\nMismatches per cycle\nMismatches in aligned reads (requires reference sequence)\n\ndetect cycle-specific errors\nbase qualities are informative!\n\n\\vskip1em\n\n\nGC bias\nGC- and AT-rich regions are more difficult to amplify\n\ncompare the GC content against the expected distribution (reference sequence)\n\n\\vskip2em\n\\vskip3em\n\n\nGC content by cycle\nWas the adapter sequence trimmed?\n\\vskip1em\n\\vskip3em\n\n\nFragment size\nPaired-end sequencing: the size of DNA fragments matters\n\\vskip1em \\vskip3em\n\n\nQuiz\n\\vskip1em \\centerline{\\hskip2em} \\vskip1em\n\\vskip3em\n\n\nInsertions / Deletions per cycle\nFalse indels\n\nair bubbles in the flow cell can manifest as false indels\n\n\\vskip1em\n\\vskip3em\n\n\nAuto QC tests\nA suggestion for human data: \\vskip1em\n\\vskip2em\n\n\n\nDetecting sample swaps\nCheck the identity against a known set of variants\n\\vskip1em \\centerline{ \\hskip1em } \\vskip3em\n\n\nHow many markers are necessary?\n\\vskip1em Number of sites required to identify non-related human samples\n\\vskip1em \\centerline{ \\hskip1em }\n\n\nSoftware\nSoftware used to produce graphs in these slides\n\nsamtools stats and plot-bamstats\nbcftools gtcheck\nmatplotlib\n\n% # xxx %\n% Pipelining %\n% http://seqanswers.com % http://www.cbs.dtu.dk/courses/27626/Exercises/BAM-postprocessing.php %\n% Schwartz: Detection and Removal of Biases in the Analysis of Next- Generation Sequencing Reads % % # Biases in Next Generation Sequencing data %\n% * nucleotide per cycle bias % * mostly in RNA-seq, sometimes in ChIP-seq % * cannot be attributed to biased PCR-amplification % * partial explanation: random hexamer priming during reverse transcription? % - more references in the paper above: 14,15,16,17 %\n% dephasing %\n% The illumina platform uses a so called sequencing by synthesis process. Bases are added one at a time and the consensus is determined in a cluster of identical sequences. %\n% The source of errors can be numerous, here is one review that discusses the issues in more detail: %\n% The challenges of sequencing by synthesis, Nature Biotech, 2009 %\n% In a nuthsell a short answer to the best of my understanding is this: Not % all sequences in a cluster will grow at the same rate, this will slowly % lead to a desynchronization as the errors accumulate. This is why the % quality dips towards the end."
  },
  {
    "objectID": "course_modules/Module1/module1_assessment.html",
    "href": "course_modules/Module1/module1_assessment.html",
    "title": "Assessment Quiz",
    "section": "",
    "text": "Quiz\n\nLook at the following FASTQ line:\n\n@ERR007731.740 IL16_2979:6:1:9:1419/1\nTAAAAAAAAGATGTCATCAGCACATCAGAAAAGAAGGCAACTTTAAAACTTTTC\n+\nDBABBBABABAABABABBABBBAAA&gt;@B@BBAA@4AAA&gt;.&gt;BAA@779:AAA@A\nWhat is the quality of the first base (T)?\n\nLook at the following FASTQ line:\n\n@ERR007731.740 IL16_2979:6:1:9:1419/1  TAAAAAAAAGATGTCATCAGCACATCAGAAAAGAAGGCAACTTTAAAACTTTTC\n+\nDBABBBABABAABABABBABBBAAA&gt;@B@BBAA@4AAA&gt;.&gt;BAA@779:AAA@A\nWhat is the probability that there was a base call error for the first base (T)?\n\nLook at the following line from the header of a SAM file.\n\n@RGID:ERR003612 PL:ILLUMINA LB:g1k-sc-NA20538-TOS-1 PI:2000 DS:SRP000540 SM:NA20538 CN:SC\nWhat does RG stand for?"
  }
]