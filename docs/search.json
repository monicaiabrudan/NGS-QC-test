[
  {
    "objectID": "course_modules/Module1/module1.html",
    "href": "course_modules/Module1/module1.html",
    "title": "Overview",
    "section": "",
    "text": "Content by Eric Dawson (Bioinformatics Scientist (Genomics / AI) - Nvidia) and Carla Daniela Robles Espinoza (Laboratorio Internacional de Investigación sobre el Genoma Humano, Universidad Nacional Autónoma de México)\n\nModule Title\nNGS Data formats and QC\n\n\nDuration\n3 hours\n\n\nKey topics\nIn this module, learners will look at data formats in detail. At the end of the theory, there is a mandatory to test their knowledge.\nFASTQ\n• Unaligned read sequences with base qualities\nSAM/BAM\n• Unaligned or aligned reads\n• Text and binary formats\nCRAM\n• Better compression than BAM\nVCF/BCF\n• Flexible variant call format\n• Arbitrary types of sequence variation\n• SNPs, indels, structural variations\n\n\nActivities\n\nLecture: 1 hour\nPractical exercises: 1.5 hours\nAssessment quiz: 0.5 hours\n\n\n\nManual\nModule manual\n\n\nPresentation slides\n(PPT/PDF, to be generated from the module manual. Instructions on how to that will be added here.)\n\n\nLecture recording, notes and scripts\nPre-recorded lecture, temporally stored on the LMS\n\n\nPractical exercises\n\nGoogle Colab\nYou can practice working with the file formats presented in this modules using a Google Colab developed specifically for this purpose.\nFor detailed information on what is Google Colab, check: What is google colab?\nTo get started with Google Colab use a shared link from Google Drive:\na. Open the Shared Link: Click on the shared link provided to you. It will usually look like this: https://drive.google.com/file/d/....\nThe shared link is IntroductionToLinux.ipynb\nb. Make a Copy: If the link opens a view-only version of the notebook, you can create your own editable copy by selecting File &gt; Save a copy in Drive. This will save the notebook to your Google Drive.\nc. Open Your Copy: Once the copy is saved, you can open it from your Google Drive. You can also access it anytime through Google Colab by selecting File &gt; Open notebook and navigating to your Drive.\n\n\nVirtual Machine\nCommand line walk through.\n\n\n\nDatasets\nPractice files for this module can be found on Github.\n\n\nAssessment quiz\nQuestions"
  },
  {
    "objectID": "course_modules/Module1/module1_manual.html",
    "href": "course_modules/Module1/module1_manual.html",
    "title": "Manual",
    "section": "",
    "text": "These formats store raw or processed nucleotide and protein sequences. \n\n\nHere’s an example of 4 lines from a human reference genome FASTA file:\n\n\"&gt;chr1\" is the header for chromosome 1. Each chromosome has its own header line in the file. \nHeaders usually contain additional details like source, version, or length, e.g.:\n&gt;chr1 dna:chromosome chromosome:GRCh38:1:1:248956422:1.\nThe following lines are the “sequence lines”.\nThey contain nucleotide bases (A, T, C, G, and sometimes N for unknown bases). In FASTA files, the sequence is often wrapped to fit within 80 characters per line.\n\n\n\nFASTQ is a simple format for raw unaligned sequencing reads. This is an extension to the FASTA file format and it is composed of sequence and an associated per base quality score.\n\n\nThe quality of the sequenced nucleotides is encoded in ASCII characters with decimal codes 33-126.\n\nThe ASCII code of “A” is 65. For a nucleotide that has the quality score encoded by A, this can be translates to quality score of Q=65−33=32.\nThe formula to compute the phred quality score is: P = 10−Q/10\n\nThe figure above shows the interpretation of the quality scores, in terms of probability of error and accuracy.\nBeware:\n\nmultiple quality scores were in use: Sanger, Solexa, Illumina 1.3+.\npaired-end sequencing produces two FASTQ files.\n\n\nThe ASCII table (American Standard Code for Information Interchange) is a character encoding standard that maps 128 characters (0–127) to numeric codes. It includes letters (uppercase and lowercase), digits, punctuation marks, control characters (e.g., newline, tab), and special symbols, enabling computers to represent and process text."
  },
  {
    "objectID": "course_modules/Module1/module1_manual.html#other-important-information",
    "href": "course_modules/Module1/module1_manual.html#other-important-information",
    "title": "Manual",
    "section": "Other important information",
    "text": "Other important information\nA CIGAR string (Compact Idiosyncratic Gapped Alignment Report) is a sequence of operations used in SAM/BAM files to describe how a read is aligned to a reference genome. It specifies matches, mismatches, insertions, deletions, and other events in the alignment.\n\nStructure of a CIGAR String\nA CIGAR string consists of a series of operations, each represented by a length (number) followed by a character (operation type).\n\nCommon Operations:\n\nM: Match (alignment match or mismatch).\nExample: 10M = 10 bases aligned (could include mismatches).\nI: Insertion (relative to the reference).\nExample: 5I = 5 bases inserted in the query sequence.\nD: Deletion (relative to the reference).\nExample: 3D = 3 bases deleted in the reference sequence.\nS: Soft clipping (query sequence bases not aligned but present in the sequence).\nExample: 8S = 8 bases clipped from the start or end.\nH: Hard clipping (query sequence bases not aligned and removed from the sequence).\nExample: 10H = 10 bases clipped and not stored in the sequence.\nN: Skipped region (in the reference).\nExample: 100N = 100 bases skipped in the reference (e.g., introns in RNA-Seq).\nP: Padding (used with insertions or deletions in multiple sequence alignment).\n=: Exact match to the reference.\nX: Mismatch to the reference.\n\nExamples:\nRef: ACGTACGTACGTACGT\nRead: ACGT----ACGTACGA\nCigar: 4M 4D 8M\nRef: ACGT----ACGTACGT\nRead: ACGTACGTACGTACGT\nCigar: 4M 4I 8M\n\nRef: ACTCAGTG--GT\nRead: ACGCA-TGCAGTtagacgt\nCigar: 5M 1D 2M 2I 2M 7S\n\n\n\n** Key Takeaways:**\n\nCIGAR strings describe how the query sequence aligns to the reference genome.\nThey are critical for understanding alignments in SAM/BAM files.\nTools like samtools or IGV can help visualize alignments and interpret CIGAR strings.\n\n\n\nThe MAF file format\nMAF stands for “Mutation-Annotation Format” and is a tab-delimited text file containing aggregated information from VCF files (NCI-GDC). It aggregates lots of information – 120+ fields per mutation! You can review all these at: https://docs.gdc.cancer.gov/Data/File_Formats/MAF_Format/\nYou can convert between VCF and MAF via vcf2maf tools!\nperl vcf2maf.pl –input-vcf [vcf_file] –output-maf\n[maf_file] –vep-path /cm/shared/apps/vep/ensembl-vep-\nrelease-106.1/ –vep-data /mnt/Archives/vep/106/38/ –ref-\nfasta [fasta_file] –tumor-id [tumor] –normal-id [normal]"
  },
  {
    "objectID": "course_modules/Module1/module1_manual.html#ga4gh",
    "href": "course_modules/Module1/module1_manual.html#ga4gh",
    "title": "Manual",
    "section": "GA4GH",
    "text": "GA4GH\nThe Global Alliance for Genomics and Health (GA4GH) is an international coalition dedicated to advancing human health by creating frameworks and standards for sharing genomic and clinical data. Its mission is to enable responsible, ethical, and secure global collaboration in genomics research and healthcare.\nCore Mission:\n\nEstablish a common framework to facilitate the sharing of genomic and clinical data.\n\n\n\nImprove human health through international collaboration and innovation.\n\n\nWorking Groups\nGA4GH is organized into several working groups, each focusing on a specific aspect of genomic data sharing:\n\nClinical: Applies genomics to healthcare and medicine.\nRegulatory and Ethics: Addresses legal, ethical, and policy issues related to genomic data.\nSecurity: Ensures the privacy and protection of sensitive genomic data.\nData: Develops tools, resources, and initiatives to enhance data sharing and analysis.\n\n\n\nKey Projects of the Data Working Group\n\nBeacon Project: Tests global willingness to share genetic data.\nBRCA Challenge: Advances understanding of breast and other cancers by studying BRCA-related genetic variants.\nMatchmaker Exchange: Connects researchers with data on rare phenotypes or genotypes.\nReference Variation: Standardizes how genomes are described to improve interpretation and assembly.\nBenchmarking: Creates toolkits for evaluating variant calling in germline, cancer, and transcriptomic data.\nFile Formats: Develops and maintains standards such as CRAM, SAM/BAM, and VCF/BCF for efficient genomic data storage and processing.\n\n\n\nFile Format Standards\nGA4GH maintains file format standards through resources like the HTS Specifications repository (http://samtools.github.io/hts-specs/), which supports interoperability and efficient data management in genomics.\nAdditional Resources:\n1. File format tutorial - University of Connecticut\n2. UCSC Galaxy - Data file formats\n3. 12 Common Bioinformatics Files Types Explained (Youtube Video)"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html",
    "title": "File conversion",
    "section": "",
    "text": "In this section we are going to look at how to convert from one file format to another. There are many tools available for converting between file formats, and we will use some of the most common ones: samtools, bcftools and Picard."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#sam-to-bam",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#sam-to-bam",
    "title": "File conversion",
    "section": "SAM to BAM",
    "text": "SAM to BAM\nTo convert from SAM to BAM format we are going to use the samtools view command. In this instance, we would like to include the SAM header, so we use the -h option:\n\nsamtools view -h data/NA20538.bam &gt; data/NA20538.sam\n\nNow, have a look at the first ten lines of the SAM file. They should look like they did in the previous section when you viewed the BAM file header.\n\nhead data/NA20538.sam\n\nWell that was easy! And converting SAM to BAM is just as straightforward. This time there is no need for the -h option, however we have to tell samtools that we want the output in BAM format. We do so by adding the -b option:\n\nsamtools view -b data/NA20538.sam &gt; data/NA20538_2.bam\n\nSamtools is very well documented, so for more usage options and functions, have a look at the samtools manual http://www.htslib.org/doc/samtools-1.0.html."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#bam-to-cram",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#bam-to-cram",
    "title": "File conversion",
    "section": "BAM to CRAM",
    "text": "BAM to CRAM\nThe samtools view command can be used to convert a BAM file to CRAM format. In the data directory there is a BAM file called yeast.bam that was created from S. cerevisiae Illumina sequencing data. There is also a reference genome in the directory, called Saccharomyces_cerevisiae.EF4.68.dna.toplevel.fa. For the conversion, an index file (.fai) for the reference must be created. This can be done using samtools faidx. However, as we will see, samtools will generate this file on the fly when we specify a reference file using the -F option.\nTo convert to CRAM, we use the -C option to tell samtools we want the output as CRAM, and the -T option to specify what reference file to use for the conversion. We also use the -o option to specify the name of the output file. Give this a try:\n\nsamtools view -C -T data/Saccharomyces_cerevisiae.EF4.68.dna.toplevel.fa -o data/yeast.cram data/yeast.bam\n\nHave a look at what files were created:\n\nls -l data\n\nAs you can see, this has created an index file for the reference genome called Saccharomyces_cerevisiae.EF4.68.dna.toplevel.fa.fai and the CRAM file yeast.cram.\n\nExercises\nQ1: Since CRAM files use reference-based compression, we expect the CRAM file to be smaller than the BAM file. What is the size of the CRAM file?\nQ2: Is your CRAM file smaller than the original BAM file?\nTo convert CRAM back to BAM, simply change -C to -b and change places for the input and output CRAM/BAM:\nsamtools view -b -T data/Saccharomyces_cerevisiae.EF4.68.dna.toplevel.fa -o data/yeast.bam data/yeast.cram"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#fastq-to-sam",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#fastq-to-sam",
    "title": "File conversion",
    "section": "FASTQ to SAM",
    "text": "FASTQ to SAM\nSAM format is mainly used to store alignment data, however in some cases we may want to store the unaligned data in SAM format and for this we can use the picard tools FastqToSam application. Picard tools is a Java application that comes with a number of useful options for manipulating high-throughput sequencing data. .\nTo convert the FASTQ files of lane 13681_1#18 to unaligned SAM format, run:\n\npicard FastqToSam F1=data/13681_1#18_1.fastq.gz F2=data/13681_1#18_2.fastq.gz O=data/13681_1#18.sam SM=13681_1#18\n\nFrom here you can go on and convert the SAM file to BAM and CRAM, as described previously. There are also multiple options for specifying what metadata to include in the SAM header. To see all available options, run:\n\npicard FastqToSam -h"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#cram-to-fastq",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#cram-to-fastq",
    "title": "File conversion",
    "section": "CRAM to FASTQ",
    "text": "CRAM to FASTQ\nIt is possible to convert CRAM to FASTQ directly using the samtools fastq command. However, for many applications we need the fastq files to be ordered so that the order of the reads in the first file match the order of the reads in the mate file. For this reason, we first use samtools collate to produce a collated BAM file.\n\nsamtools collate data/yeast.cram data/yeast.collated\n\nThe newly produced BAM file will be called yeast.collated.bam. Let’s use this to create two FASTQ files, one for the forward reads and one for the reverse reads:\n\nsamtools fastq -1 data/yeast.collated_1.fastq -2 data/yeast.collated_2.fastq data/yeast.collated.bam\n\nFor further information and usage options, have a look at the samtools manual page (http://www.htslib.org/doc/samtools.html)."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#vcf-to-bcf",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion.html#vcf-to-bcf",
    "title": "File conversion",
    "section": "VCF to BCF",
    "text": "VCF to BCF\nIn a similar way that samtools view can be used to convert between SAM, BAM and CRAM, bcftools view can be used to convert between VCF and BCF. To convert the file called 1kg.bcf to a compressed VCF file called 1kg.vcf.gz, run:\n\nbcftools view -O z -o data/1kg.vcf.gz data/1kg.bcf\n\nThe -O option allows us to specify in what format we want the output, compressed BCF (b), uncompressed BCF (u), compressed VCF (z) or uncompressed VCF (v). With the -o option we can select the name of the output file.\nHave a look at what files were generated (the options -lrt will list the files in reverse chronological order):\n\nls -lrt data\n\nThis also generated an index file, 1kg.bcf.csi.\nTo convert a VCF file to BCF, we can run a similar command. If we want to keep the original BCF, we need to give the new one a different name so that the old one is not overwritten:\n\nbcftools view -O b -o data/1kg_2.bcf data/1kg.vcf.gz\n\nCongratulations you have reached the end of the Data formats and QC tutorial!"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html",
    "title": "NGS Data formats and QC",
    "section": "",
    "text": "There are several file formats for storing Next Generation Sequencing (NGS) data. In this tutorial we will look at some of the most common formats for storing NGS reads and variant data. We will cover the following formats:\nFASTQ - This format stores unaligned read sequences with base qualities\nSAM/BAM - This format stores unaligned or aligned reads (text and binary formats)\nCRAM - This format is similar to BAM but has better compression than BAM\nVCF/BCF - Flexible variant call format for storing SNPs, indels, structural variations (text and binary formats)\nFollowing this, we will work through some examples of converting between the different formats.\nFurther to understanding the different file formats, it is important to remember that all sequencing platforms have technical limitations that can introduce biases in your sequencing data. Because of this it is very important to check the quality of the data before starting any analysis, whether you are planning to use something you have sequenced yourself or publicly available data. In the latter part of this tutorial we will describe how to perform a QC assessment for your NGS data."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#introduction",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#introduction",
    "title": "NGS Data formats and QC",
    "section": "",
    "text": "There are several file formats for storing Next Generation Sequencing (NGS) data. In this tutorial we will look at some of the most common formats for storing NGS reads and variant data. We will cover the following formats:\nFASTQ - This format stores unaligned read sequences with base qualities\nSAM/BAM - This format stores unaligned or aligned reads (text and binary formats)\nCRAM - This format is similar to BAM but has better compression than BAM\nVCF/BCF - Flexible variant call format for storing SNPs, indels, structural variations (text and binary formats)\nFollowing this, we will work through some examples of converting between the different formats.\nFurther to understanding the different file formats, it is important to remember that all sequencing platforms have technical limitations that can introduce biases in your sequencing data. Because of this it is very important to check the quality of the data before starting any analysis, whether you are planning to use something you have sequenced yourself or publicly available data. In the latter part of this tutorial we will describe how to perform a QC assessment for your NGS data."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#learning-outcomes",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#learning-outcomes",
    "title": "NGS Data formats and QC",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nOn completion of the tutorial, you can expect to be able to:\n\nDescribe the different NGS data formats available (FASTQ, SAM/BAM, CRAM, VCF/BCF)\nPerform a QC assessment of high throughput sequence data\nPerform conversions between the different data formats"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#tutorial-sections",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#tutorial-sections",
    "title": "NGS Data formats and QC",
    "section": "Tutorial sections",
    "text": "Tutorial sections\nThis tutorial comprises the following sections:\n1. Data formats\n2. QC assessment\nIf you have time you can also complete:\n\nFile conversion"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#authors",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#authors",
    "title": "NGS Data formats and QC",
    "section": "Authors",
    "text": "Authors\nThis tutorial was written by Jacqui Keane and Sara Sjunnebo based on material from Petr Danecek and Thomas Keane."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#running-the-commands-from-this-tutorial",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#running-the-commands-from-this-tutorial",
    "title": "NGS Data formats and QC",
    "section": "Running the commands from this tutorial",
    "text": "Running the commands from this tutorial\nYou can follow this tutorial by typing all the commands you see into a terminal window. This is similar to the “Command Prompt” window on MS Windows systems, which allows the user to type DOS commands to manage files.\nTo get started, open a new terminal on your computer and type the command below:\n\ncd ~/course_data/data_formats/\n\nNow you can follow the instructions in the tutorial from here."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#lets-get-started",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/index.html#lets-get-started",
    "title": "NGS Data formats and QC",
    "section": "Let’s get started!",
    "text": "Let’s get started!\nThis tutorial assumes that you have samtools, bcftools and Picard tools installed on your computer. These are already installed on the VM you are using. To check that these are installed, you can run the following commands:\n\nsamtools --help\n\n\nbcftools --help\n\n\npicard -h\n\nThis should return the help message for samtools, bcftools and picard tools respectively.\nTo get started with the tutorial, go to the first section: Data formats"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html",
    "title": "QC assessment of NGS data",
    "section": "",
    "text": "QC is an important part of any analysis. In this section we are going to look at some of the metrics and graphs that can be used to assess the QC of NGS data."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#base-quality",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#base-quality",
    "title": "QC assessment of NGS data",
    "section": "Base quality",
    "text": "Base quality\nIllumina sequencing technology relies on sequencing by synthesis. One of the most common problems with this is dephasing. For each sequencing cycle, there is a possibility that the replication machinery slips and either incorporates more than one nucleotide or perhaps misses to incorporate one at all. The more cycles that are run (i.e. the longer the read length gets), the greater the accumulation of these types of errors gets. This leads to a heterogeneous population in the cluster, and a decreased signal purity, which in turn reduces the precision of the base calling. The figure below shows an example of this.\n\n\n\nMean Base Quality\n\n\nBecause of dephasing, it is possible to have high-quality data at the beginning of the read but really low-quality data towards the end of the read. In those cases you can decide to trim off the low-quality reads, for example using a tool called Trimmomatic.\nThe figures below shows an example of a good sequencing run (left) and a poor sequencing run (right).\n\n\n\nBase quality"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#other-base-calling-errors",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#other-base-calling-errors",
    "title": "QC assessment of NGS data",
    "section": "Other base calling errors",
    "text": "Other base calling errors\nThere are several different reasons for a base to be called incorrectly, as shown in the figure below. Phasing noise and signal decay is a result of the dephasing issue described above. During library preparation, mixed clusters can occur if multiple templates get co-located. These clusters should be removed from the downstream analysis. Boundary effects occur due to optical effects when the intensity is uneven across each tile, resulting in higher intensity found toward the center. Cross-talk occurs because the emission frequency spectra for each of the four base dyes partly overlap, creating uncertainty. Finally, for previous sequencing cycle methods T fluorophore accumulation was an issue, where incomplete removal of the dye coupled to thymine lead to an ambient accumulation the nucleotides, causing a false high Thymine trend.\n\n\n\nBase Calling Errors\n\n\nBase-calling for next-generation sequencing platforms, doi: 10.1093/bib/bbq077"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#mismatches-per-cycle",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#mismatches-per-cycle",
    "title": "QC assessment of NGS data",
    "section": "Mismatches per cycle",
    "text": "Mismatches per cycle\nAligning reads to a high-quality reference genome can provide insight to the quality of a sequencing run by showing you the mismatches to the reference sequence. This can help you detect cycle-specific errors. Mismatches can occur due to two main causes, sequencing errors and differences between your sample and the reference genome, which is important to bear in mind when interpreting mismatch graphs. The figure below shows an example of a good run (left) and a bad one (right). In the graph on the left, the distribution of the number of mismatches is even between the cycles, which is what we would expect from a good run. However, in the graph on the right, two cycles stand out with a lot of mismatches compared to the other cycles.\n\n\n\nMismatches per cycle"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#gc-content",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#gc-content",
    "title": "QC assessment of NGS data",
    "section": "GC content",
    "text": "GC content\nIt is a good idea to compare the GC content of the reads against the expected distribution in a reference sequence. The GC content varies between species, so a shift in GC content like the one seen below could be an indication of sample contamination. In the left graph below, we can see that the GC content of the sample is about the same as for the reference, at ~38%. However, in the right graph, the GC content of the sample is closer to 55%, indicating that there is an issue with this sample.\n\n\n\nGC Content"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#gc-content-by-cycle",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#gc-content-by-cycle",
    "title": "QC assessment of NGS data",
    "section": "GC content by cycle",
    "text": "GC content by cycle\nLooking at the GC content per cycle can help detect if the adapter sequence was trimmed. For a random library, it is expected to be little to no difference between the different bases of a sequence run, so the lines in this plot should be parallel with each other like in the graph on the left below. In the graph on the right, the initial spikes are likely due to adapter sequences that have not been removed.\n\n\n\nGC content by cycle"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#fragment-size",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#fragment-size",
    "title": "QC assessment of NGS data",
    "section": "Fragment size",
    "text": "Fragment size\nFor paired-end sequencing the size of DNA fragments also matters. In the first of the examples below, the fragment size peaks around 440 bp. In the second however, there is also a peak at around 200 bp. This indicates that there was an issue with the fragment size selection during library prep.\n\n\n\nFragment size distribution\n\n\n\nExercises\nQ1: The figure below is from a 100bp paired-end sequencing. Can you spot any problems?\n\n\n\nQ1 Insert size distribution"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#insertionsdeletions-per-cycle",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#insertionsdeletions-per-cycle",
    "title": "QC assessment of NGS data",
    "section": "Insertions/Deletions per cycle",
    "text": "Insertions/Deletions per cycle\nSometimes, air bubbles occur in the flow cell, which can manifest as false indels. The spike in the right image provides an example of how this can look.\n\n\n\nIndels per cycle"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#generating-qc-stats",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment.html#generating-qc-stats",
    "title": "QC assessment of NGS data",
    "section": "Generating QC stats",
    "text": "Generating QC stats\nNow let’s try this out! We will generate QC stats for two lanes of Illumina paired-end sequencing data from yeast. The reads have already been aligned to the Saccromyces cerevisiae reference genome to produce the BAM file lane1.sorted.bam.\nNow we will use samtools stats to generate the stats for the primary alignments. The option -f can be used to filter reads with specific tags, while -F can be used to filter out reads with specific tags. The following command will include only primary alignments:\n\nsamtools stats -F SECONDARY data/lane1.sorted.bam &gt; data/lane1.sorted.bam.bchk\n\nHave a look at the first 47 lines of the statistics file that was generated:\n\nhead -n 47 data/lane1.sorted.bam.bchk\n\nThis file contains a number of useful stats that we can use to get a better picture of our data, and it can even be plotted with plot-bamstats, as you will see soon. First let’s have a closer look at some of the different stats. Each part of the file starts with a # followed by a description of the section and how to extract it from the file. Let’s have a look at all the sections in the file:\n\ngrep ^'#' data/lane1.sorted.bam.bchk | grep 'Use'\n\n\nSummary Numbers (SN)\nThis initial section contains a summary of the alignment and includes some general statistics. In particular, you can see how many bases mapped, and how much of the genome that was covered.\n\n\nExercises\nNow look at the output and try to answer the questions below.\nQ2: What is the total number of reads?\nQ3: What proportion of the reads were mapped?\nQ4: How many pairs were mapped to a different chromosome?\nQ5: What is the insert size mean and standard deviation?\nQ6: How many reads were paired properly?\n\n\nGenerating QC plots\nFinally, we will create some QC plots from the output of the stats command using the command plot-bamstats which is included in the samtools package:\n\nplot-bamstats -p data/lane1-plots/ data/lane1.sorted.bam.bchk\n\nNow in your web browser open the file lane1-plots/index.html to view the QC information.\nQ7: How many reads have zero mapping quality?\nQ8: Which read (forward/reverse) of the first fragments and second fragments are higher base quality on average?\nNow continue to the next section of the tutorial: File conversion."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html",
    "title": "Data formats for NGS data",
    "section": "",
    "text": "Here we will take a closer look at some of the most common NGS data formats. First, check you are in the correct directory.\npwd\nIt should display something like:\n/home/manager/course_data/data_formats/"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#fasta",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#fasta",
    "title": "Data formats for NGS data",
    "section": "FASTA",
    "text": "FASTA\nThe FASTA format is used to store both nucleotide data and protein sequences. Each sequence in a FASTA file is represented by two parts, a header line and the actual sequence. The header always starts with the symbol “&gt;” and is followed by information about the sequence, such as a unique identifier. The following lines show two sequences represented in FASTA format:\n&gt;Sequence_1\nCTTGACGACTTGAAAAATGACGAAATCACTAAAAAACGTGAAAAATGAGAAATG\nAAAATGACGAAATCACTAAAAAACGTGACGACTTGAAAAATGACCAC\n&gt;Sequence_2\nCTTGAGACGAAATCACTAAAAAACGTGACGACTTGAAGTGAAAAATGAGAAATG\nAAATCATGACGACTTGAAGTGAAAAAGTGAAAAATGAGAAATGAACGTGACGAC\nAAAATGACGAAATCATGACGACTTGAAGTGAAAAATAAATGACC\n\nExercises\nQ1: How many sequences are there in the fasta file data/example.fasta? (Hint: is there a grep option you can use?)"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#fastq",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#fastq",
    "title": "Data formats for NGS data",
    "section": "FASTQ",
    "text": "FASTQ\nFASTQ is a data format for sequencing reads. It is an extension to the FASTA file format, and includes a quality score for each base. Have a look at the example below, containing two reads:\n@ERR007731.739 IL16_2979:6:1:9:1684/1\nCTTGACGACTTGAAAAATGACGAAATCACTAAAAAACGTGAAAAATGAGAAATG\n+\nBBCBCBBBBBBBABBABBBBBBBABBBBBBBBBBBBBBABAAAABBBBB=@&gt;B\n@ERR007731.740 IL16_2979:6:1:9:1419/1\nAAAAAAAAAGATGTCATCAGCACATCAGAAAAGAAGGCAACTTTAAAACTTTTC\n+\nBBABBBABABAABABABBABBBAAA&gt;@B@BBAA@4AAA&gt;.&gt;BAA@779:AAA@A\nWe can see that for each read we get four lines:\n\nThe read metadata, such as the read ID. Starts with @ and, for paired-end Illumina reads, is terminated with /1 or /2 to show that the read is the member of a pair.\nThe read\nStarts with + and optionally contains the ID again\nThe per base Phred quality score\n\nThe quality scores range (in theory) from 1 to 94 and are encoded as ASCII characters. The first 32 ASCII codes are reserved for control characters which are not printable, and the 33rd is reserved for space. Neither of these can be used in the quality string, so we need to subtract 33 from whatever the value of the quality character is. For example, the ASCII code of “A” is 65, so the corresponding quality is:\nQ = 65 - 33 = 32\nThe Phred quality score Q relates to the base-calling error probability P as\n       P = 10-Q/10\nThe Phred quality score is a measure of the quality of base calls. For example, a base assigned with a Phred quality score of 30 tells us that there is a 1 in 1000 chance that this base was called incorrectly.\n\n\n\n\n\n\n\n\nPhred Quality Score\nProbability of incorrect base call\nBase call accuracy\n\n\n\n\n10\n1 in 10\n90%\n\n\n20\n1 in 100\n99%\n\n\n30\n1 in 1000\n99.9%\n\n\n40\n1 in 10,000\n99.99%\n\n\n50\n1 in 100,000\n99.999%\n\n\n60\n1 in 1,000,000\n99.9999%\n\n\n\n\nExercises\nQ2: How many reads are there in the file example.fastq? (Hint: remember that @ is a possible quality score. Is there something else in the header that is unique?)"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#sam",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#sam",
    "title": "Data formats for NGS data",
    "section": "SAM",
    "text": "SAM\nSAM (Sequence Alignment/Map) format is a unified format for storing read alignments to a reference genome. It is a standard format for storing NGS sequencing reads, base qualities, associated meta-data and alignments of the data to a reference genome. If no reference genome is available, the data can also be stored unaligned.\nThe files consist of a header section (optional) and an alignment section. The alignment section contains one record (a single DNA fragment alignment) per line describing the alignment between fragment and reference. Each record has 11 fixed columns and optional key:type:value tuples. Open the SAM/BAM file specification document https://samtools.github.io/hts-specs/SAMv1.pdf either in a web browser or you can find a copy in the QC directory as you may need to refer to it throughout this tutorial.\nNow let us have a closer look at the different parts of the SAM/BAM format.\n\nHeader Section\nThe header section of a SAM file looks like:\n@HD VN:1.0  SO:coordinate\n@SQ SN:test_ref LN:17637\n@RG ID:ERR003612 PL:ILLUMINA LB:g1k-sc-NA20538-TOS-1 PI:2000 DS:SRP000540 SM:NA20538 CN:SC\nEach line in the SAM header begins with an @, followed by a two-letter header record type code as defined in the SAM/BAM format specification document. Each record type can contain meta-data captured as a series of key-value pairs in the format of ‘TAG:VALUE’.\n\nRead groups\nOne useful record type is RG which can be used to describe each lane of sequencing. The RG code can be used to capture extra meta-data for the sequencing lane. Some common RG TAGs are:\n\nID: SRR/ERR number\nPL: Sequencing platform\nPU: Run name\nLB: Library name\nPI: Insert fragment size\nSM: Individual/Sample\nCN: Sequencing centre\n\nWhile most of these are self explanitory, insert fragment size may occasionally be negative. This simply indicates that the reads found are overlapping while its size is less than 2 x read length.\n\n\n\nExercises\nLook at the following line from the header of a SAM file and answering the questions that follow:\n@RG ID:ERR003612 PL:ILLUMINA LB:g1k-sc-NA20538-TOS-1 PI:2000 DS:SRP000540 SM:NA20538 CN:SC\nQ3: What does RG stand for?\nQ4: What is the sequencing platform?\nQ5: What is the sequencing centre?\nQ6: What is the lane identifier?\nQ7: What is the expected fragment insert size?\n\n\nAlignment Section\nThe alignment section of SAM files contains one line per read alignment, an example is\nERR005816.1408831 163 Chr1    19999970    23  40M5D30M2I28M   =   20000147    213 GGTGGGTGGATCACCTGAGATCGGGAGTTTGAGACTAGGTGG...    &lt;=@A@??@=@A@A&gt;@BAA@ABA:&gt;@&lt;&gt;=BBB9@@2B3&lt;=@A@...\nEach of the lines are composed of multiple columns listed below. The first 11 columns are mandatory.\n\nQNAME: Query NAME of the read or the read pair i.e. DNA sequence\nFLAG: Bitwise FLAG (pairing, strand, mate strand, etc.)\nRNAME: Reference sequence NAME\nPOS: 1-Based leftmost POSition of clipped alignment\nMAPQ: MAPping Quality (Phred-scaled)\nCIGAR: Extended CIGAR string (operations: MIDNSHPX=)\nMRNM: Mate Reference NaMe (’=’ if same as RNAME)\nMPOS: 1-Based leftmost Mate POSition\nISIZE: Inferred Insert SIZE\nSEQ: Query SEQuence on the same strand as the reference\nQUAL: Query QUALity (ASCII-33=Phred base quality)\nOTHER: Optional fields\n\nThe image below provides a visual guide to some of the columns of the SAM format.\n\n\n\nSAM format\n\n\n\n\nExercises\nLet’s have a look at example.sam. Notice that we can use the standard UNIX operations like cat on this file.\n\ncat data/example.sam\n\nQ8: What is the mapping quality of ERR003762.5016205? (Hint: can you use grep and awk to find this?)\nQ9: What is the CIGAR string for ERR003814.6979522? (Hint: we will go through the meaning of CIGAR strings in the next section)\nQ10: What is the inferred insert size of ERR003814.1408899?\n\n\nCIGAR string\nColumn 6 of the alignment is the CIGAR string for that alignment. The CIGAR string provides a compact representation of sequence alignment. Have a look at the table below. It contains the meaning of all different symbols of a CIGAR string:\n\n\n\nSymbol\nMeaning\n\n\n\n\nM\nalignment match or mismatch\n\n\n=\nsequence match\n\n\nX\nsequence mismatch\n\n\nI\ninsertion into the read (sample sequenced)\n\n\nD\ndeletion from the read (sample sequenced)\n\n\nS\nsoft clipping (clipped sequences present in SEQ)\n\n\nH\nhard clipping (clipped sequences NOT present in SEQ)\n\n\nN\nskipped region from the reference\n\n\nP\npadding (silent deletion from padded reference)\n\n\n\nBelow are two examples describing the CIGAR string in more detail.\nExample 1:\nRef:     ACGTACGTACGTACGT\nRead:  ACGT- - - - ACGTACGA\nCigar: 4M 4D 8M\nThe first four bases in the read are the same as in the reference, so we can represent these as 4M in the CIGAR string. Next comes 4 deletions, represented by 4D, followed by 7 alignment matches and one alignment mismatch, represented by 8M. Note that the mismatch at position 16 is included in 8M. This is because it still aligns to the reference.\nExample 2:\nRef:     ACTCAGTG- - GT\nRead:  ACGCA- TGCAGTtagacgt\nCigar: 5M 1D 2M 2I 2M 7S\nHere we start off with 5 alignment matches and mismatches, followed by one deletion. Then we have two more alignment matches, two insertions and two more matches. At the end, we have seven soft clippings, 7S. These are clipped sequences that are present in the SEQ (Query SEQuence on the same strand as the reference).\n\n\nExercises\nQ11: What does the CIGAR from Q9 mean?\nQ12: How would you represent the following alignment with a CIGAR string?\nRef:     ACGT- - - - ACGTACGT\nRead:  ACGTACGTACGTACGT\n\n\nFlags\nColumn 2 of the alignment contains a combination of bitwise FLAGs describing the alignment. The following table contains the information you can get from the bitwise FLAGs:\n\n\n\n\n\n\n\n\n\nHex\nDec\nFlag\nDescription\n\n\n\n\n0x1\n1\nPAIRED\npaired-end (or multiple-segment) sequencing technology\n\n\n0x2\n2\nPROPER_PAIR\neach segment properly aligned according to the aligner\n\n\n0x4\n4\nUNMAP\nsegment unmapped\n\n\n0x8\n8\nMUNMAP\nnext segment in the template unmapped\n\n\n0x10\n16\nREVERSE\nSEQ is reverse complemented\n\n\n0x20\n32\nMREVERSE\nSEQ of the next segment in the template is reversed\n\n\n0x40\n64\nREAD1\nthe first segment in the template\n\n\n0x80\n128\nREAD2\nthe last segment in the template\n\n\n0x100\n256\nSECONDARY\nsecondary alignment\n\n\n0x200\n512\nQCFAIL\nnot passing quality controls\n\n\n0x400\n1024\nDUP\nPCR or optical duplicate\n\n\n0x800\n2048\nSUPPLEMENTARY\nsupplementary alignment\n\n\n\nFor example, if you have an alignment with FLAG set to 113, this can only be represented by decimal codes 64 + 32 + 16 + 1, so we know that these four flags apply to the alignment and the alignment is paired-end, reverse complemented, sequence of the next template/mate of the read is reversed and the read aligned is the first segment in the template.\n\nPrimary, secondary and supplementary alignments\nA read that aligns to a single reference sequence (including insertions, deletions, skips and clipping but not direction changes), is a linear alignment. If a read cannot be represented as a linear alignment, but instead is represented as a group of linear alignments without large overlaps, it is called a chimeric alignment. These can for instance be caused by structural variations. Usually, one of the linear alignments in a chimeric alignment is considered to be the representative alignment, and the others are called supplementary.\nSometimes a read maps equally well to more than one spot. In these cases, one of the possible alignments is marked as the primary alignment and the rest are marked as secondary alignments."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#bam",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#bam",
    "title": "Data formats for NGS data",
    "section": "BAM",
    "text": "BAM\nBAM (Binary Alignment/Map) format, is a compressed binary version of SAM. This means that, while SAM is human readable, BAM is only readable for computers. BAM files can be viewed using samtools, and will then have the same format as a SAM file. The key features of BAM are:\n\nCan store alignments from most mappers\nSupports multiple sequencing technologies\nSupports indexing for quick retrieval/viewing\nCompact size (e.g. 112Gbp Illumina = 116GB disk space)\nReads can be grouped into logical groups e.g. lanes, libraries, samples\nWidely supported by variant calling packages and viewers\n\nSince BAM is a binary format, we can’t use the standard UNIX operations directly on this file format. Samtools is a set of programs for interacting with SAM and BAM files. Using the samtools view command, print the header of the BAM file:\n\nsamtools view -H data/NA20538.bam\n\n\nExercises\nQ13: What version of the human assembly was used to perform the alignments? (Hint: Can you spot this somewhere in the @SQ records?)\nQ14: How many lanes are in this BAM file? (Hint: Do you recall what RG represents?)\nQ15: What programs were used to create this BAM file? (Hint: have a look for the program record, @PG)\nQ16: What version of bwa was used to align the reads? (Hint: is there anything in the @PG record that looks like it could be a version tag?)\nThe output from running samtools view on a BAM file without any options is a headerless SAM file. This gets printed to STDOUT in the terminal, so we will want to pipe it to something. Let’s have a look at the first read of the BAM file:\n\nsamtools view data/NA20538.bam | head -n 1\n\nQ17: What is the name of the first read? (Hint: have a look at the alignment section if you can’t recall the different fields)\nQ18: What position does the alignment of the read start at?"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#cram",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#cram",
    "title": "Data formats for NGS data",
    "section": "CRAM",
    "text": "CRAM\nEven though BAM files are compressed, they are still very large. Typically they use 1.5-2 bytes for each base pair of sequencing data that they contain, and while disk capacity is ever improving, increases in disk capacity are being far outstripped by sequencing technologies.\nBAM stores all of the data, this includes every read base, every base quality, and it uses a single conventional compression technique for all types of data. CRAM was designed for better compression of genomic data than SAM/BAM. CRAM uses three important concepts:\n\nReference based compression\nControlled loss of quality information\nDifferent compression methods to suit the type of data, e.g. base qualities vs. metadata vs. extra tags\n\nThe figure below displays how reference-based compression works. Instead of saving all the bases of all the reads, only the nucleotides that differ from the reference, and their positions, are kept.\n\n\nIn lossless (no information is lost) mode a CRAM file is 60% of the size of a BAM file, so archives and sequencing centres have moved from BAM to CRAM.\nSince samtools 1.3, CRAM files can be read in the same way that BAM files can. We will look closer at how you can convert between SAM, BAM and CRAM formats in the next section."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#indexing",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#indexing",
    "title": "Data formats for NGS data",
    "section": "Indexing",
    "text": "Indexing\nTo allow for fast random access of regions in BAM and CRAM files, they can be indexed. The files must first be coordinate-sorted rather that sorted by read name. This can be done using samtools sort. If no options are supplied, it will by default sort by the left-most position of the reference.\n\nsamtools sort -o data/NA20538_sorted.bam data/NA20538.bam\n\nNow we can use samtools index to create an index file (.bai) for our sorted BAM file:\n\nsamtools index data/NA20538_sorted.bam\n\nTo look for reads mapped to a specific region, we can use samtools view and specify the region we are interested in as: RNAME[:STARTPOS[-ENDPOS]]. For example, to look at all the reads mapped to a region called chr4, we could use:\nsamtools view alignment.bam chr4\nTo look at the region on chr4 beginning at position 1,000,000 and ending at the end of the chromosome, we can do:\nsamtools view alignment.bam chr4:1000000\nAnd to explore the 1001bp long region on chr4 beginning at position 1,000 and ending at position 2,000, we can use:\nsamtools view alignment.bam chr4:1000-2000\n\nExercises\nQ19: How many reads are mapped to region 20025000-20030000 on chromosome 1?"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#vcf",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#vcf",
    "title": "Data formats for NGS data",
    "section": "VCF",
    "text": "VCF\nThe VCF file format was introduced to store variation data. VCF consists of tab-delimited text and is parsable by standard UNIX commands which makes it flexible and user-extensible. The figure below provides an overview of the different components of a VCF file:\n\n\n\nVCF format\n\n\n\nVCF header\nThe VCF header consists of meta-information lines (starting with ##) and a header line (starting with #). All meta-information lines are optional and can be put in any order, except for fileformat. This holds the information about which version of VCF is used and must come first.\nThe meta-information lines consist of key=value pairs. Examples of meta-information lines that can be included are ##INFO, ##FORMAT and ##reference. The values can consist of multiple fields enclosed by &lt;&gt;. More information about these fields is available in the VCF specification http://samtools.github.io/hts-specs/VCFv4.3.pdf. This can be accessed using a web browser and there is a copy in the QC directory.\n\nHeader line\nThe header line starts with # and consists of 8 required fields:\n\nCHROM: an identifier from the reference genome\nPOS: the reference position\nID: a list of unique identifiers (where available)\nREF: the reference base(s)\nALT: the alternate base(s)\nQUAL: a phred-scaled quality score\nFILTER: filter status\nINFO: additional information\n\nIf the file contains genotype data, the required fields are also followed by a FORMAT column header, and then a number of sample IDs. The FORMAT field specifies the data types and order. Some examples of these data types are:\n\nGT: Genotype, encoded as allele values separated by either / or |\nDP: Read depth at this position for this sample\nGQ: Conditional genotype quality, encoded as a phred quality\n\n\n\n\nBody\nIn the body of the VCF, each row contains information about a position in the genome along with genotype information on samples for each position, all according to the fields in the header line."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#bcf",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#bcf",
    "title": "Data formats for NGS data",
    "section": "BCF",
    "text": "BCF\nBCF is a compressed binary representation of VCF.\nVCF can be compressed with BGZF (bgzip) and indexed with TBI or CSI (tabix), but even compressed it can still be very big. For example, a compressed VCF with 3781 samples of human data will be 54 GB for chromosome 1, and 680 GB for the whole genome. VCFs can also be slow to parse, as text conversion is slow. The main bottleneck is the “FORMAT” fields. For this reason the BCF format was developed.\nIn BCF files the fields are rearranged for fast access. The following images show the process of converting a VCF file into a BCF file.\n\n\nBcftools comprises a set of programs for interacting with VCF and BCF files. It can be used to convert between VCF and BCF and to view or extract records from a region.\n\nbcftools view\nLet’s have a look at the header of the file 1kg.bcf in the data directory. Note that bcftools uses -h to print only the header, while samtools uses -H for this.\n\nbcftools view -h data/1kg.bcf\n\nSimilarly to BAM, BCF supports random access, that is, fast retrieval from a given region. For this, the file must be indexed:\n\nbcftools index data/1kg.bcf\n\nNow we can extract all records from the region 20:24042765-24043073, using the -r option. The -H option will make sure we don’t include the header in the output:\n\nbcftools view -H -r 20:24042765-24043073 data/1kg.bcf\n\n\n\nbcftools query\nThe versatile bcftools query command can be used to extract any VCF field. Combined with standard UNIX commands, this gives a powerful tool for quick querying of VCFs. Have a look at the usage options:\n\nbcftools query -h\n\nLet’s try out some useful options. As you can see from the usage, -l will print a list of all the samples in the file. Give this a go:\n\nbcftools query -l data/1kg.bcf\n\nAnother very useful option is -s which allows you to extract all the data relating to a particular sample. This is a common option meaning it can be used for many bcftools commands, like bcftools view. Try this for sample HG00131:\n\nbcftools view -s HG00131 data/1kg.bcf | head -n 50\n\nThe format option, -f can be used to select what gets printed from your query command. For example, the following will print the position, reference base and alternate base for sample HG00131, separated by tabs:\n\nbcftools query -f'%POS\\t%REF\\t%ALT\\n' -s HG00131 data/1kg.bcf | head\n\nFinally, let’s look at the -i option. With this option we can select only sites for which a particular expression is true. For instance, if we only want to look at sites that have at least 2 alternate alleles across all samples, we can use the following expression (piped to head to only show a subset of the output):\n\nbcftools query -f'%CHROM\\t%POS\\n' -i 'AC[0]&gt;2' data/1kg.bcf | head\n\nWe use -i with the expression AC[0]&gt;2. AC is an info field that holds the __a__llele __c__ount. Some fields can hold multiple values, so we use AC[0]&gt;2 to indicate that we are looking for the first value (this is zero indexed, and hence starts at 0 instead of 1), and that this value should be &gt; 2. To format our output, we use -f to specify that we want to print the chromosome name and position.\nThere is more information about expressions on the bcftools manual page http://samtools.github.io/bcftools/bcftools.html#expressions\n\n\nExercises\nNow, try and answer the following questions about the file 1kg.bcf in the data directory. For more information about the different usage options you can open the bcftools query manual page http://samtools.github.io/bcftools/bcftools.html#query in a web browser.\nQ20: What version of the human assembly do the coordinates refer to?\nQ21: How many samples are there in the BCF?\nQ22: What is the genotype of the sample HG00107 at the position 20:24019472? (Hint: use the combination of -r, -s, and -f options)\nQ23: How many positions are there with more than 10 alternate alleles? (Hint: use the -i filtering option)\nQ24: In how many positions does HG00107 have a non-reference genotype and a read depth bigger than 10? (Hint: you can use pipes to combine bcftools queries)"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#gvcf",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats.html#gvcf",
    "title": "Data formats for NGS data",
    "section": "gVCF",
    "text": "gVCF\nOften it is not enough to know variant sites only. For instance, we don’t know if a site was dropped because it matches the reference or because the data is missing. We sometimes need evidence for both variant and non-variant positions in the genome. In gVCF format, blocks of reference-only sites can be represented in a single record using the “INFO/END” tag. Symbolic alleles (&lt;*&gt;) are used for incremental calling:\n\n\n\ngVCF\n\n\n\nExercises\nQ25: In the above example, what is the size of the reference-only block starting at position 9923?\nQ26: For the same block, what is the first base?\nQ27: How many reference reads does the block have?\nNow continue to the next section of the tutorial: QC assessment of NGS data."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html",
    "title": "Identifying contamination",
    "section": "",
    "text": "It is always a good idea to check that your data is from the species you expect it to be. A very useful tool for this is Kraken. In this tutorial we will go through how you can use Kraken to check your samples for contamination.\nNote if using the Sanger cluster: Kraken is run as part of the automatic qc pipeline and you can retreive the results using the pf qc script. For more information, run pf man qc."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#setting-up-a-database",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#setting-up-a-database",
    "title": "Identifying contamination",
    "section": "Setting up a database",
    "text": "Setting up a database\nTo run Kraken you need to either build a database or download an existing one. The standard database is very large (33 GB), but thankfully there are some smaller, pre-built databased available. To download the smallest of them, the 4 GB MiniKraken. If you don’t already have a kraken database set up, run:\n\nwget https://ccb.jhu.edu/software/kra\\\n    ken/dl/minikraken_20171019_4GB.tgz\n\nThen all you need to do is un-tar it:\n\ntar -zxvf minikraken_20171019_4GB.tgz\n\nThis version of the database is constructed from complete bacterial, archaeal, and viral genomes in RefSeq, however it contains only around 3 percent of the kmers from the original kraken database (more information here). If the pre-packaged databases are not quite what you are looking for, you can create your own customized database instead. Details about this can be found here.\nNote if using the Sanger cluster: There are several pre-built databases available centrally on the Sanger cluster. For more information, please contact the Pathogen Informatics team."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#running-kraken",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#running-kraken",
    "title": "Identifying contamination",
    "section": "Running Kraken",
    "text": "Running Kraken\nTo run Kraken, you need to provide the path to the database you just created. By default, the input files are assumed to be in FASTA format, so in this case we also need to tell Kraken that our input files are in FASTQ format, gzipped, and that they are paired end reads:\n\nkraken --db ./minikraken_20171013_4GB --output kraken_results \\\n    --fastq-input --gzip-compressed --paired \\\n    data/13681_1#18_1.fastq.gz data/13681_1#18_2.fastq.gz\n\nThe five columns in the file that’s generated are:\n\n“C”/“U”: one letter code indicating that the sequence was either classified or unclassified.\nThe sequence ID, obtained from the FASTA/FASTQ header.\nThe taxonomy ID Kraken used to label the sequence; this is 0 if the sequence is unclassified.\nThe length of the sequence in bp.\nA space-delimited list indicating the LCA mapping of each k-mer in the sequence.\n\nTo get a better overview you can create a kraken report:\n\nkraken-report --db ./minikraken_20171013_4GB \\\n    kraken_results &gt; kraken-report"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#looking-at-the-results",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#looking-at-the-results",
    "title": "Identifying contamination",
    "section": "Looking at the results",
    "text": "Looking at the results\nLet’s have a closer look at the kraken_report for the sample. If for some reason your kraken-run failed there is a prebaked kraken-report at data/kraken-report\n\nhead -n 20 kraken-report\n\nThe six columns in this file are:\n\nPercentage of reads covered by the clade rooted at this taxon\nNumber of reads covered by the clade rooted at this taxon\nNumber of reads assigned directly to this taxon\nA rank code, indicating (U)nclassified, (D)omain, (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, or (S)pecies. All other ranks are simply ‘-’.\nNCBI taxonomy ID\nScientific name"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#exercises",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#exercises",
    "title": "Identifying contamination",
    "section": "Exercises",
    "text": "Exercises\nQ1: What is the most prevalent species in this sample?\nQ2: Are there clear signs of contamination?\nQ3: What percentage of reads could not be classified?"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#heterozygous-snps",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination.html#heterozygous-snps",
    "title": "Identifying contamination",
    "section": "Heterozygous SNPs",
    "text": "Heterozygous SNPs\nFor bacteria, another thing that you can look at to detect contamination is if there are heterozygous SNPs in your samples. Simply put, if you align your reads to a reference, you would expect any snps to be homozygous, i.e. if one read differs from the reference genome, then the rest of the reads that map to that same location will also do so:\nHomozygous SNP\nRef:       CTTGAGACGAAATCACTAAAAAACGTGACGACTTG\nRead1:  CTTGAGtCG\nRead2:  CTTGAGtCGAAA\nRead3:         GAGtCGAAATCACTAAAA\nRead4:               GtCGAAATCA\nBut if there is contamination, this may not be the case. In the example below, half of the mapped reads have the T allele and half have the A.\nHeterozygous SNP\nRef:       CTTGAGACGAAATCACTAAAAAACGTGACGACTTG\nRead1:  CTTGAGtCG\nRead2:  CTTGAGaCGAAA\nRead3:         GAGaCGAAATCACTAAAA\nRead4:               GtCGAAATCA\nNote if using the Sanger cluster: Heterozygous SNPs are calculated as part of the automated QC pipeline. The result for each lane is available in the file heterozygous_snps_report.txt.\nCongratulations! You have reached the end of this tutorial. You can find the answers to all the questions of the tutorial here.\nTo revisit the previous section click here. Alternatively you can head back to the index page"
  },
  {
    "objectID": "course_modules/Module2/module2.html",
    "href": "course_modules/Module2/module2.html",
    "title": "Overview",
    "section": "",
    "text": "Module Title\nRead alignment\n\n\nDuration\n4 hours\n\n\nKey topics\nIn this module, learners will look at:\n\nRead alignment theory and tools\nChallenges in alignment and quality assessment\nData processing and scalability\n\n\n\nActivities\n\nLecture: 1h\nPractical exercises: 2.5h\nQuiz: 0.5h\n\n\n\nManual and practical execises\nModule manual\nSolutions\n\n\nPresentation slides\n(PPT/PDF, to be generated from the module manual)\n\n\nLecture notes or scripts\nPre-recorded lecture\nVirtual machine\n\n\nDatasets"
  },
  {
    "objectID": "course_modules/Module2/module2_manual.html",
    "href": "course_modules/Module2/module2_manual.html",
    "title": "Manual",
    "section": "",
    "text": "Sequence alignment in NGS is the process of determining the most likely source of the observed DNA sequencing read within the reference genome sequence.\n\n\n\n1.2 Why align?\nThere are typical inferences you can make from an alignment of NGS data against a reference genome:\n• Variation from the reference – could have functional consequence.\n• Transcript abundance: Instead of a microarray, you could use alignment to genome to quantify expression: more sensitive\n• Ab-initio transcript discovery: you can see a pileup from RNA seq data showing evidence for an exon which was previously missed or an exon which is being skipped in a transcript.\n\n\n\n 1.2 Learning outcomes\nOn completion of the tutorial, you can expect to be able to:\n• Perform read alignment using standard tools (BWA-MEM)\n• Perform the following task and understand their effect on analysis results\n– Mark Duplicates\n• Visualise read alignments using IGV (Integrated Visualisation Tool)\nIf there is time you will learn how to:\n• Merge the results from multiple alignments and understand when it is appropriate to perform a merge\n\n\n\nThis tutorial comprises the following sections:\n1. Performing read alignment\n2. Alignment visualisation\nThere is also an additional (optional) section: 3. Alignment workflows\n\n\n\nThis tutorial was written by Jacqui Keane based on material from Thomas Keane, Vivek Iyer and Victoria Offord.\n\n\n\nYou can follow this tutorial by typing all the commands you see into a terminal window. This is similar to the “Command Prompt” window on MS Windows systems, which allows the user to type DOS commands to manage files.\nTo get started, open a new terminal on your computer and type the command below:\ncd /home/manager/course_data/read_alignment Now you can follow the instructions in the tutorial from here.\n\n\n\nThis tutorial assumes that you have samtools, bwa, Picard tools and IGV installed on your computer.\nThese are already installed on the VM you are using. To check that these are installed, you can run the following commands:\nsamtools --help\nbwa\npicard -h\nigv\nThis should return the help message for samtools, bwa and Picard tools respectively. The final command should launch the genome viewer IGV. You can close the IGV software, we will use it later in this tutorial to visualise alignments.\nTo get started with the tutorial, head to the first section: Performing read alignment"
  },
  {
    "objectID": "course_modules/Module2/module2_manual.html#read-alignment",
    "href": "course_modules/Module2/module2_manual.html#read-alignment",
    "title": "Manual",
    "section": "",
    "text": "Sequence alignment in NGS is the process of determining the most likely source of the observed DNA sequencing read within the reference genome sequence.\n\n\n\n1.2 Why align?\nThere are typical inferences you can make from an alignment of NGS data against a reference genome:\n• Variation from the reference – could have functional consequence.\n• Transcript abundance: Instead of a microarray, you could use alignment to genome to quantify expression: more sensitive\n• Ab-initio transcript discovery: you can see a pileup from RNA seq data showing evidence for an exon which was previously missed or an exon which is being skipped in a transcript.\n\n\n\n 1.2 Learning outcomes\nOn completion of the tutorial, you can expect to be able to:\n• Perform read alignment using standard tools (BWA-MEM)\n• Perform the following task and understand their effect on analysis results\n– Mark Duplicates\n• Visualise read alignments using IGV (Integrated Visualisation Tool)\nIf there is time you will learn how to:\n• Merge the results from multiple alignments and understand when it is appropriate to perform a merge\n\n\n\nThis tutorial comprises the following sections:\n1. Performing read alignment\n2. Alignment visualisation\nThere is also an additional (optional) section: 3. Alignment workflows\n\n\n\nThis tutorial was written by Jacqui Keane based on material from Thomas Keane, Vivek Iyer and Victoria Offord.\n\n\n\nYou can follow this tutorial by typing all the commands you see into a terminal window. This is similar to the “Command Prompt” window on MS Windows systems, which allows the user to type DOS commands to manage files.\nTo get started, open a new terminal on your computer and type the command below:\ncd /home/manager/course_data/read_alignment Now you can follow the instructions in the tutorial from here.\n\n\n\nThis tutorial assumes that you have samtools, bwa, Picard tools and IGV installed on your computer.\nThese are already installed on the VM you are using. To check that these are installed, you can run the following commands:\nsamtools --help\nbwa\npicard -h\nigv\nThis should return the help message for samtools, bwa and Picard tools respectively. The final command should launch the genome viewer IGV. You can close the IGV software, we will use it later in this tutorial to visualise alignments.\nTo get started with the tutorial, head to the first section: Performing read alignment"
  },
  {
    "objectID": "course_modules/Module2/module2_manual.html#performing-read-alignment",
    "href": "course_modules/Module2/module2_manual.html#performing-read-alignment",
    "title": "Manual",
    "section": "2. Performing Read Alignment",
    "text": "2. Performing Read Alignment\nHere we will use the BWA aligner to align a smll set of Illumina sequencing data to the Mus Musculus reference genome. We will align genomic sequence (from Whole-Genome Sequencing) from a mouse embryo which has been mutagenised while the one-cell stage using CRISPR-Cas9 and a gRNA targeting an exon of the Tyr gene. The successful mutation of the gene will delete one or both alleles. A bi-allelic null Tyr mouse will be albino, but otherwise healthy.\nFirst, check you are in the correct directory.\npwd\nIt should display something like:\n/home/manager/course_data/read_alignment\n\n2.1 Viewing the reference genome\nGo to the ref directory that contains the fasta files of the reference genomes: cd ~/course_data/read_alignment/data/ref\nFasta files (.fa) are used to store raw sequencing information before aligning data. A single chromosome from the mouse genome is contained in the file GRCm38.68.dna.toplevel.chr7.fa.gz\nView the file with zless (we use zless instead of less because the file is compressed):\nzless GRCm38.68.dna.toplevel.chr7.fa.gz\nQ1: What is the length of chromosome 7 of the mouse genome? (Hint: Look at the fasta header for chromosome 7)\n................................................................................................\nSimilar to a BAM file, to allow fast retrieval of data, an index file is often required. You should check for the presence of fasta indexes for the genome in the ‘ref’ directory:\nGRCm38.68.dna.toplevel.chr7.fa.gz.amb … GRCm38.68.dna.toplevel.chr7.fa.gz.sa\nThese are created by BWA: suffixtrees, bwt transform etc.\nIf these index files don’t exist, then you can run the indexing with the command\nbwa index GRCm38.68.dna.toplevel.chr7.fa.gz\nBeware – this indexing process can take 3-5 minutes so please only run it if the index files do not exist!\n\n\n2.2 Align the data with bwa\nGo to the ~/course_data/read_alignment/data/Exercise1/fastq/ directory - you can use this command:\ncd ../Exercise1/fastq\nUse the bwa mem command to align the fastq files to the mouse reference genome. By default bwa outputs SAM format directly to the standard output (in this case your terminal window), therefore you will have to redirect the result into a SAM file.\nbwa mem ../../ref/GRCm38.68.dna.toplevel.chr7.fa.gz md5638a_7_87000000_R1.fastq.gz md5638a_7_87000000_R2.fastq.gz &gt; md5638.sam\nThis may take a few minutes, please be patient.\n\n\n2.3 Convert a SAM file to a BAM file\nNow use samtools to convert the SAM file md5638.sam created in the previous step into a BAM file called md5638.bam.\nsamtools view -O BAM -o md5638.bam md5638.sam\nQ2: How much space is saved by using a BAM file instead of a SAM file?\n................................................................................................\n\n\n2.4 Sort and index the BAM file\nThe BAM files produced by BWA are sorted by read name (same order as the original fastq files). However, most viewing and variant calling software require the BAM files to be sorted by reference coordinate position and indexed for rapid retrieval. Therefore, use ‘samtools sort’ to produce a new BAM file called md5638.sorted.bam that is sorted by position.\nsamtools sort -T temp -O bam -o md5638.sorted.bam md5638.bam\nFinally index the sorted BAM file using ‘samtools index’ command.\nNote: indexing a BAM file is also a good way to check that the BAM file has not been truncated (e.g. your disk becomes full when writing the BAM file). At the end of every BAM file, a special end of file (EOF) marker is written. The Samtools index command will first check for this and produce an error message if it is not found.\nsamtools index md5638.sorted.bam\n\n\n2.5 Unix pipes to combine the commands together\nTo produce the sorted BAM file above we had to carry out several separate commands and produce intermediate files. The Unix pipe command allows you to feed the output of one command into the next command.\nYou can combine all of these commands together using unix pipes, and do all of this data processing together and avoid writing intermediate files. To do this type:\nbwa mem ../../ref/GRCm38.68.dna.toplevel.chr7.fa.gz md5638a_7_87000000_R1.fastq..gz md5638a_7_87000000_R2.fastq.gz | samtools view -O BAM - | samtools sort -T temp -O bam -o md5638_2.sorted.bam -\nNow index the BAM file:\nsamtools index md5638_2.sorted.bam\nNote: When the symbol - is used above, Unix will automatically replace - with the output produced by the preceding command (i.e. the command before the | symbol).\n\n\n\n2.6 Mark PCR Duplicates\nWe will use a program called ‘MarkDuplicates’ that is part of Picard tools (http://picard.source-forge.net) to remove PCR duplicates that may have been introduced during the library construction stage. To find the options for ‘MarkDuplicates’ – type:\npicard MarkDuplicates\nNow run MarkDuplicates using the ‘I=’ option to specify the input BAM file and the ‘O=’ option to specify the output file (e.g. md5638.markdup.bam). You will also need to specify the duplication metrics output file using ‘M=’ (e.g. md5638.markdup.metrics).\npicard MarkDuplicates I=md5638.sorted.bam O=md5638.markdup.bam M=md5638.metrics.txt\nQ3: From looking at the output metrics file - how many reads were marked as duplicates? What was the percent duplication?\n................................................................................................\nDon’t forget to generate an index for the new bam file using samtools.\nsamtools index md5638.markdup.bam\n\n\n\n2.7 Generate QC Stats\nUse samtools to collect some statistics and generate QC plots from the alignment in the BAM file from the previous step. Make sure you save the output of the stats command to a file (e.g. md5638.markdup.stats).\nsamtools stats md5638.markdup.bam &gt; md5638.markdup.stats\nplot-bamstats -p md5638_plot/ md5638.markdup.stats\n\n\n2.8 Exercises\nNow look at the output and answer the following questions:\nQ4: What is the total number of reads?\nQ5: What proportion of the reads were mapped?\nQ6: How many reads were paired correctly/properly?\nQ7: How many read pairs mapped to a different chromosome?\nQ8: What is the insert size mean and standard deviation?\nIn your web browser open the file called md5638_plot.html to view the QC information and answer the following questions:\nQ9: How many reads have zero mapping quality?\nQ10: Which of the first fragments or second fragments are higher base quality on average?\nCongratulations you have succesfully aligned some NGS data to a reference genome! Now continue to the next section of the tutorial: Alignment visualisation."
  },
  {
    "objectID": "course_modules/Module2/module2_manual.html#alignment-visualisation",
    "href": "course_modules/Module2/module2_manual.html#alignment-visualisation",
    "title": "Manual",
    "section": "3. Alignment Visualisation",
    "text": "3. Alignment Visualisation\nYou have now made it to the interesting part!\nIntegrative Genome Viewer (IGV) http://www.broadinstitute.org/igv/ allows you to visualise genomic datasets and is a very useful tool for looking at the alignment of reads onto a reference genome from BAM files.\nStart IGV by typing:\nigv &\n\n3.1 IGV main window\nWhen you start IGV, it will open a main window. At the top of this window you have a toolbar and genome ruler for navigation. The largest area in the main window is the data viewer where your alignments, annotations and other data will be displayed. To do this, IGV uses horizontal rows called tracks. Finally, at the bottom, there is a sequence viewer which contains the base level information for your reference genome.\n\n\n\n3.2 Load the reference genome\nIGV provides several genomes which can be selected with the “Genome drop-down box” on the toolbar.\nGo to ’ Genomes -&gt; Load Genome From Server… ’ and select “Mouse mm10”. This is a synonym for GRCm38, which is the current mouse assembly (reference genome)\n\n\n\n\n3.2.1 IGV toolbar and genome ruler\nOnce the genome has loaded, the chromosomes will be shown on the genome ruler with their names/numbers above. When a region is selected, a red box will appear. This represents the visible region of the genome.\nAbove the genome ruler is the toolbar which has a variety controls for navigating the genome:\n\nGenome drop-down - load a genome\nChromosome drop-down - zoom to a chromosome\nSearch - zoom to a chromosome, locus or gene\n\nThere are several other buttons which can be used to control the visible portion of the genome.\n\nWhole genome - zoom back out to whole genome view\nPrevious/next view - move backward/forward through views (like the back/forward buttons in a web browser)\nRefresh - refresh the display\nZoom - zooms in (+) / out (-) on a chromosome\n\n\n\n\n3.2.2 Sequence viewer\nThe sequence viewer shows the genome at the single nucleotide level. You won’t be able to see the sequence until you are zomed in. Let’s try it, select the zooom in (+) option in the top right of the screeen. As you start to zoom in (+), you will see that each nucleotide is represented by a coloured bar (red=T, yellow=G, blue=C and green=A). This makes it easier to spot repetitive regions in the genome. Carry on zooming in (+) and you will see the individual nucleotides.\n\n\n\n3.3 Navigation in IGV\nThere are several views in IGV\n\nGenome view\nChromosome view\nRegion view\n\nThere are several ways to to zoom in and out to these views to look at specific regions or base level information.\n\n\n3.3.1 Whole genome view\nTo get a view of the entire genome select the zoom to whole genome icon (house icon) found in the toolbar at the top of the IGV window.\n\n\n\n3.3.2 Chromosome view\nTo get a view of a specific chromosome select the chromosome from the chromosome drop down list in the toolbar of the IGV window.\n\n\n\n3.3.3 Region view\nJump to region If you know the co-ordinates of the region you want to view, you can enter them into the “Search” and click “Go”. The format is chromosome:start-stop. For example, to view from 100,000 to 100,100 on chr7, you would enter chr7:100,000-100,100 in the search box. We will practice this later in an exercise.\nSelect region If you don’t know the specific co-ordinates of the region you want to look at, you can click and drag to select a region on the genome toolbar.\n\nNote: the visible region of the chromosome is indicated by the red box on the genome ruler.\n\n\n3.3.4 Zooming in and out\nYou can zoom in and out from each view by using the “+” and “-” buttons on the zoom control at the right-hand side of the toolbar. This will also work with the “+” and “-” keys on your keyboard.\n\n\n\n3.4 Load the alignment\nIGV can be used to visualise many different types of data, including read alignments. Each time you load an alignment file it will be added to the data viewer as a new major track.\nGo to ’ File -&gt; Load from File… ‘. Select the “md5638.markdup.bam” BAM file that you created in the previous section and click’ Open ’.\nNote: BAM files and their corresponding index files must be in the same directory for IGV to load them properly.\n\n\n\n\n3.5 Visualising alignments\nFor each read alignment, a major track will appear containing two minor tracks for that sample:\n\ncoverage information\nread alignments\n\nFor the total number of visible tracks, see the bottom left of main window.\nAt the genome level view, there will be no coverage plot or read alignments visible. At the chromosome level view, there are two messages displayed: Zoom in to see coverage/alignments. Finally, once you have zoomed in (+) you will see a density plot in the coverage track and your read alignments.\n\n\n\n3.5.1 Coverage information\nWhen zoomed in to view a region, you can get alignment information for each position in the genome by hovering over the coverage track. This will open a yellow box which tells you the total number of reads mapped at that position, a breakdown of the mapped nucleotide frequencies and the number of reads mapping in a forward/reverse orientation. In the example shown below, 95 reads mapped, 50 forward and 45 reverse, all of which called A at position 202,768 on chromosome PccAS_05_v3.\nThis is just an example for illustrative purposes, please do not try to look at this position in IGV here.\n\n\n\n3.5.2 Viewing individual read alignment information\nRead are represented by grey or transparent/white bars which are stacked together where they align to the reference genome. Reads are pointed to indicate the orientation in which they mapped i.e. on the forward or reverse strand. Hovering over an individual read will display information about its alignment.\n(images/igv-read-information.png “IGV - read information”)\nMismatches occur where the nucleotide in the aligned read is not the same as the nucleotide in that position on the reference genome. A mismatch is indicated by a coloured bar at the relevant position on the read. The colour of the bar represents the mismatched base in the read (red=T, yellow=G, blue=C and green=A).\n\n\n\n3.6 IGV configuration\nFollow the instructions that follow to set up your IGV view:\nSelect the little yellow “speech bubble” icon in the toolbar and set the option to “Show Details on Click” (or you will go mad, I promise!).\n\nZoom in so you can see sequence reads and go to region chr7:87480000-87485000 using the navigation bar at the top.\n\nControl-click or right-click in the data view window. Choose sort alignments by insert size, then choose colour alignments by insert size and finally choose “View as pairs”.\nGo to ’ View -&gt; Preferences… ’ select the ’ Alignments ’ tab and ensure the “Show soft-clipped bases” option is ticked. This colour highlighting emphasises soft-clips on the read itself.\n\n\nYour IGV session should look similar to:\n\n\n\n3.7 Exercises\nGo to chromosome chr7, positions 87,483,625-87,484,330 using the navigation bar across the top. Take in the glorious view of a genome pileup. Stop and smell the roses! Click on stuff!\nScroll around, zoom in and out a bit!\n2. Go back to chromosome 7:87,483,625-87,484,330. What is the (rough) coverage across this region? (Hint: Look at the coverage track)\nCan you spot the three mutant variants (two small and one larger) in this region? State what the evidence is for them?\nHints\n• Hint1: Look around 87,483,960 for an insertion. How large is it? How many reads does it occur in?\n• Hint2: Look around 87,483,960 for a deletion. How large is it? How many reads does it occur in?\n• Hint3: Zoom out slightly and watch the coverage track between 87,483,700 - 87,484,200.\nOnce you’ve spotted the large change look at reference sequence the edges of the mutation to hazard a guess as to its mechanism.\n4. Can you venture a guess as to what happened here? Why are these mutations present?\nCongratulations you have completed the Read Alignment tutorial. If you have time left then continue to the next (optional) section of the tutorial: Alignment workflows.\nHere is an additional IGV tutorial and refresher: https://github.com/sanger-pathogens/pathogen-informatics-training/blob/master/Notebooks/IGV/IGV.pdf. You can find a copy of this tutorial in your manual. Unfortunately, there is not enough time to complete this tutorial now but you may find it useful to look at it after the course."
  },
  {
    "objectID": "course_modules/Module2/module2_manual.html#ngs-workflows",
    "href": "course_modules/Module2/module2_manual.html#ngs-workflows",
    "title": "Manual",
    "section": "4. NGS Workflows",
    "text": "4. NGS Workflows\nA typical NGS experiment involves more than one sample, potential 10’s or 100’s of samples. During the experiment, a sample may be split across multiple libraries and and a library may be split across multiple sequencing runs (lanes). For example, you may have to increase the number of runs for a specific sample to increase the read-depth (sequencing volume), so you have to prepare multiple libraries.\nTherefore you need a coordinated workflow, driven by standard software to bring it reliably together.\nRead alignment is just the first part of that. Once you have a BAM file for each sequencing run you need to merge them together to produce a BAM file for the library. At this stage it is important to perform de-duplication on the merged data. The main purpose of removing duplicates is to mitigate the effects of PCR amplification bias introduced during library construction. PCR duplicates erroneously inflate the coverage and, if not removed, can give the illusion of high confidence when it is not really there which can have an effect on downstream analysis such as variant calling.\nThe figure below outlines a typical NGS workflow:\n In this part of the tutotial, we have two lanes of illumina sequencing data produced from a single library of yeast. We will use the BWA aligner to align the data to the Saccromyces cerevisiae genome (ftp://ftp.ensembl.org/pub/current_fasta/saccharomyces_cerevisiae/dna/) and produce a merged BAM file for the library.\nTo begin go to the following directory:\ncd /home/manager/course_data/read_alignment/data/Exercise2/60A_Sc_DBVPG6044/library1\n\n4.1 Index the reference\nbwa index ../../../../ref/Saccharomyces_cerevisiae.R64-1-1.dna.toplevel.fa.gz\n\n\n4.2 Align the first sequencing run\nRecall that to align a lane of data to a reference genome we must perform the following steps:\n• Align the data\n• Convert from SAM to BAM\n• Sort the BAM file\n• Index the sorted BAM file\n\n\n4.2.1 Find the data\nGo to the directory that contains the data for the first sequencing run:\ncd lane1\n\n\n4.2.2 Run the alignment\nRemember from earlier in the tutorial that the Unix pipe command allows you to feed the output of one command into the next command. So using Unix pipes, we can combine all of the alignment steps together into one command and do all of this data processing together and avoid writingintermediate files. To do this type the command:\nbwa mem -M -R '@RG\\tID:lane1\\tSM:60A_Sc_DBVPG6044' ../../../../ref/Saccharomyces_cerevisiae.R64-1-1.dna.toplevel.fa.gz s_7_1.fastq.gz s_7_2. fastq.gz | samtools view -bS - | samtools sort -T temp -O bam -o lane1.sorted.bam -\nQ1: What do the -M and -R options do?\nQ2: What does the -bS option do?\nNow index the BAM file:\nsamtools index lane1.sorted.bam\n\n\n4.2.3 Generate QC stats\nNow use samtools to collect some statistics and generate QC plots from the alignment in the BAM file. Type the commands:\nsamtools stats lane1.sorted.bam &gt; lane1.stats.txt\nplot-bamstats -p plot/ lane1.stats.txt\nNow look at the output and answer the following questions:\nQ3: What is the total number of reads?\nQ4: What proportion of the reads were mapped?\nQ5: How many reads were paired correctly/properly?\nQ6: How many reads mapped to a different chromosome?\nQ7: What is the insert size mean and standard deviation?\nIn a web browser open the file called plots.html to view the QC information.\nQ8: How many reads have zero mapping quality?\nQ9: Which of the first fragments or second fragments are higher base quality on average?\n\n\n4.3 Align the second sequencing run\nThere is a second lane of sequencing data in the library1 directory contained in the directory lane2. We want to also align this sequncing data and produce a BAM file.\nGo to the directory that contains the data for the second sequencing run:\ncd ../lane2\nNow align the data in this directory to the yeast reference genome and produce a sorted BAM file.\nNote: This time when you use the bwa mem command use the following header option to specify lane2 as the read group ID:\n@RG\\tID:lane2\\tSM:60A_Sc_DBVPG6044\nQ10: What is the size of the BAM file that is produced?\n\n\n4.4 Merge the BAM files\nGo to the directory that contains the data for the library 60A_Sc_DBVPG6044/library1 . Use ls to get a listing of the files and directories contained in this directory.\ncd ..\npwd\nls\nYou will notice that there are two directories called lane1 and lane2. There were two sequencing lanes produced from this sequencing library. In order to mark library PCR duplicates, we need to merge the two lane BAM files together to produce a single BAM file. We will use the picard tool called ‘MergeSamFiles’ (http://picard.sourceforge.net) to merge the lane BAM files.\nTo find the options for ‘MergeSamFiles’ command, type:\npicard MergeSamFiles\nNow use the I= option to specify both the input BAM files and the O= option to specify the outputfile (e.g. library1.bam). Note: Multiple input files can be specified using multiple I= options\n\n\n4.5 Mark PCR duplicates\nWe will use a program called ‘MarkDuplicates’ that is part of Picard tools (http://picard.source-forge.net) to remove PCR duplicates that may have been introduced during the library construction stage. To find the options for ‘MarkDuplicates’ type:\npicard MarkDuplicates\nNow use the I= option to specify the input BAM file and the O= option to specify the output file (e.g. library1.markdup.bam). You will also need to specify the duplication metrics output file using\nM= (e.g. library1.markdup.metrics).\n**Don’t forget to index your final bam file using samtools index.\nQ11: From looking at the output metrics file - how many reads were marked as duplicates?\nQ12: What was the percent duplication?\n\n\n4.6 Visualise the alignment\nGo to the directory containing the reference genome and uncompress the file as IGV cannot read a compressed file.\ncd /home/manager/course_data/read_alignment/data/ref\ngunzip Saccharomyces_cerevisiae.R64-1-1.dna.toplevel.fa.gz\nStart IGV by typing:\nigv &\n\n\n4.6.1 Load the reference genome\nOn the top menu bar go to ’ Genomes –&gt; Load Genome From File… ‘, go to the “ref” directory and select the file “Saccharomyces_cerevisiae.R64-1-1.dna.toplevel.fa” and click’ Open ’\n\n\n\n\n4.6.2 Load the alignment\nTo load the merged BAM file, on the top menu bar go to ’File –&gt; Load from File…’ and select the library BAM file that you created in the previous step.\n\n\n\n\n4.7 Exercises\n1. Go to Chromosome IV and position 764,292. (Hint: use the navigation bar across the top)\n2. What is the reference base at this position?\n3. Do the reads agree with the reference base?\n4. What about the adjacent position (IV:764,293)? What is the reference base at this position? Is it supported by the reads?\n5. Go to Chromosome IV and position 766,589.\n6. What sort of mutation are the alignments indicating might be present?\n7. Go to Chromosome IV and position 770,137 using the navigation bar across the top.\n8. What sort of mutation are the alignments indicating might be present? Is there anything in the flanking sequence of the reference genome that might make you suspicious about this mutation?\n9. Convert the BAM file to a CRAM file\nYou have reached the end of the Read Alignment tutorial."
  },
  {
    "objectID": "course_modules/Module3/module3.html",
    "href": "course_modules/Module3/module3.html",
    "title": "Overview",
    "section": "",
    "text": "Content by Qasim Ayub, qasim.ayub@monash.edu\n\nModule Title\nVariant calling\n\n\nDuration\n3h\n\n\nKey topics\nIn this module, learners will look at\n\nDNA variation\nVariant calling basics and steps in variant detection\nCommon sources of error in variant calling\nPopulation level variant data, genomic context and clinical relevance of variants.\n\n\n\nActivities\n\nLecture 0.5h\nPractical exercises 2h\nQuiz 0.5h\n\n\n\nManual and practical exercises\nModule manual\nExercises\nSolutions\n\n\nPresentation slides\n(PPT/PDF, to be generated from the module manual)\n\n\nLecture notes or scripts\nPre-recorded lecture\n\n\nDatasets\n\n\nAssessment quiz\nQuestions\nAnswers"
  },
  {
    "objectID": "course_modules/Module3/module3_manual.html",
    "href": "course_modules/Module3/module3_manual.html",
    "title": "Manual",
    "section": "",
    "text": "Introduction and Learning Outcomes\nDNA Variations: Definitions and Types\nPractical Applications of Variant Calling\nVariant Calling Basics\nSteps in Variant Detection\nCommon Sources of Error\nAdvanced Topics in Variant Calling\nAssessing and Benchmarking Variant Calls\nFunctional Annotation and Variant Consequences\nPopulation-Level Variant Data\nReferences and Additional Resources\n\n\n\n\nBy the end of this course, you should be able to:\n\nUnderstand various types of genomic variations and how they arise.\nDescribe how variant calls are generated from raw sequencing data.\nAssess variant quality and visualize variants using tools such as IGV.\nPerform basic variant annotation and interpret biological consequences.\n\n\n\n\nMutations refer to any alteration in the DNA base sequence and can be broadly classified into germline and somatic mutations. Germline mutations occur in the egg or sperm cells and are heritable, meaning they can be passed on to subsequent generations. In contrast, somatic mutations arise in non-germline tissues and do not get inherited by offspring. When examining the types of genomic variations, it is essential to differentiate between large-scale and small-scale changes. Large-scale variations include chromosomal gains or losses (such as aneuploidies), various forms of translocations (for instance, reciprocal and Robertsonian), and copy number variants (CNVs), which are duplications or deletions typically ranging from approximately 1 kilobase to several megabases—collectively accounting for roughly 12% of the human genome. Structural variants (SVs), including insertions, inversions, translocations, and tandem duplications larger than 50 base pairs, also fall into this category. On the other hand, small-scale variations involve more subtle changes such as single nucleotide variants (SNVs), which are simple base substitutions (for example, A→C or G→T), indels that represent small insertions or deletions (less than 50 base pairs), multinucleotide polymorphisms (MNPs) which involve multiple adjacent base substitutions, and microsatellites or short tandem repeats (STRs). STRs are characterized by the repetition of small motifs of 2–6 base pairs—like the “GATA” sequence repeated 7 versus 8 times—which are inherently more variable. Notably, while single nucleotide polymorphisms (SNPs) are usually biallelic with a relatively low mutation rate (around 10^-8 per base pair per generation), STRs are multiallelic with higher mutation rates, making their ancestral states more challenging to infer.\nTo summarise:\nMutation / Variation: Any change in the DNA base sequence.\nGermline mutation: Heritable variation present in egg or sperm cells.\nSomatic mutation: Variation in non-germline tissues; not passed to offspring.\nCopy number variants (CNVs): Duplications or deletions ranging from ~1 kb to many Mb, accounting for roughly 12% of the human genome.\nStructural Variants (SVs): Insertions, inversions, translocations, tandem duplications, etc. (often &gt;50 bp).\nSingle Nucleotide Variants (SNVs): Base substitutions (A→C, G→T, etc.).\nIndels: Small insertions or deletions (&lt;50 bp).\nMultinucleotide Polymorphisms (MNPs): Multiple adjacent base substitutions.\nMicrosatellites / STRs: Short-tandem repeats of 2–6 bp repeated multiple times (e.g., “GATA” repeated 7 vs 8 times).\n\n\n\nCataloging biological diversity is fundamental for understanding population genetics and exploring evolutionary trends, while disease diagnosis leverages the identification of pathogenic mutations in clinical settings. In addition, deciphering genotype-phenotype associations plays a crucial role in locating variants that underlie specific traits or diseases, thereby facilitating pharmacogenomics where drug choice and dosage are tailored based on individual genotypes. DNA forensics employs STR profiling to aid law enforcement and personal identification, and comprehensive population genetics studies help infer demographic history. Finally, marker-assisted selection is widely used in agriculture and breeding programs to improve crop and livestock traits efficiently.\n\n\n\nIn a diploid genome, each human cell contains two copies of every chromosome, which means that each locus on the genome has two alleles. The combination of these alleles is referred to as the genotype, and examples include homozygous genotypes like “RR” and “AA” or heterozygous combinations such as “RA.” When these allele combinations are resolved into phase, meaning the specific arrangement on each individual chromosome is known, they form what is called a haplotype.\nIn the context of variant calling, the term “reference allele” (or “Ref”) refers to the allele that appears in the reference genome, whereas the “alternate allele” (or “Alt”) is the observed variant in the sequenced sample. For a diploid organism, the possible genotypes based on these alleles can be represented as RR (0/0), RA (0/1), or AA (1/1).\nThe Variant Call Format, or VCF, is a widely adopted tab-delimited text format designed for storing gene sequence variations. The format includes key fields such as CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO, FORMAT, and additional sample-specific columns. Notably, the VCF format captures details such as the depth (DP), which is the total number of sequencing reads covering a variant site, and the allelic depth (AD), which provides coverage information for each allele.\nSeveral tools are available for variant calling. BCFtools and samtools are frequently used for identifying single nucleotide variants (SNPs) and small insertions or deletions (indels) from alignment data. For more advanced analyses, tools like GATK’s HaplotypeCaller leverage local re-assembly techniques to improve the accuracy of indel calling. Additionally, other tools such as FreeBayes, Platypus, and DeepVariant contribute to variant calling efforts by offering alternative methodologies and algorithms suited to various data types and experimental designs.\n\n\n\nThe process begins by generating sequencing data, which consists of raw reads produced by sequencing platforms such as Illumina. These reads are subjected to rigorous quality control, including trimming of adapters and filtering out low-quality bases, before being aligned or mapped to a reference genome. Once aligned, a pileup is generated to summarize the number of reads supporting each base at every position, which then informs the variant calling step—determining the genotype probabilities at each locus. Subsequent filtering addresses factors such as base quality, where Phred scores indicate the confidence in each base call, mapping quality that reflects the accuracy of the read’s placement within the genome, and established depth thresholds to ensure sufficient coverage. Variant calling itself can be approached naïvely, using simple allele-frequency thresholds (for example, calling a heterozygote if roughly 50% of reads show a particular base), or through more sophisticated statistical methods that incorporate base and mapping error rates, prior allele frequencies, and other variables to compute a posterior probability for each potential genotype.\n\n\n\nSeveral common sources of error must be considered during variant calling. Homopolymers and repetitive regions, characterized by long runs of identical bases, frequently cause systematic sequencing and mapping errors. Strand bias, where a variant appears exclusively on forward or reverse sequencing reads, often signals technical artefacts rather than genuine biological variants. Incorrect alignments, particularly near insertions or deletions (indels), may lead to false-positive single nucleotide polymorphisms (SNPs). Additionally, extremely high sequencing coverage can indicate repetitive elements or duplicated genomic regions, complicating accurate variant calling. Differences between RNA-seq and DNA-seq data, such as splice junctions and RNA editing events, may also produce apparent variants that do not reflect underlying genomic DNA sequence changes. Finally, variability in experimental conditions can result in non-reproducible calls, emphasizing the importance of validating and replicating findings to ensure reliability.\n\n\n\nSomatic variant calling specifically aims to identify genetic variants present in tumor cells by comparing sequences from tumor samples against matched normal tissues. The primary objective is detecting mutations that may drive cancer progression. Because tumors are heterogeneous, subclonal variants—mutations present in only a subset of cells—often exhibit widely varying allele fractions, complicating their detection and interpretation. Specialized bioinformatics pipelines such as Mutect2 and Strelka2 have been developed to address these complexities and accurately distinguish true somatic mutations from background noise.\nIndel calling presents unique challenges, notably due to elevated sequencing error rates in regions such as microsatellites and homopolymers, where accurate base calling is particularly difficult. Additionally, indels can be represented in multiple valid ways by different alignment tools, leading to inconsistencies in their annotation and interpretation. As a result, complex indel regions often suffer from low reproducibility, with significant discrepancies observed across different variant callers. Users are encouraged to validate indel calls rigorously, especially in clinical or sensitive research contexts.\nEmerging approaches in variant calling are addressing these limitations. Local de novo assembly methods, implemented in tools like GATK’s HaplotypeCaller, Scalpel, and Octopus, reconstruct local genomic haplotypes directly from sequencing reads, helping resolve complex variants more effectively. Additionally, newer methods employ variation graphs—data structures that represent multiple known variants simultaneously—to improve alignment accuracy and variant calling performance, particularly in regions of high genetic complexity or variability. These innovative approaches promise to significantly enhance the accuracy and comprehensiveness of genomic analyses moving forward.\n\n\n\nThe transition/transversion (Ts/Tv) ratio is a critical metric used to assess the quality of variant calls. Transitions (Ts)—base substitutions within purines (A↔︎G) or pyrimidines (C↔︎T)—occur more frequently than transversions (Tv), substitutions between purines and pyrimidines. For high-quality SNP datasets in humans, a Ts/Tv ratio of approximately 2 to 3 is typically expected; deviations from this range can indicate underlying errors in variant calling.\nAnother key consideration is the concept of a callable genome, as certain regions of the genome are inherently difficult to analyze due to repetitive sequences, structural complexities, or extreme GC content. Not all genomic regions are equally accessible or “callable,” and thus it is beneficial to utilize established benchmark sets, such as the Genome in a Bottle project, which define high-confidence genomic regions suitable for accurate variant detection and performance assessment.\nWhen evaluating variant-calling performance, metrics such as precision and recall become essential. Precision represents the proportion of called variants that are correct (true positives), while recall, also known as sensitivity, measures the proportion of true variants correctly identified. To accurately compute these metrics, benchmarking tools like hap.py or vcfeval are routinely employed, allowing researchers to systematically assess and optimize variant-calling workflows for reliability and accuracy.\n\n\n\nFunctional annotation of genetic variants is an essential step in understanding their potential biological impacts. Annotation tools such as BCFtools/csq, Ensembl Variant Effect Predictor (VEP), and ANNOVAR are commonly utilized to systematically determine the genomic context of variants, categorizing them as coding, intronic, untranslated region (UTR), or intergenic. These tools further predict the functional consequences of variants, distinguishing between synonymous changes, which do not alter the amino acid sequence, and non-synonymous or missense mutations, which result in amino acid substitutions. More severe mutations include nonsense variants, which introduce premature stop codons, and frameshift variants, which disrupt the reading frame of the protein. Variant pathogenicity is often classified into categories such as pathogenic, likely pathogenic, benign, likely benign, or variants of uncertain significance (VUS). These classifications integrate population frequency data, computational prediction models, family-based segregation analyses, and results from functional assays to provide meaningful insights into the clinical or biological relevance of each variant.\n\n\n\nPopulation-level variant datasets provide critical resources for interpreting genetic variation in a global context. The 1000 Genomes Project, for instance, encompasses genomic data from over 2,500 individuals representing 26 distinct populations worldwide, with an average sequencing coverage of approximately 7–8X. This extensive collection offers researchers a comprehensive snapshot of human genetic diversity, aiding studies in population genetics, evolutionary biology, and clinical genomics.\nComplementary to the 1000 Genomes Project, resources like HapMap, HGDP-CEPH, and gnomAD further enrich our understanding of global genetic variation. The International HapMap Project, although now archived, was an early effort aimed at cataloging common single nucleotide polymorphisms (SNPs) across diverse human populations. The HGDP-CEPH panel provides valuable genomic data from a broad array of worldwide populations, offering insights into human evolutionary history and population structure. The Genome Aggregation Database (gnomAD) expands upon these earlier efforts by compiling allele frequency data from tens of thousands of sequenced individuals, greatly enhancing our ability to interpret genetic variants, understand their functional significance, and accurately determine their frequencies across different populations.\n\n\n\nOlson, N.D., et al. (2023) Nature Reviews Genetics 24:464–483.\nThe 1000 Genomes Project Consortium. (2015) Nature 526:68–74.\nCann, H.M., et al. (2002) Science 296:261–262. (HGDP-CEPH)\nEnsembl Variation documentation: https://www.ensembl.org/info/docs/variation/index.html\nBCFtools: https://github.com/samtools/bcftools\nVEP (Variant Effect Predictor): https://github.com/willmclaren/ensembl-vep\ngnomAD: https://gnomad.broadinstitute.org/about\nFor course-related inquiries, contact: qasim.ayub@monash.edu"
  },
  {
    "objectID": "course_modules/Module3/module3_manual.html#section",
    "href": "course_modules/Module3/module3_manual.html#section",
    "title": "Manual",
    "section": "",
    "text": "Introduction and Learning Outcomes\nDNA Variations: Definitions and Types\nPractical Applications of Variant Calling\nVariant Calling Basics\nSteps in Variant Detection\nCommon Sources of Error\nAdvanced Topics in Variant Calling\nAssessing and Benchmarking Variant Calls\nFunctional Annotation and Variant Consequences\nPopulation-Level Variant Data\nReferences and Additional Resources\n\n\n\n\nBy the end of this course, you should be able to:\n\nUnderstand various types of genomic variations and how they arise.\nDescribe how variant calls are generated from raw sequencing data.\nAssess variant quality and visualize variants using tools such as IGV.\nPerform basic variant annotation and interpret biological consequences.\n\n\n\n\nMutations refer to any alteration in the DNA base sequence and can be broadly classified into germline and somatic mutations. Germline mutations occur in the egg or sperm cells and are heritable, meaning they can be passed on to subsequent generations. In contrast, somatic mutations arise in non-germline tissues and do not get inherited by offspring. When examining the types of genomic variations, it is essential to differentiate between large-scale and small-scale changes. Large-scale variations include chromosomal gains or losses (such as aneuploidies), various forms of translocations (for instance, reciprocal and Robertsonian), and copy number variants (CNVs), which are duplications or deletions typically ranging from approximately 1 kilobase to several megabases—collectively accounting for roughly 12% of the human genome. Structural variants (SVs), including insertions, inversions, translocations, and tandem duplications larger than 50 base pairs, also fall into this category. On the other hand, small-scale variations involve more subtle changes such as single nucleotide variants (SNVs), which are simple base substitutions (for example, A→C or G→T), indels that represent small insertions or deletions (less than 50 base pairs), multinucleotide polymorphisms (MNPs) which involve multiple adjacent base substitutions, and microsatellites or short tandem repeats (STRs). STRs are characterized by the repetition of small motifs of 2–6 base pairs—like the “GATA” sequence repeated 7 versus 8 times—which are inherently more variable. Notably, while single nucleotide polymorphisms (SNPs) are usually biallelic with a relatively low mutation rate (around 10^-8 per base pair per generation), STRs are multiallelic with higher mutation rates, making their ancestral states more challenging to infer.\nTo summarise:\nMutation / Variation: Any change in the DNA base sequence.\nGermline mutation: Heritable variation present in egg or sperm cells.\nSomatic mutation: Variation in non-germline tissues; not passed to offspring.\nCopy number variants (CNVs): Duplications or deletions ranging from ~1 kb to many Mb, accounting for roughly 12% of the human genome.\nStructural Variants (SVs): Insertions, inversions, translocations, tandem duplications, etc. (often &gt;50 bp).\nSingle Nucleotide Variants (SNVs): Base substitutions (A→C, G→T, etc.).\nIndels: Small insertions or deletions (&lt;50 bp).\nMultinucleotide Polymorphisms (MNPs): Multiple adjacent base substitutions.\nMicrosatellites / STRs: Short-tandem repeats of 2–6 bp repeated multiple times (e.g., “GATA” repeated 7 vs 8 times).\n\n\n\nCataloging biological diversity is fundamental for understanding population genetics and exploring evolutionary trends, while disease diagnosis leverages the identification of pathogenic mutations in clinical settings. In addition, deciphering genotype-phenotype associations plays a crucial role in locating variants that underlie specific traits or diseases, thereby facilitating pharmacogenomics where drug choice and dosage are tailored based on individual genotypes. DNA forensics employs STR profiling to aid law enforcement and personal identification, and comprehensive population genetics studies help infer demographic history. Finally, marker-assisted selection is widely used in agriculture and breeding programs to improve crop and livestock traits efficiently.\n\n\n\nIn a diploid genome, each human cell contains two copies of every chromosome, which means that each locus on the genome has two alleles. The combination of these alleles is referred to as the genotype, and examples include homozygous genotypes like “RR” and “AA” or heterozygous combinations such as “RA.” When these allele combinations are resolved into phase, meaning the specific arrangement on each individual chromosome is known, they form what is called a haplotype.\nIn the context of variant calling, the term “reference allele” (or “Ref”) refers to the allele that appears in the reference genome, whereas the “alternate allele” (or “Alt”) is the observed variant in the sequenced sample. For a diploid organism, the possible genotypes based on these alleles can be represented as RR (0/0), RA (0/1), or AA (1/1).\nThe Variant Call Format, or VCF, is a widely adopted tab-delimited text format designed for storing gene sequence variations. The format includes key fields such as CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO, FORMAT, and additional sample-specific columns. Notably, the VCF format captures details such as the depth (DP), which is the total number of sequencing reads covering a variant site, and the allelic depth (AD), which provides coverage information for each allele.\nSeveral tools are available for variant calling. BCFtools and samtools are frequently used for identifying single nucleotide variants (SNPs) and small insertions or deletions (indels) from alignment data. For more advanced analyses, tools like GATK’s HaplotypeCaller leverage local re-assembly techniques to improve the accuracy of indel calling. Additionally, other tools such as FreeBayes, Platypus, and DeepVariant contribute to variant calling efforts by offering alternative methodologies and algorithms suited to various data types and experimental designs.\n\n\n\nThe process begins by generating sequencing data, which consists of raw reads produced by sequencing platforms such as Illumina. These reads are subjected to rigorous quality control, including trimming of adapters and filtering out low-quality bases, before being aligned or mapped to a reference genome. Once aligned, a pileup is generated to summarize the number of reads supporting each base at every position, which then informs the variant calling step—determining the genotype probabilities at each locus. Subsequent filtering addresses factors such as base quality, where Phred scores indicate the confidence in each base call, mapping quality that reflects the accuracy of the read’s placement within the genome, and established depth thresholds to ensure sufficient coverage. Variant calling itself can be approached naïvely, using simple allele-frequency thresholds (for example, calling a heterozygote if roughly 50% of reads show a particular base), or through more sophisticated statistical methods that incorporate base and mapping error rates, prior allele frequencies, and other variables to compute a posterior probability for each potential genotype.\n\n\n\nSeveral common sources of error must be considered during variant calling. Homopolymers and repetitive regions, characterized by long runs of identical bases, frequently cause systematic sequencing and mapping errors. Strand bias, where a variant appears exclusively on forward or reverse sequencing reads, often signals technical artefacts rather than genuine biological variants. Incorrect alignments, particularly near insertions or deletions (indels), may lead to false-positive single nucleotide polymorphisms (SNPs). Additionally, extremely high sequencing coverage can indicate repetitive elements or duplicated genomic regions, complicating accurate variant calling. Differences between RNA-seq and DNA-seq data, such as splice junctions and RNA editing events, may also produce apparent variants that do not reflect underlying genomic DNA sequence changes. Finally, variability in experimental conditions can result in non-reproducible calls, emphasizing the importance of validating and replicating findings to ensure reliability.\n\n\n\nSomatic variant calling specifically aims to identify genetic variants present in tumor cells by comparing sequences from tumor samples against matched normal tissues. The primary objective is detecting mutations that may drive cancer progression. Because tumors are heterogeneous, subclonal variants—mutations present in only a subset of cells—often exhibit widely varying allele fractions, complicating their detection and interpretation. Specialized bioinformatics pipelines such as Mutect2 and Strelka2 have been developed to address these complexities and accurately distinguish true somatic mutations from background noise.\nIndel calling presents unique challenges, notably due to elevated sequencing error rates in regions such as microsatellites and homopolymers, where accurate base calling is particularly difficult. Additionally, indels can be represented in multiple valid ways by different alignment tools, leading to inconsistencies in their annotation and interpretation. As a result, complex indel regions often suffer from low reproducibility, with significant discrepancies observed across different variant callers. Users are encouraged to validate indel calls rigorously, especially in clinical or sensitive research contexts.\nEmerging approaches in variant calling are addressing these limitations. Local de novo assembly methods, implemented in tools like GATK’s HaplotypeCaller, Scalpel, and Octopus, reconstruct local genomic haplotypes directly from sequencing reads, helping resolve complex variants more effectively. Additionally, newer methods employ variation graphs—data structures that represent multiple known variants simultaneously—to improve alignment accuracy and variant calling performance, particularly in regions of high genetic complexity or variability. These innovative approaches promise to significantly enhance the accuracy and comprehensiveness of genomic analyses moving forward.\n\n\n\nThe transition/transversion (Ts/Tv) ratio is a critical metric used to assess the quality of variant calls. Transitions (Ts)—base substitutions within purines (A↔︎G) or pyrimidines (C↔︎T)—occur more frequently than transversions (Tv), substitutions between purines and pyrimidines. For high-quality SNP datasets in humans, a Ts/Tv ratio of approximately 2 to 3 is typically expected; deviations from this range can indicate underlying errors in variant calling.\nAnother key consideration is the concept of a callable genome, as certain regions of the genome are inherently difficult to analyze due to repetitive sequences, structural complexities, or extreme GC content. Not all genomic regions are equally accessible or “callable,” and thus it is beneficial to utilize established benchmark sets, such as the Genome in a Bottle project, which define high-confidence genomic regions suitable for accurate variant detection and performance assessment.\nWhen evaluating variant-calling performance, metrics such as precision and recall become essential. Precision represents the proportion of called variants that are correct (true positives), while recall, also known as sensitivity, measures the proportion of true variants correctly identified. To accurately compute these metrics, benchmarking tools like hap.py or vcfeval are routinely employed, allowing researchers to systematically assess and optimize variant-calling workflows for reliability and accuracy.\n\n\n\nFunctional annotation of genetic variants is an essential step in understanding their potential biological impacts. Annotation tools such as BCFtools/csq, Ensembl Variant Effect Predictor (VEP), and ANNOVAR are commonly utilized to systematically determine the genomic context of variants, categorizing them as coding, intronic, untranslated region (UTR), or intergenic. These tools further predict the functional consequences of variants, distinguishing between synonymous changes, which do not alter the amino acid sequence, and non-synonymous or missense mutations, which result in amino acid substitutions. More severe mutations include nonsense variants, which introduce premature stop codons, and frameshift variants, which disrupt the reading frame of the protein. Variant pathogenicity is often classified into categories such as pathogenic, likely pathogenic, benign, likely benign, or variants of uncertain significance (VUS). These classifications integrate population frequency data, computational prediction models, family-based segregation analyses, and results from functional assays to provide meaningful insights into the clinical or biological relevance of each variant.\n\n\n\nPopulation-level variant datasets provide critical resources for interpreting genetic variation in a global context. The 1000 Genomes Project, for instance, encompasses genomic data from over 2,500 individuals representing 26 distinct populations worldwide, with an average sequencing coverage of approximately 7–8X. This extensive collection offers researchers a comprehensive snapshot of human genetic diversity, aiding studies in population genetics, evolutionary biology, and clinical genomics.\nComplementary to the 1000 Genomes Project, resources like HapMap, HGDP-CEPH, and gnomAD further enrich our understanding of global genetic variation. The International HapMap Project, although now archived, was an early effort aimed at cataloging common single nucleotide polymorphisms (SNPs) across diverse human populations. The HGDP-CEPH panel provides valuable genomic data from a broad array of worldwide populations, offering insights into human evolutionary history and population structure. The Genome Aggregation Database (gnomAD) expands upon these earlier efforts by compiling allele frequency data from tens of thousands of sequenced individuals, greatly enhancing our ability to interpret genetic variants, understand their functional significance, and accurately determine their frequencies across different populations.\n\n\n\nOlson, N.D., et al. (2023) Nature Reviews Genetics 24:464–483.\nThe 1000 Genomes Project Consortium. (2015) Nature 526:68–74.\nCann, H.M., et al. (2002) Science 296:261–262. (HGDP-CEPH)\nEnsembl Variation documentation: https://www.ensembl.org/info/docs/variation/index.html\nBCFtools: https://github.com/samtools/bcftools\nVEP (Variant Effect Predictor): https://github.com/willmclaren/ensembl-vep\ngnomAD: https://gnomad.broadinstitute.org/about\nFor course-related inquiries, contact: qasim.ayub@monash.edu"
  },
  {
    "objectID": "course_modules/Module3/module3_exercises.html",
    "href": "course_modules/Module3/module3_exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "1 Variant Calling\n\n\n1.1 Introduction\nVariant calling is the process of identifying differences between the reference genome and the samples that have been sequenced. These differences can be single nucleotide polymorphisms (SNPs), multi-nucleotide polymorphisms (MNPs) or small insertions and deletions (indels) and examples of each of these are shown below.\n\nFigure 1: SNPs and small insertions and deletions\n\n\n1.2 Learning outcomes\nOn completion of the tutorial, you can expect to be able to:\n• Perform variant calling (SNPs and indels) using standard tools\n• Assess the quality/confidence of a variant call\n• Filter variant calls to remove low quality/confidence calls\n• Perform variant calling across multiple samples\n• Visualise variants using standard tools\n• Annotate variants with consequence calls\n\n\n1.3 Tutorial sections\nThis tutorial comprises the following sections:\n\nPerforming variant calling\nFiltering variants\nMulti-sample variant calling\nVisualising variants\n\n\n\n1.4 Authors\nThis tutorial was written by Jacqui Keane based on material from Thomas Keane and Petr Danecek.\nThere is also an additional (optional) section: 5. Variant annotation\n\n\n1.5 Running the commands from this tutorial\nYou can follow this tutorial by typing all the commands you see into a terminal window. This is similar to the “Command Prompt” window on MS Windows systems, which allows the user to type DOS commands to manage files.\nTo get started, open a new terminal on your computer and type the command below:\ncd ~/course_data/variant_calling/data\nNow you can follow the instructions in the tutorial from here.\n\n\n1.6 Let’s get started!\nThis tutorial assumes that you have samtools, bcftools and IGV installed on your computer. These are already installed on the VM you are using. To check that these are installed, you can run the following commands:\nsamtools --help\nbcftools --help\nigv\nThis should return the help message for samtools and bcftools. The final command should launch the genome viewer IGV. You can close the IGV software, we will use it later in this tutorial to visualise variants.\nTo get started with the tutorial, go to to the first section: Performing variant calling\n\n\n2 Performing Variant Calling\nWhen performing variant calling we need the aligned sequences in SAM, BAM or CRAM format and the reference genome that we want to call varants against.\nFirst, check you are in the correct directory.\npwd\nIt should display something like: /home/manager/course_data/variant_calling/data\n\n\n2.1 Assessing the input data\nTo list the files in the current directory, type\nls -lh\nThe listing shows aligned data for two mouse strains A/J and NZO (A_J.bam and NZO.bam) and the chromosome 19 of the mouse reference genome (GRCm38_68.19.fa).\nBefore performing variant calling, it is important to check the quality of the data that you will be working with. We have already seen how to do this in the QC and Data Formats and Read Alignment sessions. The commands would look like:\nsamtools stats -r GRCm38_68.19.fa A_J.bam &gt; A_J.stats\nsamtools stats -r GRCm38_68.19.fa NZO.bam &gt; NZO.stats\nplot-bamstats -r GRCm38_68.19.fa.gc -p A_J.graphs/ A_J.stats\nplot-bamstats -r GRCm38_68.19.fa.gc -p NZO.graphs/ NZO.stats\nYou do not need to run these QC checks on this data and for this we will assume that QC has already been performed and the data is of good quality.\n\n\n2.2 Generating pileup\nThe command samtools mpileup prints the read bases that align to each position in the reference genome. Type the command:\nsamtools mpileup -f GRCm38_68.19.fa A_J.bam | less -S\nEach line corresponds to a position on the genome.\nThe columns are: chromosome, position, reference base, read depth, read bases (dot . and comma , indicate match on the forward and on the reverse strand; ACGTN and acgtn a mismatch on the forward and the reverse strand) and the final column is the base qualities encoded into characters.\nThe caret symbol ^ marks the start of a read, the dollar sign $ the end of a read, deleted bases are represented by asterisk *.\n\n\n2.3 Generating genotype likelihoods and calling variants\nThis output can be used for a simple consensus calling. One rarely needs this type of output. Instead, for a more sophisticated variant calling method, see the next section.\n\n\n2.2.1 Exercises\nLook at the output from the mpileup command above and answer the following questions.\nQ1: What is the read depth at position 10001994? (Rather than scrolling to the position, use the substring searching capabilities of less: press /, then type 10001994 followed by enter to find the position.)\nQ2: What is the reference allele and the alternate allele at position 10001994?\nQ3: How many reads call the reference allele at position 10001994 and how many reads call the alternate allele at position 10001994?\n\n\n2.3 Generating genotype likelihoods and calling variants\nThe bcftools mpileup command can be used to generate genotype likelihoods. (Beware: the command mpileup is present in both samtools and bcftools, but in both they do different things. While samtools mpileup produces the text pileup output seen in the previous exercise, bcftools mpileup generates a VCF file with genotype likelihoods.)\nRun the following command (when done, press q to quit the viewing mode):\nbcftools mpileup -f GRCm38_68.19.fa A_J.bam | less -S\nThis generates an intermediate output which contains genotype likelihoods and other raw information necessary for variant calling. This output is usually streamed directly to the caller like this\nbcftools mpileup -f GRCm38_68.19.fa A_J.bam | bcftools call -m | less -S\nThe output above contains both variant and non-variant positions. Check the input/output options section of the bcftools call usage page and see if there is an option to print out only variant sites.\nThen construct a command to print out variant sites only:\nThe INFO and FORMAT fields of each entry tells us something about the data at the position in the genome. It consists of a set of key-value pairs with the tags being explained in the header of the VCF file (see the ##INFO and ##FORMAT lines in the header).\nWe can tell mpileup to add additional ##INFO and ##FORMAT information to the output. For example, we can ask it to add the FORMAT/AD tag which informs about the number of high-quality reads that support alleles listed in REF and ALT columns. The list of all available tags can be printed with the command:\nbcftools mpileup -a ?\nNow let’s run the variant calling again, this time adding the -a AD option. We will also add the -Ou option so that it streams a binary uncompressed BCF into call. This is to avoid the unnecessary CPU overhead of formatting the internal binary format to plain text VCF only to be immediately formatted back to the internal binary format again.\nbcftools mpileup -a AD -f GRCm38_68.19.fa A_J.bam -Ou | bcftools call -mv -o out.vcf\n\n\n2.4 Exercises\nLook at the content of the VCF file produced above and answers the questions that follow.\nless -S out.vcf\nQ1: What is the reference allele and the alternate allele at position 10001994?\nQ2: What is the total raw read depth at position 10001994?\nNote: This number may be different from the values we obtained earlier, because some low quality reads or bases might have been filtered previously.\nQ3: What is the number of high-quality reads supporting the SNP call at position 10001994? How many reads support the reference allele and how many support the alternate allele?\nHint: Look up the AD tag in the FORMAT column: the first value gives the number of reads calling the reference allelle and the second gives the number of reads calling the alternate alleles.\nQ4: What sort of event is happening at position 10003649?\nCongratulations, you have sucessfully called variants from some NGS data. Now continue to the next section of the tutorial: filtering variants.\n\n\n3 Variant Filtering\nIn the next series of commands we will learn how to extract information from VCFs and how to filter the raw calls. We will use the bcftools commands again. Most of the commands accept the -i, – include and -e, –exclude options https://samtools.github.io/bcftools/bcftools.html# expressions which will be useful when filtering using fixed thresholds. We will estimate the quality of the callset by calculating the ratio of transitions and transversions https://en.wikipedia.org/wiki/Transversion.\nWhen drafting commands, it is best to build them gradually. This prevents errors and allows you to verify that they work as expected. Let’s start with printing a simple list of positions from the VCF using the bcftools query command https://samtools.github.io/bcftools/bcftools.html#query and pipe through the head command to limit the printed output to the first few lines:\nbcftools query --format 'POS=%POS\\n' out.vcf | head\nAs you can see, the command expanded the formatting expression POS=%POSin the following way: for each VCF record the string POS= was copied verbatim, the string %POS was replaced by the VCF coordinate stored in the POS column, and then the newline character ended each line. (Without the newline character, positions from the entire VCF would be printed on a single line.)\nNow add the reference and the alternate allele to the output. They are stored in the REF and ALT column in the VCF, and let’s separate them by a comma:\nbcftools query -f'%POS %REF,%ALT\\n' out.vcf | head\nIn the next step add the quality (%QUAL), genotype (%GT) and sequencing depth (%AD) to the output. Note that FORMAT tags must be enclosed within square brackets […] to iterate over all samples in the VCF. (Check the Extracting per-sample tags section in the manual https://samtools.github.io/bcftools/howtos/query.html for a more detailed explanation why the square brackets are needed.)\nbcftools query -f'%POS %QUAL [%GT %AD] %REF %ALT\\n' out.vcf | head\nNow we are able to quickly extract important information from the VCFs. Now let’s filter rows with QUAL smaller than 30 by adding the filtering expression –exclude ‘QUAL&lt;30’ or –include ‘QUAL&gt;=30’ like this:\nbcftools query -f'%POS %QUAL [%GT %AD] %REF %ALT\\n' -i'QUAL&gt;=30' out.vcf | head\nNow compare the result with the output from the previous command, were the low-quality lines removed?\nIn the next step limit the output to SNPs and ignore indels by adding the type=“snp” condition to the filtering expression. Because both conditions must be valid at the same time, we request the AND logic using the && operator:\nbcftools query -f'%POS %QUAL [%GT %AD] %REF %ALT\\n' -i'QUAL&gt;=30 && type=\"snp\"'out.vcf | head\n\n\n3.1 Exercises\nQ1: Can you print SNPs with QUAL bigger than 30 and require at least 25 alternate reads in the AD tag?\nRemember, the first value of the AD tag is the number of reference reads, the second is the number of alternate reads, therefore you will need to query the second value of the AD tag. The first value can be queried as AD[0] and the second as AD[1] (the allele indexes are zero-based). In case of FORMAT fields, also the queried sample must be selected as AD[sample:subfield] . Therefore add to the expression the condition AD[0:1] &gt;= 25 to select the first (and in our case the only one) sample or AD[*:1] &gt;= 25 to select any sample for which the condition is valid.\nNow we can filter our callset. In order to evaluate the quality, we will use bcftools stats to calculate the ratio of transitions vs transversions. We start by checking what is the ts/tv of the raw unfiltered callset. The stats command produces a text output, we extract the field of interest as follows:\nbcftools stats out.vcf | less\nbcftools stats out.vcf | grep TSTV\nbcftools stats out.vcf | grep TSTV | cut -f5\nQ2: Calculate ts/tv of the set filtered as above by adding -i ‘QUAL&gt;=30 && AD[*:1]&gt;=25’ to the bcftools stats command.\n(Here the asterisk followed by a colon tells the program to apply the filtering to all samples. At least one sample must pass in order for a site to pass.) After applying the filter, you should observe an increased ts/tv value.\nQ3: Can you do the reverse and find out the ts/tv of the removed sites? Use the -e option instead of -i. The ts/tv of the removed low-quality sites should be lower.\nQ4: The test data come from an inbred homozygous mouse, therefore any heterozygous genotypes are most likely mapping and alignment artefacts. Can you find out what is the ts/tv of the heterozyous SNPs? Do you expect higher or lower ts/tv? Use the filtering expression -i ‘GT=“het”’ to select sites with heterozygous genotypes.\nAnother useful command is bcftools filter which allows to “soft filter” the VCF: instead of removing sites, it can annotate the FILTER column to indicate sites which fail. Apply the above filters (‘QUAL&gt;=30 && AD[*:1]&gt;=25’) to produce a final callset, adding also the –SnpGap and the –IndelGap option to filter variants in close proximity to indels:\nbcftools filter -s LowQual -i'QUAL&gt;=30 && AD[*:1]&gt;=25' -g8 -G10 out.vcf -o out.flt.vcf\n\n\n3.2 Variant normalization\nThe same indel variant can be represented in different ways. For example, consider the following 2bp deletion. Although the resulting sequence does not change, the deletion can be placed at two different positions within the short repeat:\n12345\nTTCTC\nPOS=1 T–TC\nPOS=3 TTC–\nIn order to be able to compare indels between two datasets, we left-align such variants.\nQ5: Use the bcftools norm command to normalize the filtered callset. Note that you will need to provide the –fasta-ref option. Check in the output how many indels were realigned.\nNow continue to the next section of the tutorial: Multi-sample variant calling\n4 Calling Variants Across Multiple Samples\nIn many types of experiments we sequence multiple samples and compare their genetic variation across samples. The single-sample variant calling we have done so far has the disadvantage of not providing information about reference genotypes. Because only variant sites are stored, we are not able to distinguish between records missing due to reference genotypes versus records missing due to lack of coverage.\nIn this section we will call variants across two mouse samples.\nTo begin, check that there are two BAM files in the directory.\nls *.bam\nNow modify the variant calling command from the previous section to use both BAM files. Write the output to a BCF file called multi.bcf.\nNow index the file multi.bcf\nFilter the file multi.bcf using the same filters as the previous section and write the output to a BCF file called multi.filt.bcf.\nNow index the multi.filt.bcf file.\n\n\n4.1 Exercises\nQ1: What is the ts/tv of the raw calls and of the filtered set?\nQ2: What is the ts/tv of the removed sites?\nNow continue to the next section of the tutorial: Visualising variants\n\n\n5 Variant visualisation\nIt is often useful to visually inspect a SNP or indel of interest in order to assess the quality of the variant and interpret the genomic context of the variant. We can use the IGV tool to view some of the variant positions from the VCF file.\nStart IGV by typing:\nigv\n\n\n5.1 Load the reference genome\nOpen the mouse reference genome”\nGo to ’ Genomes -&gt; Load Genome From Server… ’ and select “Mouse mm10”. This is a synonym for GRCm38, which is the current mouse assembly (reference genome)\n\n\n5.2 Load the alignment\nLoad the alignment file for the sample A_J (A_J.bam).\nGo to ’ File -&gt; Load from File… ‘. Select the “A_J.bam” BAM file that you created in the previous section and click’ Open ’.\n\n\n5.3 Exercises\nUse the IGV navigation bar, go to the region chr19:10,001,874-10,002,017 and inspect the SNP at position 10001946.\nQ1: How many forward aligned reads support the SNP call?\nHint; Hover the mouse pointer over the coverage bar at the top (or click, depending on the IGV settings) to get this information.\nQ2: Was this SNP called by bcftools?\nHint Use bcftools view -H -r chr19:10001946 multi.filt.bcf to verify\nQ3: Did this SNP pass the filters?\nHint Look for this information in the BCF file\nUse the IGV navigation bar, go to the region chr19:10072443 and inspect the SNP at position 10072443.\nQ4: Was this SNP called by bcftools?\nQ5: Did the SNP pass the filters?\nQ6: Does this look like a real SNP? Please explain why.\nNow continue to the next section of the tutorial: Variant annotation\n\n\n6 Variant annotation\nVariant annotation is used to help researchers filter and prioritise functionally important variants for further study. There are several popular programs available for annotating variants. These include:\n• bcftools csq\n• Ensembl VEP (Variant Effect Predictor)\n• SnpEff\nThese tools can be used to to predict the functional consequence of the variants on the protein (e.g. whether a variant is mis-sense, stop-gain, frameshift inducing etc).\n\n\n6.1 bcftools csq\nHere we will use the lightweight bcftools csq command to annotate the variants. Type the command:\nbcftools view -i 'FILTER=\"PASS\"' multi.filt.bcf | bcftools csq -p m -f GRCm38_68.19.fa -g Mus_musculus.part.gff3.gz -Ob -o multi.filt.annot.bcf\nThe command takes VCF as input, the -f option specifies the reference file that the data was aligned\ntoo and the -g option specifies the GFF file that contains the gene models for the reference. Because our data is not phased, we provide the -p option (which does not actually phase the data, but tells the program to make an assumption about the phase). The -Ob option ensures the command produces compressed BCF as output.\nNow index the BCF file:\nbcftools index multi.filt.annot.bcf\n\n\n6.2 Exercises\nQ1 Use the bcftools query -f ‘%BCSQ’ command to extract the consequence at position 19:10088937.\nQ2 What is the functional annotation at this site?\nQ3 What is the amino acid change?\nCongratulations you have reached the end of the variant calling tutorial. For the answers to the exercises in this tutorial please visit answers."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "The materials provided in this repository are FREE to use. This work is licensed under a Creative Commons Attribution 4.0 International License. Reuse is encouraged with acknowledgement.\n\nAll materials to be added in markdown (with extension .qmd), except for recorded lectures.\nThere are no slides on this website. Instead, you will find instructions on how to generate slides from the markdown content."
  },
  {
    "objectID": "template_course.html",
    "href": "template_course.html",
    "title": "template_course",
    "section": "",
    "text": "Course Overview\n- Course Title\n- Course Description: Short and extended versions\n- Course format \n- Target Audience: (e.g., clinicians, researchers, students)\n- Prerequisites: Knowledge or skills expected\n \nLearning Outcomes\n- Clearly defined, measurable outcomes using Blooms action verbs \n- Mapped to competencies if relevant\nAssessment\n- Formative assessments (quizzes, exercises, peer review)\n- Summative assessments (final project, test, reflection)\n- Rubrics and grading templates for instructors \n- Submission methods/platform\n- Model answers or guides \n \nTeaching Platform & Tech Tools\n- Platforms guide: e.g., GitHub Classroom, Google classroom, Moodle, Zoom etc \n- Accounts/Access setup instructions\n- Tools used in communication and teaching: e.g., Zoom, Slack, BLAST, RStudio\n- Instructions for setting up any required environments (Docker, Conda, virtual machines)\n \nResources & References\n- Core readings (articles, textbooks)\n- Supplementary materials (websites, tools, videos)\n- Glossary of terms\n- FAQs and Troubleshooting guide (tech and teaching)\n \nInstructor & Facilitator Guide - important to include\n- Adult learning strategies [see T3 resource] \n- Teaching tips for each module\n- Common learner questions/issues \n- Discussion prompts\n- Inclusivity guidance [see T3 resource, UDL] \n \n \nEvaluation & Feedback Templates\n- Evaluation questions [what do we want to know] \n- Data collection: learner feedback forms, instructor reflection log/observation structured notes, ost course survey etc)\n- Plan for data analysis \n- Plan for results dissemination"
  },
  {
    "objectID": "course_modules/Module3/module3_assessement_answers.html",
    "href": "course_modules/Module3/module3_assessement_answers.html",
    "title": "Quiz answers",
    "section": "",
    "text": "Q1.\nCorrect Answer: B Explanation: Germline mutations occur in egg or sperm cells, meaning they are heritable, while somatic mutations occur in non-reproductive tissues and are not passed on.\n\n\nQ2.\nCorrect Answer: B Explanation: A duplication involving 2 kb is an example of a copy number variant, which is considered a large-scale variation.\n\n\nQ3.\nCorrect Answer: C Explanation: SNVs refer to single base substitutions, and indels refer to small insertions or deletions generally less than 50 bp.\n\n\nQ4.\nCorrect Answer: C Explanation: Determining the speed of DNA replication is not a direct application of variant calling.\n\n\nQ5.\nCorrect Answer: B Explanation: Phased haplotypes allow for the determination of which variants are inherited together on the same chromosome, enhancing genotype interpretation.\n\n\nQ6.\nCorrect Answer: C Explanation: “TEMP” is not a standard field in the VCF format, while CHROM, POS, and ALT are.\n\n\nQ7.\nCorrect Answer: C Explanation: The correct order is to generate sequencing data, perform quality control, align the reads, generate a pileup, and then call variants.\n\n\nQ8.\nCorrect Answer: B Explanation: Homopolymers and repetitive regions are known to cause systematic errors in sequencing and mapping, leading to inaccuracies in variant calling.\n\n\nQ9.\nCorrect Answer: C Explanation: High-quality human SNP datasets typically have a Ts/Tv ratio of around 2 to 3.\n\n\nQ10.\nCorrect Answer: A Explanation: Population-level datasets provide valuable insights into human genetic diversity and help determine variant frequencies across various populations."
  },
  {
    "objectID": "course_modules/Module3/module3_solutions.html",
    "href": "course_modules/Module3/module3_solutions.html",
    "title": "module3_solutions",
    "section": "",
    "text": "1 Variant Calling - Solutions\nNo exercises in this section.\n\n\n2 Performing variant calling\nQ1 66 reads\nQ2 The reference allele is A and the alternate allele is G. The upper/lower case letters indicate the forward/reverse orientation of the read.\nQ3 0 reads calling reference allelle and 66 reads calling the alternate allele\nQ4 Add the -v option to the command:\nbcftools mpileup -f GRCm38_68.19.fa A_J.bam | bcftools call -mv | less -S\n\n\n2.1 Exercises\nQ1 The reference allele is A and the alternate allele is G.\nQ2 Look up the tag DP in the INFO column: there were 69 raw reads at the position.\nQ3 There are 0 reads calling the reference and 66 high-quality reads calling the alternate.\nQ4 An indel. Five bases TGTGG were inserted after the T at position 10003649\n\n\n3 Variant Filtering\nQ1 The complete command is:\nbcftools query -f'%POS %QUAL [%GT %AD] %REF %ALT\\n' -i'QUAL&gt;=30 && type=\"snp\" && AD[*:1]&gt;=25' out.vcf | head\nQ2 The complete command is:\nbcftools stats -i'QUAL&gt;=30 && AD[*:1]&gt;=25' out.vcf | grep TSTV | cut -f5\nQ3 The complete command is:\nbcftools stats -e'QUAL&gt;=30 && AD[*:1]&gt;=25' out.vcf | grep TSTV | cut -f5\nQ4 The complete command is:\nbcftools stats -i 'GT=\"het\"' out.vcf | grep TSTV | cut -f5\nQ5 The complete command is:\nbcftools norm -f GRCm38_68.19.fa out.flt.vcf -o out.flt.norm.vcf\n\n\n4 Calling Variants Across Multiple Samples\nQ1 Use the commands:\nbcftools mpileup -a AD -f GRCm38_68.19.fa *.bam -Ou | bcftools call -mv -Ob -o multi.bcf bcftools index multi.bcf\nQ2 Use the commands\nbcftools filter -s LowQual -i'QUAL&gt;=30 && AD[*:1]&gt;=25' -g8 -G10 multi.bcf -Ob -o multi.filt.bcf bcftools index multi.filt.bcf\nQ3 Use the commands:\nbcftools stats multi.filt.bcf | grep TSTV | cut -f5 (raw calls)\nbcftools stats -i 'FILTER=\"PASS\"' multi.filt.bcf | grep TSTV | cut -f5 (only filtered set)\nQ4 Use the commands:\nbcftools stats -e 'FILTER=\"PASS\"' multi.filt.bcf | grep TSTV | cut -f5\n\n\n5 Visualising Alignments\nQ1 75 in total, 39 on the forward and 36 on the reverse strand.\nQ2 Yes. Use the command:\nbcftools view -H -r 19:10001946 multi.filt.bcf\nQ3 Yes.\nQ4 Yes. Use the command:\nbcftools view -H -r 19:10072443 multi.filt.bcf\nQ5 No. It fails due to lowQual and snpGap, this means the call was removed by filtering because the quality of the call falls below the treshold set and the call is in close proximity to an indel.\nQ6 No. It is an alignment artefact, the aligner prefered two SNPs instead of a long deletion.\n\n\n6 Variant annotation\nQ1 Use the command:\nbcftools query -f '%BCSQ' -r 19:10088937 multi.filt.annot.bcf\nto return\nmissense|Fads2|ENSMUST00000025567|protein_coding|-|163V&gt;163I|10088937C&gt;T(base)\nQ2 A missense mutation\nQ3 The C&gt;T mutation changes the amino acid at position 163 in the protein sequence, from valine to isoleucine."
  },
  {
    "objectID": "course_modules/Module3/module3_assessment.html",
    "href": "course_modules/Module3/module3_assessment.html",
    "title": "Quiz",
    "section": "",
    "text": "Q1\nWhat is the main difference between germline mutations and somatic mutations?\nA. Germline mutations occur in non-reproductive cells, while somatic mutations occur in reproductive cells.\nB. Germline mutations are heritable as they occur in egg or sperm cells, while somatic mutations occur in non-germline tissues and are not passed to offspring.\nC. Germline mutations only occur in bacteria, while somatic mutations are found only in humans.\nD. Both types of mutations are heritable but affect different chromosomes.\n\n\nQ2\nWhich of the following is an example of a large-scale genomic variation?\nA. A point mutation in a single base.\nB. A duplication involving 2 kilobases of DNA (CNV).\nC. A small insertion or deletion of 10 base pairs.\nD. A single nucleotide polymorphism (SNP).\n\n\nQ3\nWhich statement best describes the difference between single nucleotide variants (SNVs) and indels?\nA. SNVs involve changes in multiple adjacent bases; indels involve changes in just one base.\nB. SNVs are large deletions; indels are large insertions.\nC. SNVs involve single base substitutions, while indels are small insertions or deletions typically less than 50 base pairs.\nD. SNVs occur only in coding regions; indels occur only in non-coding regions.\n\n\nQ4\nWhich of the following is NOT a practical application of variant calling?\nA. Cataloging biological diversity in population genetics.\nB. Identifying pathogenic mutations for disease diagnosis.\nC. Determining the speed of DNA replication during cell division.\nD. Tailoring drug dosages in pharmacogenomics.\n\n\nQ5\nWhat is the benefit of resolving phased haplotypes in variant calling analyses?\nA. It provides information about the total number of chromosomes in the organism.\nB. It determines which variants are inherited together on the same chromosome, thereby clarifying genotype information.\nC. It helps to identify only somatic mutations exclusively.\nD. It replaces the need for any sequencing data.\n\n\nQ6\nWhich key field is NOT typically included in a Variant Call Format (VCF) file?\nA. CHROM (chromosome)\nB. POS (position)\nC. TEMP (temperature of the sample)\nD. ALT (alternate allele)\n\n\nQ7\nWhich sequence correctly describes the process from raw sequencing data to final variant calls?\nA. Alignment, Quality Control, Generate Sequencing Data, Pileup, Variant Calling.\nB. Generate Sequencing Data, Alignment, Quality Control, Variant Calling, Pileup.\nC. Generate Sequencing Data, Quality Control, Alignment, Pileup, Variant Calling.\nD. Pileup, Generate Sequencing Data, Quality Control, Alignment, Variant Calling.\n\n\nQ8\nWhich of the following is a common source of error in variant calling?\nA. Uniform base composition across the genome.\nB. Homopolymers and repetitive regions causing sequencing and mapping errors.\nC. Excessively high mapping quality in all reads.\nD. Infrequent occurrence of strand bias in high-quality datasets.\n\n\nQ9\nThe transition/transversion (Ts/Tv) ratio is used as a quality metric in SNP datasets. What Ts/Tv ratio is typically expected in high-quality human SNP calls?\nA. Approximately 0.5–1\nB. Approximately 1–2\nC. Approximately 2–3\nD. Approximately 4–5\n\n\nQ10\nHow do population-level datasets like those from the 1000 Genomes Project and gnomAD aid researchers?\nA. They provide a comprehensive snapshot of human genetic diversity and variant frequencies across various populations.\nB. They measure the metabolic rates of individuals in diverse populations.\nC. They only include data from European populations.\nD. They offer real-time monitoring of gene expression levels."
  },
  {
    "objectID": "course_modules/Module2/module2_solutions.html",
    "href": "course_modules/Module2/module2_solutions.html",
    "title": "Solutions",
    "section": "",
    "text": "1 Read Alignment\nThere are no questions in this section.\n\n\n2 Performing Read Alignment\n1. 145441459\n2. The sam is ~ 157M and the bam is ~ 25M\n3. 67,461 (17.2%) or 359 + (33551 * 2)\n4. 392,820\n5. 391603/392820 (99.7%)\n6. 389410\n7. 0\n8. 419 (mean) 113.9 (standard deviation)\n9. 7,853 (2.0%)\n10. First/Forward read\n\n\n3 Alignment Visualisation\n1. This exercise is just asking you to explore the genome and become familiar with navigating in IGV.\n2. 23X-57X\n3. There is a 1bp insertion (at “T)” at position 87,483,966. This is supported by 9 reads.\nThere is a 28bp deletion at position 87,483,966. This is supported by 3 reads.\nThe third mutation is a bit harder to spot, because it’s bigger than the read length (so no single read will span it). Look first at the coverage track, and notice a sharp coverage drop between chr7:87,483,833 and chr7:87,484,169. That suggests that one of the two alleles have been deleted across that position. Notice also the soft-clipping of some reads “entering” chr7:87,483,833 from the left, and the same softclipping of reads entering chr7:87,484,169 from the right. This soft-clipping shows up as reads being partly multi-coloured. That’s happening because the physical genome between those points has been excised for one allele, causing the mis-alignment when we attempt to align some reads to the reference genome. That mis-alignment causes the bwa aligner to “give up” and mark a part of the read as soft-clipped.\n4. This mouse was bred from a zygote which was mutagenised with Crispr-Cas9, targeted at the Tyr locus. You are watching the zygote DNA-repair machinery panicking and grabbing at straws when trying to repair double-stranded DNA breaks. In the process, it makes mistakes, and those mistakes are propagated into the mouse genome: different zygote cells received different mutations, which is why some reads reflect different mutations to others. Specifically - The CRISPR-Cas9 has acted on the zygote at this locus to create Non-Homologous-End-Join-based damage around 87,483,960: that resulted in a subclonal 1bp insertion and a 28bp deletion. Also, a related DNA repair process has resulted in the a 336bp deletion across the same area.\n\n\n3.1 Alignment workflows\n1. -M marks shorter split hits as secondary and -R adds the read group to the header of the BAM file\n2. -b means create a BAM as output and -S indicates that the input files is a SAM file. The -S option is now ignored by samtools as it can now autodetect the input file type.\n3. 397506\n4. 303036/397506 (76.2%)\n5. 282478\n6. 2239\n7. 275.9 (mean) and 47.7 (standard deviation)\n8. 23,789 (7.9%)\n9. First\n10.\nbwa mem -M -R ”@RG\\tID:lane2\\tSM:60A_Sc_DBVPG6044” ../../../../ref/Saccharomyces_cerevisiae.R64-1-1.dna.toplevel.fa.gz s_7_1.fastq.gz s_7_2.fastq.gz | samtools view -bS - | samtools sort -T temp -O bam -o lane1.sorted.bam -\n~22M\nMerge: ~/course_data/read_alignment/data/Exercise2/60A_Sc_DBVPG6044/library1$ picard\nMergeSamFiles -I lane1/lane1.sorted.bam -I lane2/lane1.sorted.bam -O library1.bam\nMarkdup: ~/course_data/read_alignment/data/Exercise2/60A_Sc_DBVPG6044/library1$ picard\nMarkDuplicates -I library1.bam -O library1.markdup.bam -M library1.metrics.txt\n11. 12399 or 3115 + (4642 * 2) = unpaired read dups + (paired read dups *2)\n12. 2.5%\n\n\n3.2 Exercises\n1. No answer needed\n2. The reference base is C\n3. No (the reads call T)\n4. The reference base is G and all reads agree\n5. No answer\n6. An insertion\n7. No answer\n8. A deletion. This is unlikely to be a true variant and may be due to misalignment due the run of T’s in the flanking region.\n9. The following command procuces a cram file which should be ~29MB in size.\nsamtools view -C -T ../../../ref/Saccharomyces_cerevisiae.R64-1-1.dna.toplevel.fa -o library1.markdup.cram library1.markdup.bam\n-C means create a CRAM file as output\n-T is the reference file to use for the compression\n-o is the name of CRAM file to create"
  },
  {
    "objectID": "course_modules/template_module.html",
    "href": "course_modules/template_module.html",
    "title": "template_module",
    "section": "",
    "text": "Title of session/module\n  - Duration \n  - Key topics\n  - Activities (lectures, hands-on, discussions) - Use GHRU template here \n- Presentation slides (PPT/PDF)\n- Lecture notes or scripts\n- Videos (prerecorded lectures, screencasts, youtube etc, with transcripts)\n- Practical/lab exercises (e.g., Jupyter notebooks, Google Colab walkthrough, command line walkthroughs)\n- Datasets (example files or open data repositories)\n- Case studies or examples"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats-answers.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/formats-answers.html",
    "title": "Data formats for NGS data - Answers",
    "section": "",
    "text": "1. There are 10 sequences in this file. To count all the header lines, we can use grep -c \"&gt;\" data/example.fasta\n2. There are 8 reads in this file. We can use grep to search for /1 or /2:\ngrep -c \"/1\" data/example.fastq\nAlternatively, we can use wc -l to count the lines in the file and then divide this by 4.\n3. RG = Read Group\n4. Illumina. See the __PL__field.\n5. SC. See the CN field.\n6. ERR003612. See the ID field.\n7. 2kbp. See the PI field.\n8. The quality is 48. We can use grep to find the id, followed by awk to print the fifth column:\ngrep \"ERR003762.5016205\" data/example.sam | awk '{print $5}'\n9. The CIGAR is 37M. We can use grep and awk to find it:\ngrep ERR003814.6979522 data/example.sam | awk '{print $6}'\n10. 213. The ninth column holds the insert size, so we can use awk to get this:\ngrep ERR003814.1408899 data/example.sam | awk '{print $9}'\n11. The CIGAR in Q9 was 37M, meaning all 37 bases in the read are either matches or mismatches to the reference.\n12. CIGAR: 4M 4I 8M. The first four bases in the read are the same as in the reference, so we can represent these as 4M in the CIGAR string. Next comes 4 insertions, represented by 4I, followed by 8 alignment matches, represented by 8M.\n13. NCBI build v37\n14. There are 15 lanes in the file. We can count the @RG lines manually, or use standard UNIX commands such as:\nsamtools view -H data/NA20538.bam | grep ^@RG | wc -l\nor\nsamtools view -H data/NA20538.bam | awk '{if($1==\"@RG\")n++}END{print n}'\n15. Looking at the @PG records ID tags, we see that three programs were used: GATK IndelRealigner, GATK TableRecalibration and bwa.\n16. The @PG records contain a the tag VN. From this we see that bwa version 0.5.5 was used.\n17. The first collumn holds the name of the read: ERR003814.1408899\n18. Chromosome 1, position 19999970. Column three contains the name of the reference sequenceand the fourth column holds the leftmost position of the clipped alignment.\n19. 320 reads are mapped to this region. We have already sorted and indexed the BAM file, so now we can search for the reagion using samtools view. Then we can pipe the output to wc to count the number of reads in this region:\nsamtools view data/NA20538_sorted.bam 1:20025000-20030000 | wc -l\n20. The reference version is 37. In the same way that we can use -h in samtools to include the header in the output, we can also use this with bcftools:\nbcftools view -h data/1kg.bcf | grep \"##reference\"\n21. There are 50 samples in the file. The -l option will list all samples in the file:\nbcftools query -l data/1kg.bcf | wc -l\n22. The genotype is A/T. With -f we specify the format of the output, -r is used to specify the region we are looking for, and with -s we select the sample.\nbcftools query -f'%POS [ %TGT]\\n' -r 20:24019472 -s HG00107 data/1kg.bcf\n23. There are 4778 positions with more than 10 alternate alleles. We can use -i to specify that we are looking for instances where the value of the INFO:AC tag (Allele Count) is greater than 10:\nbcftools query -f'%POS\\n' -i 'AC[0]&gt;10' data/1kg.bcf | wc -l\n24. There are 451 such positions. The first command picks out sample HG00107. We can then pipe the output to the second command to filter by depth and non-reference genotype. Then use wc to count the lines:\nbcftools view -s HG00107 data/1kg.bcf | bcftools query -i'FMT/DP&gt;10 & FMT/GT!=\"0/0\"' -f'%POS[ %GT %DP]\\n' | wc -l\n25. 26. The first base is at position 9923 and the last is at 9948.\n26. G. To reduce file size, only the first base is provided in the REF field.\n27. 10. See the MinDP tag in the INFO field."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment-answers.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/assessment-answers.html",
    "title": "QC assessment of NGS data",
    "section": "",
    "text": "1. The peak is at 140 bp, and the read length is 100 bp. This means that the forward and reverse reads overlap with 60 bp.\n2. There are 400252 reads in total.\nLook inside the file and locate the field “raw total sequences”. To extract the information quickly from multiple files, commands similar to the following can be used:\ngrep ^SN lane*.sorted.bam.bchk | awk -F'\\t' '$2==\"raw total sequences:\"'\n3. 76% of the reads were mapped. Divide “reads mapped” (303036) by “raw total sequences” (400252).\n4. 2235 pairs mapped to a different chromosome. Look for “pairs on different chromosomes”\n5. The mean insert size is 275.9 and the standard deviation is 47.7. Look for “insert size mean” and “insert size standard deviation”.\n6. 282478 reads were properly paired. Look for “reads properly paired”.\n7. 23,803 (7.9%) of the reads have zero mapping quality. Look for “zero MQ” in the “Reads” section.\n8. The forward reads. Look at the “Quality per cycle” graphs."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion-answers.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/conversion-answers.html",
    "title": "File conversion - Answers",
    "section": "",
    "text": "1. The CRAM file is ~18 MB. We can check this using:\nls -lh data/yeast.cram\n2. Yes, the BAM file is ~16 MB bigger than the CRAM file. We can check this using:\nls -lh data/yeast*"
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination-answers.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/practical/Notebooks/contamination-answers.html",
    "title": "Identifying contamination - Answers",
    "section": "",
    "text": "1. Streptococcus pneumoniae\n2. No\n3. ~7% of the reads. Look for “unclassified” at the top of the file."
  },
  {
    "objectID": "course_modules/NGS_Data_Formats_and_QC/lecture/src/hts-qc.html",
    "href": "course_modules/NGS_Data_Formats_and_QC/lecture/src/hts-qc.html",
    "title": "only for printing",
    "section": "",
    "text": "% subset-slides\n\\vskip2em\n\\vskip10em\n\nData Formats\nFASTQ\n\nUnaligned read sequences with base qualities\n\nSAM/BAM\n\nUnaligned or aligned reads\nText and binary formats\n\nCRAM\n\nBetter compression than BAM\n\nVCF/BCF\n\nFlexible variant call format\nArbitrary types of sequence variation\nSNPs, indels, structural variations\n\n\\vskip2em\nSpecifications maintained by the Global Alliance for Genomics and Health\n\n\nFASTQ\n\nSimple format for raw unaligned sequencing reads\nExtension to the FASTA file format\nSequence and an associated per base quality score\n\n\nQuality encoded in ASCII characters with decimal codes 33-126\n\nASCII code of “A” is 65, the corresponding quality is Q\\(= 65 - 33 = 32\\)\n\n\\vskip0em\n\nPhred quality score: \\(P = 10^{-Q/10}\\) \n\nBeware: multiple quality scores were in use!\n\nSanger, Solexa, Illumina 1.3+\n\nPaired-end sequencing produces two FASTQ files\n\n{A: Q=30, one error in 1000 bases}\n\n\nSAM / BAM\nSAM (Sequence Alignment/Map) format\n\nUnified format for storing read alignments to a reference genome\nDeveloped by the 1000 Genomes Project group (2009)\n\n\nOne record (a single DNA fragment alignment) per line describing alignment between fragment and reference\n11 fixed columns + optional key:type:value tuples\n\n\\vskip0.5em\n\\vskip0.5em\n\\vskip1em\nNote that BAM can contain\n\nunmapped reads\nmultiple alignments of the same read\nsupplementary (chimeric) reads\n\n\n\nSAM\nSAM fields\n\\vskip1em \nCCCTAACCCTAACCATAGCCCTAACCCTAACCCTAACCCTAACCCT[…]CAAACCCACCCCCAAACCCAAAACCTCACCAC\nFFFFFJJJJJJJJFJJJJFJAJJJJJ-JJAAAJFJJFFJJF&lt;FJJFFJJJJFJJJJFF[…]&lt;—F—–A7-J-&lt;J-A–77AF—J7–\nMD:Z:1G24C2A76 PG:Z:MarkDuplicates RG:Z:1 NM:i:3 MQ:i:0 AS:i:94 XS:i:94 \\end{verbatim}}}\n\n\nCIGAR string\nCompact representation of sequence alignment\n\\vskip1em \nExamples:\n\n\nFlags\n\\vskip0.5em\n\\vskip0.5em\nBit operations made easy\n\npython \nsamtools flags \n\n\\vskip5em\n\n\nOptional tags\nEach lane has a unique RG tag that contains meta-data for the lane\nRG tags\n\nID: SRR/ERR number\nPL: Sequencing platform\nPU: Run name\nLB: Library name\nPI: Insert fragment size\nSM: Individual\nCN: Sequencing center\n\n\\vskip10em\n\n\nBAM\nBAM (Binary Alignment/Map) format\n\nBinary version of SAM\nDeveloped for fast processing and random access\n\nBGZF (Block GZIP) compression for indexing\n\n\nKey features\n\nCan store alignments from most mappers\nSupports multiple sequencing technologies\nSupports indexing for quick retrieval/viewing\nCompact size (e.g. 112Gbp Illumina = 116GB disk space)\nReads can be grouped into logical groups e.g. lanes, libraries, samples\nWidely supported by variant calling packages and viewers\n\n\n\nReference based Compression\nBAM files are too large\n\n~1.5-2 bytes per base pair\n\nIncreases in disk capacity are being far outstripped by sequencing technologies\nBAM stores all of the data\n\nEvery read base\nEvery base quality\nUsing a single conventional compression technique for all types of data\n\n\\vskip14em\n\n\nCRAM\nThree important concepts\n\nReference based compression\nControlled loss of quality information\nDifferent compression methods to suit the type of data, e.g. base qualities vs. metadata vs. extra tags\n\nIn lossless mode: 60% of BAM size\nArchives and sequencing centers moving from BAM to CRAM\n\nSupport for CRAM added to Samtools/HTSlib in 2014\nSoon to be available in Picard/GATK\n\n\\vskip1em\n\n\nVCF: Variant Call Format\nFile format for storing variation data\n\nTab-delimited text, parsable by standard UNIX commands\nFlexible and user-extensible\nCompressed with BGZF (bgzip), indexed with TBI or CSI (tabix)\n\n\\vskip1em\n\\vskip3em\n\n\nVCF / BCF\nVCFs can be very big\n\ncompressed VCF with 3781 samples, human data:\n\n54 GB for chromosome 1\n680 GB whole genome\n\n\nVCFs can be slow to parse\n\ntext conversion is slow\nmain bottleneck: FORMAT fields\n\n\\vskip0.5em\n\\vskip1em\nBCF\n\nbinary representation of VCF\nfields rearranged for fast access\n\n\\vskip0.5em\n\n\ngVCF\nOften it is not enough not know variant sites only\n\nwas a site dropped because of a reference call or because of missing data?\nwe need evidence for both variant and non-variant positions in the genome\n\n\\vskip0.5em\ngVCF\n\nblocks of reference-only sites can be represented in a single record using the INFO/END tag\nsymbolic alleles &lt;*&gt; for incremental calling\n\nraw, “callable” gVCF\ncalculate genotype likelihoods only once (an expensive step)\nthen call incrementally as more samples come in\n\n\n\\vskip0.5em\n\n\nOptimizing variant calls for speed\n\\vskip2em\n\\vskip3em\nNew TWK format by Marcus Klarqvist (under development)\n\nBCF still too slow for querying hundreds of thousands and millions of samples\nbigger but 100x faster for certain operations on GTs\n\n\n\nCustom formats for custom tasks\n\\centerline{ \\hskip1em } \\vskip1em \\centerline{ \\hskip2em }\n\n\nGlobal Alliance for Genomics and Health\nInternational coalition dedicated to improving human health\nMission\n\nestablish a common framework to enable sharing of genomic and clinical data\n\nWorking groups\n\nclinical\nregulatory and ethics\nsecurity\ndata\n\nData working group\n\nbeacon project .. test the willingness of international sites to share genetic data \nBRCA challenge .. advance understanding of the genetic basis of breast and other cancers \nmatchmaker exchange .. locate data on rare phenotypes or genotypes \nreference variation .. describe how genomes differ so researchers can assemble and interpret them \nbenchmarking .. develop variant calling benchmark toolkits for germline, cancer, and transcripts \nfile formats .. CRAM, SAM/BAM, VCF/BCF \n\nFile formats\n\nhttp://samtools.github.io/hts-specs/\n\n% # Coffee break and questions %\n% \\vskip7em %\n\n\nQuality Control\nBiases in sequencing\n\nBase calling accuracy\nRead cycle vs. base content\nGC vs. depth\nIndel ratio\n\n\\vskip0.5em\nBiases in mapping\n\\vskip1em\nGenotype checking\n\nSample swaps\nContaminations\n\n\n\nBase quality\nSequencing by synthesis: dephasing\n\ngrowing sequences in a cluster gradually desynchronize\nerror rate increases with read length\n\n\\vskip1em\nCalculate the average quality at each position across all reads\n\\vskip0.5em\n\\vskip0.5em\n\n\nBase calling errors\n\n\n\nBase quality\n\\centerline{ \\hskip5em } \n\n\nMismatches per cycle\nMismatches in aligned reads (requires reference sequence)\n\ndetect cycle-specific errors\nbase qualities are informative!\n\n\\vskip1em\n\n\nGC bias\nGC- and AT-rich regions are more difficult to amplify\n\ncompare the GC content against the expected distribution (reference sequence)\n\n\\vskip2em\n\\vskip3em\n\n\nGC content by cycle\nWas the adapter sequence trimmed?\n\\vskip1em\n\\vskip3em\n\n\nFragment size\nPaired-end sequencing: the size of DNA fragments matters\n\\vskip1em \\vskip3em\n\n\nQuiz\n\\vskip1em \\centerline{\\hskip2em} \\vskip1em\n\\vskip3em\n\n\nInsertions / Deletions per cycle\nFalse indels\n\nair bubbles in the flow cell can manifest as false indels\n\n\\vskip1em\n\\vskip3em\n\n\nAuto QC tests\nA suggestion for human data: \\vskip1em\n\\vskip2em\n\n\n\nDetecting sample swaps\nCheck the identity against a known set of variants\n\\vskip1em \\centerline{ \\hskip1em } \\vskip3em\n\n\nHow many markers are necessary?\n\\vskip1em Number of sites required to identify non-related human samples\n\\vskip1em \\centerline{ \\hskip1em }\n\n\nSoftware\nSoftware used to produce graphs in these slides\n\nsamtools stats and plot-bamstats\nbcftools gtcheck\nmatplotlib\n\n% # xxx %\n% Pipelining %\n% http://seqanswers.com % http://www.cbs.dtu.dk/courses/27626/Exercises/BAM-postprocessing.php %\n% Schwartz: Detection and Removal of Biases in the Analysis of Next- Generation Sequencing Reads % % # Biases in Next Generation Sequencing data %\n% * nucleotide per cycle bias % * mostly in RNA-seq, sometimes in ChIP-seq % * cannot be attributed to biased PCR-amplification % * partial explanation: random hexamer priming during reverse transcription? % - more references in the paper above: 14,15,16,17 %\n% dephasing %\n% The illumina platform uses a so called sequencing by synthesis process. Bases are added one at a time and the consensus is determined in a cluster of identical sequences. %\n% The source of errors can be numerous, here is one review that discusses the issues in more detail: %\n% The challenges of sequencing by synthesis, Nature Biotech, 2009 %\n% In a nuthsell a short answer to the best of my understanding is this: Not % all sequences in a cluster will grow at the same rate, this will slowly % lead to a desynchronization as the errors accumulate. This is why the % quality dips towards the end."
  },
  {
    "objectID": "course_modules/Module1/module1_assessment.html",
    "href": "course_modules/Module1/module1_assessment.html",
    "title": "Assessment Quiz",
    "section": "",
    "text": "Quiz\n\nLook at the following FASTQ line:\n\n@ERR007731.740 IL16_2979:6:1:9:1419/1\nTAAAAAAAAGATGTCATCAGCACATCAGAAAAGAAGGCAACTTTAAAACTTTTC\n+\nDBABBBABABAABABABBABBBAAA&gt;@B@BBAA@4AAA&gt;.&gt;BAA@779:AAA@A\nWhat is the quality of the first base (T)?\n\nLook at the following FASTQ line:\n\n@ERR007731.740 IL16_2979:6:1:9:1419/1  TAAAAAAAAGATGTCATCAGCACATCAGAAAAGAAGGCAACTTTAAAACTTTTC\n+\nDBABBBABABAABABABBABBBAAA&gt;@B@BBAA@4AAA&gt;.&gt;BAA@779:AAA@A\nWhat is the probability that there was a base call error for the first base (T)?\n\nLook at the following line from the header of a SAM file.\n\n@RGID:ERR003612 PL:ILLUMINA LB:g1k-sc-NA20538-TOS-1 PI:2000 DS:SRP000540 SM:NA20538 CN:SC\nWhat does RG stand for?"
  }
]